{"file_contents":{"docs-mastra.md":{"content":"---\ntitle: \"Dynamic Agents\"\ndescription: Dynamically configure your agent's instruction, model and tools using runtime context.\n---\n\n# Dynamic Agents\n[EN] Source: https://mastra.ai/en/docs/agents/dynamic-agents\n\nDynamic agents use [runtime context](./runtime-variables), like user IDs and other important parameters, to adjust their settings in real-time.\n\nThis means they can change the model they use, update their instructions, and select different tools as needed.\n\nBy using this context, agents can better respond to each user's needs. They can also call any API to gather more information, which helps improve what the agents can do.\n\n### Example Configuration\n\nHere's an example of a dynamic support agent that adjusts its behavior based on the user's subscription tier and language preferences:\n\n```typescript\nconst supportAgent = new Agent({\n  name: \"Dynamic Support Agent\",\n\n  instructions: async ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    const language = runtimeContext.get(\"language\");\n\n    return `You are a customer support agent for our SaaS platform.\n    The current user is on the ${userTier} tier and prefers ${language} language.\n    \n    For ${userTier} tier users:\n    ${userTier === \"free\" ? \"- Provide basic support and documentation links\" : \"\"}\n    ${userTier === \"pro\" ? \"- Offer detailed technical support and best practices\" : \"\"}\n    ${userTier === \"enterprise\" ? \"- Provide priority support with custom solutions\" : \"\"}\n    \n    Always respond in ${language} language.`;\n  },\n\n  model: ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    return userTier === \"enterprise\"\n      ? openai(\"gpt-4\")\n      : openai(\"gpt-3.5-turbo\");\n  },\n\n  tools: ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    const baseTools = [knowledgeBase, ticketSystem];\n\n    if (userTier === \"pro\" || userTier === \"enterprise\") {\n      baseTools.push(advancedAnalytics);\n    }\n\n    if (userTier === \"enterprise\") {\n      baseTools.push(customIntegration);\n    }\n\n    return baseTools;\n  },\n});\n```\n\nIn this example, the agent:\n\n- Adjusts its instructions based on the user's subscription tier (free, pro, or enterprise)\n- Uses a more powerful model (GPT-4) for enterprise users\n- Provides different sets of tools based on the user's tier\n- Responds in the user's preferred language\n\nThis demonstrates how a single agent can handle different types of users and scenarios by leveraging runtime context, making it more flexible and maintainable than creating separate agents for each use case.\n\nFor a complete implementation example including API routes, middleware setup, and runtime context handling, see our [Dynamic Agents Example](/examples/agents/dynamic-agents).\n\n\n---\ntitle: \"Agent Overview | Agent Documentation | Mastra\"\ndescription: Overview of agents in Mastra, detailing their capabilities and how they interact with tools, workflows, and external systems.\n---\n\n# Using Agents\n[EN] Source: https://mastra.ai/en/docs/agents/overview\n\n**Agents** are one of the core Mastra primitives. Agents use a language model to decide on a sequence of actions. They can call functions (known as _tools_). You can compose them with *workflows* (the other main Mastra primitive), either by giving an agent a workflow as a tool, or by running an agent from within a workflow.\n\nAgents can run autonomously in a loop, run once, or take turns with a user. You can give short-term, long-term, and working memory of their user interactions. They can stream text or return structured output (ie, JSON). They can access third-party APIs, query knowledge bases, and so on.\n\n## 1. Creating an Agent\n\nTo create an agent in Mastra, you use the `Agent` class and define its properties:\n\n```ts showLineNumbers filename=\"src/mastra/agents/index.ts\" copy\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\n**Note:** Ensure that you have set the necessary environment variables, such as your OpenAI API key, in your `.env` file:\n\n```.env filename=\".env\" copy\nOPENAI_API_KEY=your_openai_api_key\n```\n\nAlso, make sure you have the `@mastra/core` package installed:\n\n```bash npm2yarn copy\nnpm install @mastra/core@latest\n```\n\n### Registering the Agent\n\nRegister your agent with Mastra to enable logging and access to configured tools and integrations:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { myAgent } from \"./agents\";\n\nexport const mastra = new Mastra({\n  agents: { myAgent },\n});\n```\n\n## 2. Generating and streaming text\n\n### Generating text\n\nUse the `.generate()` method to have your agent produce text responses:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\" copy\nconst response = await myAgent.generate([\n  { role: \"user\", content: \"Hello, how can you assist me today?\" },\n]);\n\nconsole.log(\"Agent:\", response.text);\n```\n\nFor more details about the generate method and its options, see the [generate reference documentation](/reference/agents/generate).\n\n### Streaming responses\n\nFor more real-time responses, you can stream the agent's response:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\" copy\nconst stream = await myAgent.stream([\n  { role: \"user\", content: \"Tell me a story.\" },\n]);\n\nconsole.log(\"Agent:\");\n\nfor await (const chunk of stream.textStream) {\n  process.stdout.write(chunk);\n}\n```\n\nFor more details about streaming responses, see the [stream reference documentation](/reference/agents/stream).\n\n## 3. Structured Output\n\nAgents can return structured data by providing a JSON Schema or using a Zod schema.\n\n### Using JSON Schema\n\n```typescript\nconst schema = {\n  type: \"object\",\n  properties: {\n    summary: { type: \"string\" },\n    keywords: { type: \"array\", items: { type: \"string\" } },\n  },\n  additionalProperties: false,\n  required: [\"summary\", \"keywords\"],\n};\n\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"Please provide a summary and keywords for the following text: ...\",\n    },\n  ],\n  {\n    output: schema,\n  },\n);\n\nconsole.log(\"Structured Output:\", response.object);\n```\n\n### Using Zod\n\nYou can also use Zod schemas for type-safe structured outputs.\n\nFirst, install Zod:\n\n```bash npm2yarn copy\nnpm install zod\n```\n\nThen, define a Zod schema and use it with the agent:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\" copy\nimport { z } from \"zod\";\n\n// Define the Zod schema\nconst schema = z.object({\n  summary: z.string(),\n  keywords: z.array(z.string()),\n});\n\n// Use the schema with the agent\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"Please provide a summary and keywords for the following text: ...\",\n    },\n  ],\n  {\n    output: schema,\n  },\n);\n\nconsole.log(\"Structured Output:\", response.object);\n```\n\n### Using Tools\n\nIf you need to generate structured output alongside tool calls, you'll need to use the `experimental_output` property instead of `output`. Here's how:\n\n```typescript\nconst schema = z.object({\n  summary: z.string(),\n  keywords: z.array(z.string()),\n});\n\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"Please analyze this repository and provide a summary and keywords...\",\n    },\n  ],\n  {\n    // Use experimental_output to enable both structured output and tool calls\n    experimental_output: schema,\n  },\n);\n\nconsole.log(\"Structured Output:\", response.object);\n```\n\n<br />\n\nThis allows you to have strong typing and validation for the structured data returned by the agent.\n\n## 4. Multi-step tool use\n\nAgents can be enhanced with tools - functions that extend their capabilities beyond text generation. Tools allow agents to perform calculations, access external systems, and process data. Agents not only decide whether to call tools they're given, they determine the parameters that should be given to that tool.\n\nFor a detailed guide to creating and configuring tools, see the [Adding Tools documentation](/docs/agents/using-tools-and-mcp), but below are the important things to know.\n\n### Using `maxSteps`\n\nThe `maxSteps` parameter controls the maximum number of sequential LLM calls an agent can make, particularly important when using tool calls. By default, it is set to 1 to prevent infinite loops in case of misconfigured tools. You can increase this limit based on your use case:\n\n```ts showLineNumbers filename=\"src/mastra/agents/index.ts\" copy\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport * as mathjs from \"mathjs\";\nimport { z } from \"zod\";\n\nexport const myAgent = new Agent({\n  name: \"My Agent\",\n  instructions: \"You are a helpful assistant that can solve math problems.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    calculate: {\n      description: \"Calculator for mathematical expressions\",\n      schema: z.object({ expression: z.string() }),\n      execute: async ({ expression }) => mathjs.evaluate(expression),\n    },\n  },\n});\n\nconst response = await myAgent.generate(\n  [\n    {\n      role: \"user\",\n      content:\n        \"If a taxi driver earns $41 per hour and works 12 hours a day, how much do they earn in one day?\",\n    },\n  ],\n  {\n    maxSteps: 5, // Allow up to 5 tool usage steps\n  },\n);\n```\n\n### Streaming progress with `onStepFinish`\n\nYou can monitor the progress of multi-step operations using the `onStepFinish` callback. This is useful for debugging or providing progress updates to users.\n\n`onStepFinish` is only available when streaming or generating text without structured output.\n\n```ts showLineNumbers filename=\"src/mastra/agents/index.ts\" copy\nconst response = await myAgent.generate(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onStepFinish: ({ text, toolCalls, toolResults }) => {\n      console.log(\"Step completed:\", { text, toolCalls, toolResults });\n    },\n  },\n);\n```\n\n### Detecting completion with `onFinish`\n\nThe `onFinish` callback is available when streaming responses and provides detailed information about the completed interaction. It is called after the LLM has finished generating its response and all tool executions have completed.\nThis callback receives the final response text, execution steps, token usage statistics, and other metadata that can be useful for monitoring and logging:\n\n```ts showLineNumbers filename=\"src/mastra/agents/index.ts\" copy\nconst stream = await myAgent.stream(\n  [{ role: \"user\", content: \"Calculate the taxi driver's daily earnings.\" }],\n  {\n    maxSteps: 5,\n    onFinish: ({\n      steps,\n      text,\n      finishReason, // 'complete', 'length', 'tool', etc.\n      usage, // token usage statistics\n      reasoningDetails, // additional context about the agent's decisions\n    }) => {\n      console.log(\"Stream complete:\", {\n        totalSteps: steps.length,\n        finishReason,\n        usage,\n      });\n    },\n  },\n);\n```\n\n## 5. Testing agents locally\n\nMastra provides a CLI command `mastra dev` to run your agents behind an API. By default, this looks for exported agents in files in the `src/mastra/agents` directory. It generates endpoints for testing your agent (eg `http://localhost:5000/api/agents/myAgent/generate`) and provides a visual playground where you can chat with an agent and view traces.\n\nFor more details, see the [Local Dev Playground](/docs/server-db/local-dev-playground) docs.\n\n## Next Steps\n\n- Learn about Agent Memory in the [Agent Memory](./agent-memory.mdx) guide.\n- Learn about Agent Tools in the [Agent Tools and MCP](./using-tools-and-mcp.mdx) guide.\n- See an example agent in the [Chef Michel](../../guides/guide/chef-michel.mdx) example.\n\n\n---\ntitle: \"Runtime context | Agents | Mastra Docs\"\ndescription: Learn how to use Mastra's dependency injection system to provide runtime configuration to agents and tools.\n---\n\n# Agent Runtime Context\n[EN] Source: https://mastra.ai/en/docs/agents/runtime-variables\n\nMastra provides runtime context, which is a system based on dependency injection that enables you to configure your agents and tools with runtime variables. If you find yourself creating several different agents that do very similar things, runtime context allows you to combine them into one agent.\n\n## Overview\n\nThe dependency injection system allows you to:\n\n1. Pass runtime configuration variables to agents through a type-safe runtimeContext\n2. Access these variables within tool execution contexts\n3. Modify agent behavior without changing the underlying code\n4. Share configuration across multiple tools within the same agent\n\n## Basic Usage\n\n```typescript\nconst agent = mastra.getAgent(\"weatherAgent\");\n\n// Define your runtimeContext's type structure\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\"; // Fixed typo in \"fahrenheit\"\n};\n\nconst runtimeContext = new RuntimeContext<WeatherRuntimeContext>();\nruntimeContext.set(\"temperature-scale\", \"celsius\");\n\nconst response = await agent.generate(\"What's the weather like today?\", {\n  runtimeContext,\n});\n\nconsole.log(response.text);\n```\n\n## Using with REST API\n\nHere's how to dynamically set temperature units based on a user's location using the Cloudflare `CF-IPCountry` header:\n\n```typescript filename=\"src/index.ts\"\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { agent as weatherAgent } from \"./agents/weather\";\n\n// Define RuntimeContext type with clear, descriptive types\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\";\n};\n\nexport const mastra = new Mastra({\n  agents: {\n    weather: weatherAgent,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const country = c.req.header(\"CF-IPCountry\");\n        const runtimeContext = c.get<WeatherRuntimeContext>(\"runtimeContext\");\n\n        // Set temperature scale based on country\n        runtimeContext.set(\n          \"temperature-scale\",\n          country === \"US\" ? \"fahrenheit\" : \"celsius\",\n        );\n\n        await next(); // Don't forget to call next()\n      },\n    ],\n  },\n});\n```\n\n## Creating Tools with Variables\n\nTools can access runtimeContext variables and must conform to the agent's runtimeContext type:\n\n```typescript\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const weatherTool = createTool({\n  id: \"getWeather\",\n  description: \"Get the current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"The location to get weather for\"),\n  }),\n  execute: async ({ context, runtimeContext }) => {\n    // Type-safe access to runtimeContext variables\n    const temperatureUnit = runtimeContext.get(\"temperature-scale\");\n\n    const weather = await fetchWeather(context.location, {\n      temperatureUnit,\n    });\n\n    return { result: weather };\n  },\n});\n\nasync function fetchWeather(\n  location: string,\n  { temperatureUnit }: { temperatureUnit: \"celsius\" | \"fahrenheit\" },\n): Promise<WeatherResponse> {\n  // Implementation of weather API call\n  const response = await weatherApi.fetch(location, temperatureUnit);\n\n  return {\n    location,\n    temperature: \"72Â°F\",\n    conditions: \"Sunny\",\n    unit: temperatureUnit,\n  };\n}\n```\n\n\n---\ntitle: \"Using Tools with Agents | Agents | Mastra Docs\"\ndescription: Learn how to create tools, add them to Mastra agents, and integrate tools from MCP servers.\n---\n\n# Using Tools with Agents\n[EN] Source: https://mastra.ai/en/docs/agents/using-tools-and-mcp\n\nTools are typed functions that can be executed by agents or workflows. Each tool has a schema defining its inputs, an executor function implementing its logic, and optional access to configured integrations.\n\n## Creating Tools\n\nHere's a basic example of creating a tool:\n\n```typescript filename=\"src/mastra/tools/weatherInfo.ts\" copy\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const weatherInfo = createTool({\n  id: \"Get Weather Information\",\n  inputSchema: z.object({\n    city: z.string(),\n  }),\n  description: `Fetches the current weather information for a given city`,\n  execute: async ({ context: { city } }) => {\n    // Tool logic here (e.g., API call)\n    console.log(\"Using tool to fetch weather information for\", city);\n    return { temperature: 20, conditions: \"Sunny\" }; // Example return\n  },\n});\n```\n\nFor details on creating and designing tools, see the [Tools Overview](/docs/tools-mcp/overview).\n\n## Adding Tools to an Agent\n\nTo make a tool available to an agent, add it to the `tools` property in the agent's configuration.\n\n```typescript filename=\"src/mastra/agents/weatherAgent.ts\" {3,11}\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { weatherInfo } from \"../tools/weatherInfo\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions:\n    \"You are a helpful assistant that provides current weather information. When asked about the weather, use the weather information tool to fetch the data.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    weatherInfo,\n  },\n});\n```\n\nWhen you call the agent, it can now decide to use the configured tool based on its instructions and the user's prompt.\n\n## Adding MCP Tools to an Agent\n\n[Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) provides a standardized way for AI models to discover and interact with external tools and resources. You can connect your Mastra agent to MCP servers to use tools provided by third parties.\n\nFor more details on MCP concepts and how to set up MCP clients and servers, see the [MCP Overview](/docs/tools-mcp/mcp-overview).\n\n### Installation\n\nFirst, install the Mastra MCP package:\n\n```bash npm2yarn copy\nnpm install @mastra/mcp@latest\n```\n\n### Using MCP Tools\n\nBecause there are so many MCP server registries to choose from, we've created an [MCP Registry Registry](https://mastra.ai/mcp-registry-registry) to help you find MCP servers.\n\nOnce you have a server you want to use with your agent, import the Mastra `MCPClient` and add the server configuration.\n\n```typescript filename=\"src/mastra/mcp.ts\" {1,7-16}\nimport { MCPClient } from \"@mastra/mcp\";\n\n// Configure MCPClient to connect to your server(s)\nexport const mcp = new MCPClient({\n  servers: {\n    filesystem: {\n      command: \"npx\",\n      args: [\n        \"-y\",\n        \"@modelcontextprotocol/server-filesystem\",\n        \"/Users/username/Downloads\",\n      ],\n    },\n  },\n});\n```\n\nThen connect your agent to the server tools:\n\n```typescript filename=\"src/mastra/agents/mcpAgent.ts\" {7}\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { mcp } from \"../mcp\";\n\n// Create an agent and add tools from the MCP client\nconst agent = new Agent({\n  name: \"Agent with MCP Tools\",\n  instructions: \"You can use tools from connected MCP servers.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: await mcp.getTools(),\n});\n```\n\nFor more details on configuring `MCPClient` and the difference between static and dynamic MCP server configurations, see the [MCP Overview](/docs/tools-mcp/mcp-overview).\n\n## Accessing MCP Resources\n\nIn addition to tools, MCP servers can also expose resources - data or content that can be retrieved and used in your application.\n\n```typescript filename=\"src/mastra/resources.ts\" {3-8}\nimport { mcp } from \"./mcp\";\n\n// Get resources from all connected MCP servers\nconst resources = await mcp.getResources();\n\n// Access resources from a specific server\nif (resources.filesystem) {\n  const resource = resources.filesystem.find(\n    (r) => r.uri === \"filesystem://Downloads\",\n  );\n  console.log(`Resource: ${resource?.name}`);\n}\n```\n\nEach resource has a URI, name, description, and MIME type. The `getResources()` method handles errors gracefully - if a server fails or doesn't support resources, it will be omitted from the results.\n\n## Accessing MCP Prompts\n\nMCP servers can also expose prompts, which represent structured message templates or conversational context for agents.\n\n### Listing Prompts\n\n```typescript filename=\"src/mastra/prompts.ts\"\nimport { mcp } from \"./mcp\";\n\n// Get prompts from all connected MCP servers\nconst prompts = await mcp.prompts.list();\n\n// Access prompts from a specific server\nif (prompts.weather) {\n  const prompt = prompts.weather.find(\n    (p) => p.name === \"current\"\n  );\n  console.log(`Prompt: ${prompt?.name}`);\n}\n```\n\nEach prompt has a name, description, and (optional) version.\n\n### Retrieving a Prompt and Its Messages\n\n```typescript filename=\"src/mastra/prompts.ts\"\nconst { prompt, messages } = await mcp.prompts.get({ serverName: \"weather\", name: \"current\" });\nconsole.log(prompt);    // { name: \"current\", version: \"v1\", ... }\nconsole.log(messages);  // [ { role: \"assistant\", content: { type: \"text\", text: \"...\" } }, ... ]\n```\n\n## Exposing Agents as Tools via MCPServer\n\nIn addition to using tools from MCP servers, your Mastra Agents themselves can be exposed as tools to any MCP-compatible client using Mastra's `MCPServer`.\n\nWhen an `Agent` instance is provided to an `MCPServer` configuration:\n\n- It is automatically converted into a callable tool.\n- The tool is named `ask_<agentKey>`, where `<agentKey>` is the identifier you used when adding the agent to the `MCPServer`'s `agents` configuration.\n- The agent's `description` property (which must be a non-empty string) is used to generate the tool's description.\n\nThis allows other AI models or MCP clients to interact with your Mastra Agents as if they were standard tools, typically by \"asking\" them a question.\n\n**Example `MCPServer` Configuration with an Agent:**\n\n```typescript filename=\"src/mastra/mcp.ts\"\nimport { Agent } from \"@mastra/core/agent\";\nimport { MCPServer } from \"@mastra/mcp\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { weatherInfo } from \"../tools/weatherInfo\";\nimport { generalHelper } from \"../agents/generalHelper\";\n\nconst server = new MCPServer({\n  name: \"My Custom Server with Agent-Tool\",\n  version: \"1.0.0\",\n  tools: {\n    weatherInfo,\n  },\n  agents: { generalHelper }, // Exposes 'ask_generalHelper' tool\n});\n```\n\nFor an agent to be successfully converted into a tool by `MCPServer`, its `description` property must be set to a non-empty string in its constructor configuration. If the description is missing or empty, `MCPServer` will throw an error during initialization.\n\nFor more details on setting up and configuring `MCPServer`, refer to the [MCPServer reference documentation](/reference/tools/mcp-server).\n\n\n---\ntitle: \"Using with Vercel AI SDK\"\ndescription: \"Learn how Mastra leverages the Vercel AI SDK library and how you can leverage it further with Mastra\"\n---\n\nimport Image from \"next/image\";\n\n# Using with Vercel AI SDK\n[EN] Source: https://mastra.ai/en/docs/frameworks/agentic-uis/ai-sdk\n\nMastra leverages AI SDK's model routing (a unified interface on top of OpenAI, Anthropic, etc), structured output, and tool calling.\n\nWe explain this in greater detail in [this blog post](https://mastra.ai/blog/using-ai-sdk-with-mastra)\n\n## Mastra + AI SDK\n\nMastra acts as a layer on top of AI SDK to help teams productionize their proof-of-concepts quickly and easily.\n\n<Image\n  src=\"/image/mastra-ai-sdk.png\"\n  alt=\"Agent interaction trace showing spans, LLM calls, and tool executions\"\n  style={{ maxWidth: \"800px\", width: \"100%\", margin: \"8px 0\" }}\n  className=\"nextra-image rounded-md py-8\"\n  data-zoom\n  width={800}\n  height={400}\n/>\n\n## Model routing\n\nWhen creating agents in Mastra, you can specify any AI SDK-supported model:\n\n```typescript\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"Instructions for the agent...\",\n  model: openai(\"gpt-4-turbo\"), // Model comes directly from AI SDK\n});\n\nconst result = await agent.generate(\"What is the weather like?\");\n```\n\n## AI SDK Hooks\n\nMastra is compatible with AI SDK's hooks for seamless frontend integration:\n\n### useChat\n\nThe `useChat` hook enables real-time chat interactions in your frontend application\n\n- Works with agent data streams i.e. `.toDataStreamResponse()`\n- The useChat `api` defaults to `/api/chat`\n- Works with the Mastra REST API agent stream endpoint `{MASTRA_BASE_URL}/agents/:agentId/stream` for data streams,\n  i.e. no structured output is defined.\n\n```typescript filename=\"app/api/chat/route.ts\" copy\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(messages);\n\n  return stream.toDataStreamResponse();\n}\n```\n\n```typescript copy\nimport { useChat } from '@ai-sdk/react';\n\nexport function ChatComponent() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}: {m.content}\n        </div>\n      ))}\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Say something...\"\n        />\n      </form>\n    </div>\n  );\n}\n```\n\n> **Gotcha**: When using `useChat` with agent memory functionality, make sure to check out the [Agent Memory section](/docs/agents/agent-memory#usechat) for important implementation details.\n\n### useCompletion\n\nFor single-turn completions, use the `useCompletion` hook:\n\n- Works with agent data streams i.e. `.toDataStreamResponse()`\n- The useCompletion `api` defaults to `/api/completion`\n- Works with the Mastra REST API agent stream endpoint `{MASTRA_BASE_URL}/agents/:agentId/stream` for data streams,\n  i.e. no structured output is defined.\n\n```typescript filename=\"app/api/completion/route.ts\" copy\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { prompt } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream([{ role: \"user\", content: prompt }]);\n\n  return stream.toDataStreamResponse();\n}\n```\n\n```typescript\nimport { useCompletion } from \"@ai-sdk/react\";\n\nexport function CompletionComponent() {\n  const {\n    completion,\n    input,\n    handleInputChange,\n    handleSubmit,\n  } = useCompletion({\n  api: '/path-to-your-agent-stream-api-endpoint'\n  });\n\n  return (\n    <div>\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={handleInputChange}\n          placeholder=\"Enter a prompt...\"\n        />\n      </form>\n      <p>Completion result: {completion}</p>\n    </div>\n  );\n}\n```\n\n### useObject\n\nFor consuming text streams that represent JSON objects and parsing them into a complete object based on a schema.\n\n- Works with agent text streams i.e. `.toTextStreamResponse()`\n- Works with the Mastra REST API agent stream endpoint `{MASTRA_BASE_URL}/agents/:agentId/stream` for text streams,\n  i.e. structured output is defined.\n\n```typescript filename=\"app/api/use-object/route.ts\" copy\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const body = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  const stream = await myAgent.stream(body, {\n    output: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return stream.toTextStreamResponse();\n}\n```\n\n```typescript\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\n\nexport default function Page() {\n  const { object, submit } = useObject({\n    api: '/api/use-object',\n    schema: z.object({\n      weather: z.string(),\n    }),\n  });\n\n  return (\n    <div>\n      <button onClick={() => submit('example input')}>Generate</button>\n      {object?.weather && <p>{object.weather}</p>}\n    </div>\n  );\n}\n```\n\n### With additional data / RuntimeContext\n\nYou can send additional data via the UI hooks that can be leveraged in Mastra as RuntimeContext using the `sendExtraMessageFields` option.\n\n#### Frontend: Using sendExtraMessageFields\n\n```typescript\nimport { useChat } from '@ai-sdk/react';\n\nexport function ChatComponent() {\n  const { messages, input, handleInputChange, handleSubmit } = useChat({\n    api: '/api/chat',\n    sendExtraMessageFields: true, // Enable sending extra fields\n  });\n\n  const handleFormSubmit = (e: React.FormEvent) => {\n        e.preventDefault();        \n        handleSubmit(e,{\n            // Add context data to the message\n            data: {\n                userId: 'user123',\n                preferences: { language: 'en', temperature: 'celsius' },\n            },\n        });\n  };\n\n  return (\n    <form onSubmit={handleFormSubmit}>\n      <input value={input} onChange={handleInputChange} />\n    </form>\n  );\n}\n```\n\n#### Backend: Handling in API Route\n\n```typescript filename=\"app/api/chat/route.ts\" copy\nimport { mastra } from \"@/src/mastra\";\nimport { RuntimeContext } from \"@mastra/core/runtime-context\";\n\nexport async function POST(req: Request) {\n  const { messages, data } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  \n  const runtimeContext = new RuntimeContext();\n  \n  if (data) {\n    Object.entries(data).forEach(([key, value]) => {\n      runtimeContext.set(key, value);\n    });\n  }\n  \n  const stream = await myAgent.stream(messages, { runtimeContext });\n  return stream.toDataStreamResponse();\n}\n```\n\n#### Alternative: Server Middleware\n\nYou can also handle this at the server middleware level:\n\n```typescript filename=\"src/mastra/index.ts\" copy\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const runtimeContext = c.get(\"runtimeContext\");\n        \n        if (c.req.method === 'POST') {\n          try {\n            // Clone the request since reading the body can only be done once\n            const clonedReq = c.req.raw.clone();\n            const body = await clonedReq.json();\n            \n            \n            if (body?.data) {\n              Object.entries(body.data).forEach(([key, value]) => {\n                runtimeContext.set(key, value);\n              });\n            }\n          } catch {\n            // Continue without additional data\n          }\n        }\n        \n        await next();\n      },\n    ],\n  },\n});\n```\n\nYou can then access this data in your tools via the `runtimeContext` parameter. See the [Runtime Context documentation](/docs/agents/runtime-variables) for more details.\n\n## Tool Calling\n\n### AI SDK Tool Format\n\nMastra supports tools created using the AI SDK format, so you can use\nthem directly with Mastra agents. See our tools doc on [Vercel AI SDK Tool Format\n](/docs/agents/adding-tools#vercel-ai-sdk-tool-format) for more details.\n\n### Client-side tool calling\n\nMastra leverages AI SDK's tool calling, so what applies in AI SDK applies here still.\n[Agent Tools](/docs/agents/adding-tools) in Mastra are 100% percent compatible with AI SDK tools.\n\nMastra tools also expose an optional `execute` async function. It is optional because you might want to forward tool calls to the client or to a queue instead of executing them in the same process.\n\nOne way to then leverage client-side tool calling is to use the `@ai-sdk/react` `useChat` hook's `onToolCall` property for\nclient-side tool execution\n\n## Custom DataStream\n\nIn certain scenarios you need to write custom data, message annotations to an agent's dataStream.\nThis can be useful for:\n\n- Streaming additional data to the client\n- Passing progress info back to the client in real time\n\nMastra integrates well with AI SDK to make this possible\n\n### CreateDataStream\n\nThe `createDataStream` function allows you to stream additional data to the client\n\n```typescript copy\nimport { createDataStream } from \"ai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nexport const weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `\n          You are a helpful weather assistant that provides accurate weather information.\n\n          Your primary function is to help users get weather details for specific locations. When responding:\n          - Always ask for a location if none is provided\n          - If the location name isn't in English, please translate it\n          - If giving a location with multiple parts (e.g. \"New York, NY\"), use the most relevant part (e.g. \"New York\")\n          - Include relevant details like humidity, wind conditions, and precipitation\n          - Keep responses concise but informative\n\n          Use the weatherTool to fetch current weather data.\n    `,\n  model: openai(\"gpt-4o\"),\n  tools: { weatherTool },\n});\n\nconst stream = createDataStream({\n  async execute(dataStream) {\n    // Write data\n    dataStream.writeData({ value: \"Hello\" });\n\n    // Write annotation\n    dataStream.writeMessageAnnotation({ type: \"status\", value: \"processing\" });\n\n    //mastra agent stream\n    const agentStream = await weatherAgent.stream(\"What is the weather\");\n\n    // Merge agent stream\n    agentStream.mergeIntoDataStream(dataStream);\n  },\n  onError: (error) => `Custom error: ${error.message}`,\n});\n```\n\n### CreateDataStreamResponse\n\nThe `createDataStreamResponse` function creates a Response object that streams data to the client\n\n```typescript filename=\"app/api/chat/route.ts\" copy\nimport { mastra } from \"@/src/mastra\";\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const myAgent = mastra.getAgent(\"weatherAgent\");\n  //mastra agent stream\n  const agentStream = await myAgent.stream(messages);\n\n  const response = createDataStreamResponse({\n    status: 200,\n    statusText: \"OK\",\n    headers: {\n      \"Custom-Header\": \"value\",\n    },\n    async execute(dataStream) {\n      // Write data\n      dataStream.writeData({ value: \"Hello\" });\n\n      // Write annotation\n      dataStream.writeMessageAnnotation({\n        type: \"status\",\n        value: \"processing\",\n      });\n\n      // Merge agent stream\n      agentStream.mergeIntoDataStream(dataStream);\n    },\n    onError: (error) => `Custom error: ${error.message}`,\n  });\n\n  return response;\n}\n```\n\n\n---\ntitle: Using with Assistant UI\ndescription: \"Learn how to integrate Assistant UI with Mastra\"\n---\n\nimport { Callout, FileTree, Steps } from 'nextra/components'\n\n# Using with Assistant UI\n[EN] Source: https://mastra.ai/en/docs/frameworks/agentic-uis/assistant-ui\n\n[Assistant UI](https://assistant-ui.com) is the TypeScript/React library for AI Chat.\nBuilt on shadcn/ui and Tailwind CSS, it enables developers to create beautiful, enterprise-grade chat experiences in minutes.\n\n<Callout type=\"info\">\nFor a full-stack integration approach where Mastra runs directly in your Next.js API routes, see the [Full-Stack Integration Guide](https://www.assistant-ui.com/docs/runtimes/mastra/full-stack-integration) on Assistant UI's documentation site.\n</Callout>\n\n## Integration Guide\n\nRun Mastra as a standalone server and connect your Next.js frontend (with Assistant UI) to its API endpoints.\n\n<Steps>\n### Create Standalone Mastra Server\n\nSet up your directory structure. A possible directory structure could look like this:\n\n<FileTree>\n    <FileTree.Folder name=\"project-root\" defaultOpen>\n        <FileTree.Folder name=\"mastra-server\" defaultOpen>\n            <FileTree.Folder name=\"src\">\n                <FileTree.Folder name=\"mastra\" />\n            </FileTree.Folder>\n            <FileTree.File name=\"package.json\" />\n        </FileTree.Folder>\n        <FileTree.Folder name=\"nextjs-frontend\">\n            <FileTree.File name=\"package.json\" />\n        </FileTree.Folder>\n    </FileTree.Folder>\n</FileTree>\n\nBootstrap your Mastra server:\n\n```bash copy\nnpx create-mastra@latest\n```\n\nThis command will launch an interactive wizard to help you scaffold a new Mastra project, including prompting you for a project name and setting up basic configurations.\nFollow the prompts to create your server project.\n\nYou now have a basic Mastra server project ready. You should have the following files and folders:\n\n<FileTree>\n    <FileTree.Folder name=\"src\" defaultOpen>\n      <FileTree.Folder name=\"mastra\" defaultOpen>\n        <FileTree.File name=\"index.ts\" />\n        <FileTree.Folder name=\"agents\" defaultOpen>\n          <FileTree.File name=\"weather-agent.ts\" />\n        </FileTree.Folder>\n        <FileTree.Folder name=\"tools\" defaultOpen>\n          <FileTree.File name=\"weather-tool.ts\" />\n        </FileTree.Folder>\n        <FileTree.Folder name=\"workflows\" defaultOpen>\n          <FileTree.File name=\"weather-workflow.ts\" />\n        </FileTree.Folder>\n      </FileTree.Folder>\n    </FileTree.Folder>\n</FileTree>\n\n<Callout>\nEnsure that you have set the appropriate environment variables for your LLM provider in the `.env` file.\n</Callout>\n\n### Compatibility Fix\n\nCurrently, to ensure proper compatibility between Mastra and Assistant UI, you need to setup server middleware. Update your `/mastra/index.ts` file with the following configuration:\n\n```typescript showLineNumbers copy filename=\"src/mastra/index.ts\"\nexport const mastra = new Mastra({\n  //mastra server middleware\n  server:{\n  middleware: [{\n    path: '/api/agents/*/stream',\n    handler: async (c,next)=>{\n    \n      const body = await c.req.json();\n  \n      if ('state' in body && body.state == null) {\n        delete body.state;\n        delete body.tools;\n      }\n  \n       c.req.json = async() => body;\n  \n      return next()\n    }\n  }]\n },\n});\n```\n\nThis middleware ensures that when Assistant UI sends a request with `state: null` and `tools: {}` in the request body, we remove those properties to make the request work properly with Mastra.\n\n<Callout type=\"info\">\nThe `state: null` property can cause errors like `Cannot use 'in' operator to search for 'input' in null` in Mastra. Additionally, passing `tools: {}` overrides Mastra's built-in tools. Mastra only supports `clientTools` via the Mastra client SDK from the client side. For more information about client tools, see the [Client Tools documentation](/reference/client-js/agents#client-tools).\n</Callout>\n\n### Run the Mastra Server\n\nRun the Mastra server using the following command:\n\n```bash copy\nnpm run dev\n```\n\nBy default, the Mastra server will run on `http://localhost:5000`. Your `weatherAgent` should now be accessible via a POST request endpoint, typically `http://localhost:5000/api/agents/weatherAgent/stream`. Keep this server running for the next steps where we'll set up the Assistant UI frontend to connect to it.\n\n### Initialize Assistant UI\n\nCreate a new `assistant-ui` project with the following command.\n\n```bash copy\nnpx assistant-ui@latest create\n```\n\n<Callout>For detailed setup instructions, including adding API keys, basic configuration, and manual setup steps, please refer to [assistant-ui's official documentation](https://assistant-ui.com/docs).</Callout>\n\n### Configure Frontend API Endpoint\n\nThe default Assistant UI setup configures the chat runtime to use a local API route (`/api/chat`) within the Next.js project. Since our Mastra agent is running on a separate server, we need to update the frontend to point to that server's endpoint.\n\nFind the `useChatRuntime` hook in the `assistant-ui` project, typically at `app/assistant.tsx` and change the `api` property to the full URL of your Mastra agent's stream endpoint:\n\n```typescript showLineNumbers copy filename=\"app/assistant.tsx\" {2}\nconst runtime = useChatRuntime({\n    api: \"http://localhost:5000/api/agents/weatherAgent/stream\",\n});\n```\n\nNow, the Assistant UI frontend will send chat requests directly to your running Mastra server.\n\n### Run the Application\n\nYou're ready to connect the pieces! Make sure both the Mastra server and the Assistant UI frontend are running. Start the Next.js development server:\n\n```bash copy\nnpm run dev\n```\n\nYou should now be able to chat with your agent in the browser.\n\n</Steps>\n\nCongratulations! You have successfully integrated Mastra with Assistant UI using a separate server approach. Your Assistant UI frontend now communicates with a standalone Mastra agent server.\n\n\n---\ntitle: \"Using with CopilotKit\"\ndescription: \"Learn how Mastra leverages the CopilotKit's AGUI library and how you can leverage it to build user experiences\"\n---\n\nimport { Tabs } from \"nextra/components\";\nimport Image from \"next/image\";\n\n# Using with CopilotKit in React\n[EN] Source: https://mastra.ai/en/docs/frameworks/agentic-uis/copilotkit\n\nCopilotKit provides React components to quickly integrate customizable AI copilots into your application.\nCombined with Mastra, you can build sophisticated AI apps featuring bidirectional state synchronization and interactive UIs.\n\n## Create a Mastra Project\n{/*\nLLM CONTEXT:\nThis Tabs component shows commands for creating a new Mastra project using different package managers.\nEach tab displays the command for that specific package manager to create a Mastra project.\nThis is the first step in setting up Mastra with CopilotKit for building AI copilot applications.\nAll commands create the same Mastra project but use different package manager syntax.\n*/}\n\n<Tabs items={[\"npx\", \"npm\", \"yarn\", \"pnpm\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npx create-mastra@latest\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    npm create mastra\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    yarn create mastra\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    pnpm create mastra\n    ```\n  </Tabs.Tab>\n</Tabs>\n\n\nSelect the agent example when scaffolding your project. This will give you a weather agent.\n\nFor detailed setup instructions, see the [installation guide](/docs/getting-started/installation).\n\n## Basic Setup\n\nIntegrating Mastra with CopilotKit involves two main steps: setting up the backend runtime and configuring your frontend components.\n{/*\nLLM CONTEXT: This Tabs component shows installation commands for the CopilotKit runtime package.\nEach tab displays the installation command for that specific package manager.\nThis installs the core CopilotKit runtime needed for backend integration with Mastra.\nAll commands install the same @copilotkit/runtime package but use different package manager syntax.\n*/}\n\n<Tabs items={[\"npm\", \"yarn\", \"pnpm\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npm install @copilotkit/runtime\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    yarn add @copilotkit/runtime\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    pnpm add @copilotkit/runtime\n    ```\n  </Tabs.Tab>\n</Tabs>\n\n## Set up the runtime\n\nYou can leverage Mastra's custom API routes to add CopilotKit's runtime to your Mastra server.\n\nThe current version of the integration leverages `MastraClient` to format Mastra agents into the AGUI format of CopilotKit.\n\n{/*\nLLM CONTEXT: This Tabs component shows installation commands for the Mastra AGUI package.\nEach tab displays the installation command for that specific package manager.\nThis installs the alpha version of @ag-ui/mastra which provides CopilotKit integration capabilities.\nAll commands install the same @ag-ui/mastra package but use different package manager syntax.\n*/}\n\n<Tabs items={[\"npm\", \"yarn\", \"pnpm\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npm install @ag-ui/mastra\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    yarn add @ag-ui/mastra\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    pnpm add @ag-ui/mastra\n    ```\n  </Tabs.Tab>\n</Tabs>\n\nNext, let's update the Mastra instance with a custom API route for CopilotKit.\n\n```typescript filename=\"src/mastra/index.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { PinoLogger } from \"@mastra/loggers\";\nimport { LibSQLStore } from \"@mastra/libsql\";\nimport { CopilotRuntime, copilotRuntimeNodeHttpEndpoint, ExperimentalEmptyAdapter } from \"@copilotkit/runtime\";\nimport { registerCopilotKit } from \"@ag-ui/mastra\";\nimport { weatherAgent } from \"./agents/weather-agent\";\n\nconst serviceAdapter = new ExperimentalEmptyAdapter();\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n  storage: new LibSQLStore({\n    // stores telemetry, evals, ... into memory storage,\n    // if you need to persist, change to file:../mastra.db\n    url: \":memory:\"\n  }),\n  logger: new PinoLogger({\n    name: \"Mastra\",\n    level: \"info\"\n  }),\n  server: {\n    // We will be calling this from a Vite App. Allow CORS\n    cors: {\n      origin: \"*\",\n      allowMethods: [\"*\"],\n      allowHeaders: [\"*\"]\n    },\n    apiRoutes: [\n      registerCopilotKit({\n        path: \"/copilotkit\",\n        resourceId: \"weatherAgent\",\n        setContext: (c, runtimeContext) => {\n          // Add whatever you need to the runtimeContext\n          runtimeContext.set(\"user-id\", c.req.header(\"X-User-ID\"));\n          runtimeContext.set(\"temperature-scale\", \"celsius\");\n        }\n      })\n    ]\n  }\n});\n```\n\nWith this setup you now have CopilotKit running on your Mastra server. You can start your Mastra server with `mastra dev`.\n\n## Set up the UI\n\nInstall CopilotKit's React components:\n{/*\nLLM CONTEXT: This Tabs component shows installation commands for CopilotKit's React UI components.\nEach tab displays the installation command for that specific package manager.\nThis installs the React components needed for the frontend CopilotKit integration.\nAll commands install the same @copilotkit/react-core and @copilotkit/react-ui packages but use different package manager syntax.\n*/}\n\n<Tabs items={[\"npm\", \"yarn\", \"pnpm\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npm install @copilotkit/react-core @copilotkit/react-ui\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    yarn add @copilotkit/react-core @copilotkit/react-ui\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    pnpm add @copilotkit/react-core @copilotkit/react-ui\n    ```\n  </Tabs.Tab>\n</Tabs>\n\nNext, add CopilotKit's React components to your frontend.\n\n```jsx copy\nimport { CopilotChat } from \"@copilotkit/react-ui\";\nimport { CopilotKit } from \"@copilotkit/react-core\";\nimport \"@copilotkit/react-ui/styles.css\";\n\nexport function CopilotKitComponent() {\n  return (\n    <CopilotKit\n      runtimeUrl=\"http://localhost:5000/copilotkit\"\n      agent=\"weatherAgent\"\n    >\n      <CopilotChat\n        labels={{\n          title: \"Your Assistant\",\n          initial: \"Hi! ðŸ‘‹ How can I assist you today?\",\n        }}\n      />\n    </CopilotKit>\n  );\n}\n```\n\nRender the component and start building the future!\n\n<br />\n\n<Image\n  className=\"rounded-lg\"\n  src=\"/image/copilotkit/cpkoutput.jpg\"\n  alt=\"CopilotKit output\"\n  width={700}\n  height={700}\n/>\n\n## Using with other frameworks (NextJS)\n\nYou can still leverage AGUI without going through Mastra Server.\n\n```typescript copy\n// import your mastra instance from dir\nimport { mastra } from \"../path/to/mastra\";\nimport {\n  CopilotRuntime,\n  ExperimentalEmptyAdapter,\n  copilotRuntimeNextJSAppRouterEndpoint,\n} from \"@copilotkit/runtime\";\nimport { NextRequest } from \"next/server\";\nimport { MastraAgent } from \"@ag-ui/mastra\";\n\nexport const POST = async (req: NextRequest) => {\n  // Clone the request before reading the body\n  const clonedReq = req.clone();\n  const body = await clonedReq.json();\n  const resourceId = body.resourceId || \"TEST\";\n\n  const mastraAgents = MastraAgent.getLocalAgents({\n    resourceId,\n    mastra,\n    runtimeContext,\n  });\n\n  const runtime = new CopilotRuntime({\n    agents: mastraAgents,\n  });\n\n  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({\n    runtime,\n    serviceAdapter: new ExperimentalEmptyAdapter(),\n    endpoint: \"/api/copilotkit\",\n  });\n\n  // Use the original request for handleRequest\n  return handleRequest(req);\n};\n```\n\n## Using with Mastra Client SDK\n\n```typescript copy\nimport { MastraClient } from \"@mastra/client-js\";\nimport {\n  CopilotRuntime,\n  ExperimentalEmptyAdapter,\n  copilotRuntimeNextJSAppRouterEndpoint,\n} from \"@copilotkit/runtime\";\nimport { NextRequest } from \"next/server\";\nimport { MastraAgent } from \"@ag-ui/mastra\";\n\nexport const POST = async (req: NextRequest) => {\n  // Clone the request before reading the body\n  const clonedReq = req.clone();\n  const body = await clonedReq.json();\n  const resourceId = body.resourceId || \"TEST\";\n\n  const baseUrl = process.env.MASTRA_BASE_URL || \"http://localhost:5000\";\n  const mastraClient = new MastraClient({\n    baseUrl,\n  });\n\n  const mastraAgents = await MastraAgent.getRemoteAgents({ mastraClient });\n\n  const runtime = new CopilotRuntime({\n    agents: mastraAgents,\n  });\n\n  const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({\n    runtime,\n    serviceAdapter: new ExperimentalEmptyAdapter(),\n    endpoint: \"/api/copilotkit\",\n  });\n\n  // Use the original request for handleRequest\n  return handleRequest(req);\n};\n```\n\n\n## Using Typed Runtime Context\n\nFor better type safety, you can specify the type of your runtime context:\n\n```typescript filename=\"src/mastra/index.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { PinoLogger } from \"@mastra/loggers\";\nimport { LibSQLStore } from \"@mastra/libsql\";\nimport { registerCopilotKit } from \"@ag-ui/mastra\";\nimport { weatherAgent } from \"./agents\";\n\n// Define your runtime context type\ntype WeatherRuntimeContext = {\n  \"user-id\": string;\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\";\n  \"api-key\": string;\n};\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent },\n  storage: new LibSQLStore({\n    url: \":memory:\",\n  }),\n  logger: new PinoLogger({\n    name: \"Mastra\",\n    level: \"info\",\n  }),\n  server: {\n    cors: {\n      origin: \"*\",\n      allowMethods: [\"*\"],\n      allowHeaders: [\"*\"],\n    },\n    apiRoutes: [\n      registerCopilotKit<WeatherRuntimeContext>({\n        path: \"/copilotkit\",\n        resourceId: \"weatherAgent\",\n        setContext: (c, runtimeContext) => {\n          // TypeScript will enforce the correct types here\n          runtimeContext.set(\"user-id\", c.req.header(\"X-User-ID\") || \"anonymous\");\n          runtimeContext.set(\"temperature-scale\", \"celsius\"); // Only \"celsius\" | \"fahrenheit\" allowed\n          runtimeContext.set(\"api-key\", process.env.WEATHER_API_KEY || \"\");\n\n          // This would cause a TypeScript error:\n          // runtimeContext.set(\"invalid-key\", \"value\"); // âŒ Error: invalid key\n          // runtimeContext.set(\"temperature-scale\", \"kelvin\"); // âŒ Error: invalid value\n        }\n      }),\n    ],\n  },\n});\n```\n\n## Further Reading\n\n- [CopilotKit Documentation](https://docs.copilotkit.ai)\n- [React Hooks with CopilotKit](https://docs.copilotkit.ai/reference/hooks/useCoAgent)\n\n\n---\ntitle: \"Using with OpenRouter\"\ndescription: \"Learn how to integrate OpenRouter with Mastra\"\n---\n\nimport { Steps } from 'nextra/components'\n\n# Use OpenRouter with Mastra\n[EN] Source: https://mastra.ai/en/docs/frameworks/agentic-uis/openrouter\n\nIntegrate OpenRouter with Mastra to leverage the numerous models available on OpenRouter.\n\n<Steps>\n## Initialize a Mastra Project\n\nThe simplest way to get started with Mastra is to use the `mastra` CLI to initialize a new project:\n\n```bash copy\nnpx create-mastra@latest\n```\n\nYou'll be guided through prompts to set up your project. For this example, select:\n- Name your project: my-mastra-openrouter-app\n- Components: Agents (recommended)\n- For default provider, select OpenAI (recommended) - we'll configure OpenRouter manually later\n- Optionally include example code\n\n## Configure OpenRouter\n\nAfter creating your project with `create-mastra`, you'll find a `.env` file in your project root.\nSince we selected OpenAI during setup, we'll configure OpenRouter manually: \n\n```bash filename=\".env\" copy\nOPENROUTER_API_KEY=\n```\n\nWe remove the `@ai-sdk/openai` package from the project:\n\n```bash copy\nnpm uninstall @ai-sdk/openai\n```\n\nThen, we install the `@openrouter/ai-sdk-provider` package:\n\n```bash copy\nnpm install @openrouter/ai-sdk-provider\n```\n\n## Configure your Agent to use OpenRouter\n\nWe will now configure our agent to use OpenRouter.\n\n```typescript filename=\"src/mastra/agents/assistant.ts\" copy showLineNumbers {4-6,11}\nimport { Agent } from \"@mastra/core/agent\";\nimport { createOpenRouter } from \"@openrouter/ai-sdk-provider\";\n\nconst openrouter = createOpenRouter({\n    apiKey: process.env.OPENROUTER_API_KEY,\n})\n\nexport const assistant = new Agent({\n    name: \"assistant\",\n    instructions: \"You are a helpful assistant.\",\n    model: openrouter(\"anthropic/claude-sonnet-4\"),\n})\n```\n\nMake sure to register your agent to the Mastra instance:\n\n```typescript filename=\"src/mastra/index.ts\" copy showLineNumbers {4}\nimport { assistant } from \"./agents/assistant\";\n\nexport const mastra = new Mastra({\n    agents: { assistant }\n})\n```\n\n## Run and Test your Agent\n\n```bash copy\nnpm run dev\n```\n\nThis will start the Mastra development server.\n\nYou can now test your agent by visiting [http://localhost:5000](http://localhost:5000) for the playground or via the Mastra API at [http://localhost:5000/api/agents/assistant/stream](http://localhost:5000/api/agents/assistant/stream).\n\n</Steps>\n\n## Advanced Configuration\n\nFor more control over your OpenRouter requests, you can pass additional configuration options.\n\n### Provider-wide options:\n\nYou can pass provider-wide options to the OpenRouter provider:\n\n```typescript filename=\"src/mastra/agents/assistant.ts\" {6-10} copy showLineNumbers\nimport { Agent } from \"@mastra/core/agent\";\nimport { createOpenRouter } from \"@openrouter/ai-sdk-provider\";\n\nconst openrouter = createOpenRouter({\n    apiKey: process.env.OPENROUTER_API_KEY,\n    extraBody: {\n        reasoning: {\n            max_tokens: 10,\n        }\n    }\n})\n\nexport const assistant = new Agent({\n    name: \"assistant\",\n    instructions: \"You are a helpful assistant.\",\n    model: openrouter(\"anthropic/claude-sonnet-4\"),\n})\n```\n\n### Model-specific options:\n\nYou can pass model-specific options to the OpenRouter provider:\n\n```typescript filename=\"src/mastra/agents/assistant.ts\" {11-17} copy showLineNumbers\nimport { Agent } from \"@mastra/core/agent\";\nimport { createOpenRouter } from \"@openrouter/ai-sdk-provider\";\n\nconst openrouter = createOpenRouter({\n    apiKey: process.env.OPENROUTER_API_KEY,\n})\n\nexport const assistant = new Agent({\n    name: \"assistant\",\n    instructions: \"You are a helpful assistant.\",\n    model: openrouter(\"anthropic/claude-sonnet-4\", {\n        extraBody: {\n            reasoning: {\n                max_tokens: 10,\n            }\n        }\n    }),\n})\n```\n\n### Provider-specific options:\n\nYou can pass provider-specific options to the OpenRouter provider:\n\n```typescript copy showLineNumbers {7-12}\n// Get a response with provider-specific options\nconst response = await assistant.generate([\n  {\n    role: 'system',\n    content:\n      'You are Chef Michel, a culinary expert specializing in ketogenic (keto) diet...',\n    providerOptions: {\n      // Provider-specific options - key can be 'anthropic' or 'openrouter'\n      anthropic: {\n        cacheControl: { type: 'ephemeral' },\n      },\n    },\n  },\n  {\n    role: 'user',\n    content: 'Can you suggest a keto breakfast?',\n  },\n]);\n```\n\n\n# AI SDK v5 (beta) Migration Guide\n[EN] Source: https://mastra.ai/en/docs/frameworks/ai-sdk-v5\n\nThis guide covers Mastra-specific considerations when migrating from AI SDK v4 to v5 beta.\n\nPlease add any feedback or bug reports to the [AI SDK v5 mega issue in Github.](https://github.com/mastra-ai/mastra/issues/5470)\n\n## Official Migration Guide\n\n**Follow the official [AI SDK v5 Migration Guide](https://v5.ai-sdk.dev/docs/migration-guides/migration-guide-5-0)** for all AI SDK core breaking changes, package updates, and API changes.\n\nThis guide covers only the Mastra-specific aspects of the migration.\n\n## Warnings\n\n- **Data compatibility**: New data stored in v5 format will no longer work if you downgrade from the beta\n- **Backup recommendation**: Keep DB backups from before you upgrade to v5 beta\n- **Production use**: Wait for the AI SDK v5 stable release before using in production applications\n- **Prerelease status**: The Mastra `ai-v5` tag is a prerelease version and may have bugs\n\n## Memory Storage\n\nYour existing AI SDK v4 data will run through our internal `MessageList` class which handles converting to/from various message formats.\nThis includes converting from AI SDK v4->v5. This means you don't need to run any DB migrations and your data will be translated on the fly and will just work when you upgrade.\n\n\n## Migration Strategy\n\nMigrating to AI SDK v5 with Mastra involves updating both your **backend** (Mastra server) and **frontend**.\nWe provide a compatibility mode to handle stream format conversion during the transition.\n\n### Backend Upgrade\n\nBump Mastra to the new `ai-v5` prerelease version for all Mastra packages:\n\n```bash npm2yarn copy\nnpm i mastra@ai-v5 @mastra/core@ai-v5 @mastra/memory@ai-v5 [etc]\n```\n\nThen configure your Mastra instance with v4 compatibility so your existing frontend will continue to work:\n\n```typescript\nimport { Mastra } from '@mastra/core';\n\nexport const mastra = new Mastra({\n  agents: { myAgent },\n  aiSdkCompat: 'v4', // <- add this for compatibility\n});\n```\n\n#### Dependencies\n\nYou will need to upgrade all AI SDK dependencies to use the new v5 beta versions in your backend when you bump to the Mastra `ai-v5` prerelease tag.\n\nIn most cases this will only involve bumping your model provider packages. For example: `npm i @ai-sdk/openai@2.0.0-beta.1` - refer to the [AI SDK v5 documentation](https://v5.ai-sdk.dev/docs/migration-guides/migration-guide-5-0) for more info. Some model providers do not yet have V5 versions (Openrouter for example).\n\nAlso note that you need to bump all your Mastra dependencies to the new `ai-v5` tag, and you must upgrade `zod` to the latest version if you have it installed.\n\n#### Using Stream Compatibility Manually\n\nIf you have a frontend that calls Mastra agents in an endpoint, you can wrap the new `response.toUIMessageStreamResponse()` manually.\n\n```ts\nimport { mastra } from \"@/src/mastra\";\nimport { createV4CompatibleResponse } from \"@mastra/core/agent\";\n\nconst myAgent = mastra.getAgent(\"weatherAgent\");\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const stream = await myAgent.stream(messages);\n\n  return createV4CompatibleResponse(stream.toUIMessageStreamResponse().body!);\n}\n```\n\n### Using Mastra Playground\n\nCurrently playground is still an AI SDK v4 frontend. For now you need to set `aiSdkCompat: 'v4'` for it to work.\nWe'll handle this automatically for you soon.\n\n### Frontend Upgrade\n\nWhen you're ready, remove the compatibility flag and upgrade your frontend:\n\n1. Remove `aiSdkCompat: 'v4'` from your Mastra configuration\n2. Follow the AI SDK guide on upgrading your frontend dependencies\n3. Update your frontend code for v5 breaking changes\n\n## Discussion and Bug Reports\n\nPlease add any feedback or bug reports to the [AI SDK v5 mega issue in Github.](https://github.com/mastra-ai/mastra/issues/5470)\n\n\n\n---\ntitle: \"Getting started with Mastra and Express | Mastra Guides\"\ndescription: A step-by-step guide to integrating Mastra with an Express backend.\n---\n\nimport { Callout, Steps, Tabs, FileTree } from \"nextra/components\";\n\n# Integrate Mastra in your Express project\n[EN] Source: https://mastra.ai/en/docs/frameworks/servers/express\n\nMastra integrates with Express, making it easy to:\n\n- Build flexible APIs to serve AI-powered features\n- Maintain full control over your server logic and routing\n- Scale your backend independently of your frontend\n\nUse this guide to scaffold and integrate Mastra with your Express project.\n\n<Callout type=\"warning\">\nThis setup is compatible with the following package versions:\n- `express`: 4.x\n- `@types/express`: 4.x\n\nType compatibility in 5.x can be inconsistent while `express` and `@types/express` evolve toward alignment.\n\n</Callout>\n\n<Steps>\n## Install Mastra\n\nInstall the required Mastra packages:\n\n<Tabs items={[\"npm\", \"yarn\", \"pnpm\", \"bun\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npm install mastra@latest @mastra/core@latest @mastra/libsql@latest\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    yarn add mastra@latest @mastra/core@latest @mastra/libsql@latest\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    pnpm add mastra@latest @mastra/core@latest @mastra/libsql@latest\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    bun add mastra@latest @mastra/core@latest @mastra/libsql@latest\n    ```\n  </Tabs.Tab>\n</Tabs>\n\n## Integrate Mastra\n\nTo integrate Mastra in your project, you have two options:\n\n### 1. Use the One-Liner\n\nRun the following command to quickly scaffold the default Weather agent with sensible defaults:\n\n```bash copy\nnpx mastra@latest init --default\n```\n\n> See [mastra init](/reference/cli/init) for more information.\n\n### 2. Use the Interactive CLI\n\nIf you prefer to customize the setup, run the `init` command and choose from the options when prompted:\n\n```bash copy\nnpx mastra@latest init\n```\n\nAdd the `dev` and `build` scripts to `package.json`:\n\n```json filename=\"package.json\"\n{\n  \"scripts\": {\n    ...\n    \"dev\": \"mastra dev\",\n    \"build\": \"mastra build\"\n  }\n}\n```\n\n> If your project already uses `dev` and `build` scripts, we recommend using: `dev:mastra` and `build:mastra`.\n\n## Initialize TypeScript\n\nCreate a `tsconfig.json` file in your project root with the following configuration:\n\n```json filename=\"tsconfig.json\" copy\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"outDir\": \"dist\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \".mastra\"]\n}\n```\n\n> This TypeScript configuration is optimized for Mastra projects, using modern module resolution and strict type checking.\n\n## Set Up API Key\n\n```bash filename=\".env\" copy\nOPENAI_API_KEY=<your-api-key>\n```\n\n> Each llm provider uses a different env var. See [Model Capabilities](/docs/getting-started/model-capability) for more information.\n\n## Start the Mastra Dev Server\n\nStart the Mastra dev server to expose your agents as REST endpoints:\n\n<Tabs items={[\"npm\", \"CLI\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    npm run dev\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    mastra dev\n    ```\n  </Tabs.Tab>\n</Tabs>\n\n> Once running, your agents are available locally. See [Local Development Environment](/docs/server-db/local-dev-playground) for more information.\n\n## Example Express App\n\nThis example creates an `/api/weather` endpoint that expects a `city` query parameter.\n\n```typescript filename=\"src/server.ts\" showLineNumbers copy\nimport \"dotenv/config\";\nimport express, { Request, Response } from \"express\";\n\nimport { mastra } from \"./mastra\";\n\nconst app = express();\nconst port = process.env.PORT ?? 3000;\n\napp.get(\"/api/weather\", async (req: Request, res: Response) => {\n  const { city } = req.query as { city?: string };\n\n  if (!city) {\n    return res.status(400).send(\"Missing 'city' query parameter\");\n  }\n\n  const agent = mastra.getAgent(\"weatherAgent\");\n\n  try {\n    const result = await agent.generate(`What's the weather like in ${city}?`);\n    res.send(result.text);\n  } catch (error) {\n    console.error(\"Agent error:\", error);\n    res.status(500).send(\"An error occurred while processing your request\");\n  }\n});\n\napp.listen(port, () => {\n  console.log(`Server listening on port ${port}`);\n});\n```\n\nWith the Mastra dev server running, start your Express app separately. For example:\n\n```bash copy\nnpx tsx --watch src/server.ts --watch-dir src\n```\n\nYou can now make a request to the endpoint using one of the following:\n\n<Tabs items={[\"http\", \"curl\"]}>\n  <Tabs.Tab>\n    ```bash copy\n    http://localhost:3000/api/weather?city=London\n    ```\n  </Tabs.Tab>\n  <Tabs.Tab>\n    ```bash copy\n    curl \"http://localhost:3000/api/weather?city=London\"\n    ```\n  </Tabs.Tab>\n</Tabs>\n\nYou should see output similar to the below:\n\n```plaintext\nThe current weather in London is as follows:\n\n- **Temperature:** 12.9Â°C (Feels like 9.7Â°C)\n- **Humidity:** 63%\n- **Wind Speed:** 14.7 km/h\n- **Wind Gusts:** 32.4 km/h\n- **Conditions:** Overcast\n\nLet me know if you need more information!\n```\n\n</Steps>\n\n## Next Steps\n\n- [Mastra Client SDK](/docs/deployment/client)\n\n\n---\ntitle: \"Installing Mastra | Getting Started | Mastra Docs\"\ndescription: Guide on installing Mastra and setting up the necessary prerequisites for running it with various LLM providers.\n---\n\nimport { Callout, Steps } from \"nextra/components\";\nimport { Tabs, Tab } from \"@/components/tabs\";\n\n# Install Mastra\n[EN] Source: https://mastra.ai/en/docs/getting-started/installation\n\nTo get started with Mastra, youâ€™ll need access to a large language model (LLM). By default, Mastra is set up to work with [OpenAI](https://platform.openai.com/), so youâ€™ll need an API key to begin.\n\nMastra also supports other LLM providers. For a full list of supported models and setup instructions, see [Model Providers](/docs/getting-started/model-providers).\n\n\n## Prerequisites\n\n- Node.js `v20.0` or higher\n- An API key from a supported [Model Provider](/docs/getting-started/model-providers)\n\n<Steps>\n\n## Install using the `create-mastra` CLI\n\nOur CLI is the fastest way to get started with Mastra. Run the following command to start the interactive setup:\n\n{/*\nLLM CONTEXT: This Tabs component shows different package manager commands for creating a new Mastra project.\nEach tab displays the equivalent command for that specific package manager (npx, npm, yarn, pnpm, bun).\nThis helps users choose their preferred package manager while following the same installation process.\nAll commands achieve the same result - creating a new Mastra project with the interactive setup.\n*/}\n\n<Tabs items={[\"npx\", \"npm\", \"yarn\", \"pnpm\", \"bun\"]}>\n  <Tab>\n    ```bash copy\n    npx create-mastra@latest\n    ```\n  </Tab>\n  <Tab>\n    ```bash copy\n    npm create mastra@latest\n    ```\n  </Tab>\n  <Tab>\n    ```bash copy\n    yarn create mastra@latest\n    ```\n  </Tab>\n  <Tab>\n    ```bash copy\n    pnpm create mastra@latest\n    ```\n  </Tab>\n  <Tab>\n    ```bash copy\n    bun create mastra@latest\n    ```\n  </Tab>\n</Tabs>\n\n\n**Install using CLI flags**\n\nYou can also run the Mastra CLI in non-interactive mode by passing all required flags, for example:\n\n```bash copy\nnpx create-mastra@latest --project-name hello-mastra --example --components tools,agents,workflows --llm openai\n```\n\n> See the [create-mastra](/reference/cli/create-mastra) documentation for a full list of available CLI options.\n\n### Add your API key\n\nAdd your API key to the `.env` file:\n\n```bash filename=\".env\" copy\nOPENAI_API_KEY=<your-api-key>\n```\n> This example uses OpenAI. Each LLM provider uses a unique name. See [Model Capabilities](/docs/getting-started/model-capability) for more information.\n\nYou can now launch the [Mastra Development Server](/docs/server-db/local-dev-playground) and test your agent using the Mastra Playground.\n\n</Steps>\n\n## Install manually\n\nThe following steps will walk you through installing Mastra manually.\n\n<Steps>\n\n### Create a new project\n\nCreate a new project and change directory:\n\n```bash copy\nmkdir hello-mastra && cd hello-mastra\n```\n\nInitialize a TypeScript project including the `@mastra/core` package:\n\n{/*\nLLM CONTEXT: This Tabs component shows manual installation commands for different package managers.\nEach tab displays the complete setup process for that package manager including project initialization,\ndev dependencies installation, and core Mastra packages installation.\nThis helps users manually set up a Mastra project with their preferred package manager.\n*/}\n\n<Tabs items={[\"npm\", \"pnpm\", \"yarn\", \"bun\"]}>\n\n  <Tab>\n    ```bash copy\n    npm init -y\n\n    npm install typescript tsx @types/node mastra@latest --save-dev\n\n    npm install @mastra/core@latest zod@^3 @ai-sdk/openai\n    ```\n\n  </Tab>\n  <Tab>\n    ```bash copy\n    pnpm init\n\n    pnpm add typescript tsx @types/node mastra@latest --save-dev\n\n    pnpm add @mastra/core@latest zod@^3 @ai-sdk/openai\n    ```\n\n  </Tab>\n  <Tab>\n    ```bash copy\n    yarn init -y\n\n    yarn add typescript tsx @types/node mastra@latest --dev\n\n    yarn add @mastra/core@latest zod@^3 @ai-sdk/openai\n    ```\n\n  </Tab>\n  <Tab>\n    ```bash copy\n    bun init -y\n\n    bun add typescript tsx @types/node mastra@latest --dev\n\n    bun add @mastra/core@latest zod@^3 @ai-sdk/openai\n    ```\n\n  </Tab>\n</Tabs>\n\nAdd the `dev` and `build` scripts to `package.json`:\n\n```json filename=\"package.json\" copy\n{\n  \"scripts\": {\n    // ...\n    \"dev\": \"mastra dev\",\n    \"build\": \"mastra build\"\n  }\n}\n```\n\n### Initialize TypeScript\n\nCreate a `tsconfig.json` file:\n\n```bash copy\ntouch tsconfig.json\n```\n\nAdd the following configuration:\n\n```json filename=\"tsconfig.json\" copy\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"esModuleInterop\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"strict\": true,\n    \"skipLibCheck\": true,\n    \"noEmit\": true,\n    \"outDir\": \"dist\"\n  },\n  \"include\": [\n    \"src/**/*\"\n  ]\n}\n```\n\n> This TypeScript configuration is optimized for Mastra projects, using modern module resolution and strict type checking.\n\n### Set up your API key\n\nCreate `.env` file:\n\n```bash copy\ntouch .env\n```\n\nAdd your API key:\n\n```bash filename=\".env\" copy\nOPENAI_API_KEY=<your-api-key>\n```\n\n> This example uses OpenAI. Each LLM provider uses a unique name. See [Model Capabilities](/docs/getting-started/model-capability) for more information.\n\n### Create a Tool\n\nCreate a `weather-tool.ts` file:\n\n```bash copy\nmkdir -p src/mastra/tools && touch src/mastra/tools/weather-tool.ts\n```\n\nAdd the following code:\n\n```ts filename=\"src/mastra/tools/weather-tool.ts\" showLineNumbers copy\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"Get current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"City name\")\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  }),\n  execute: async () => {\n    return {\n      output: \"The weather is sunny\"\n    };\n  }\n});\n```\n\n> See the full weatherTool example in [Giving an Agent a Tool](/examples/agents/using-a-tool).\n\n### Create an Agent\n\nCreate a `weather-agent.ts` file:\n\n```bash copy\nmkdir -p src/mastra/agents && touch src/mastra/agents/weather-agent.ts\n```\n\nAdd the following code:\n\n```ts filename=\"src/mastra/agents/weather-agent.ts\" showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { weatherTool } from \"../tools/weather-tool\";\n\nexport const weatherAgent = new Agent({\n  name: 'Weather Agent',\n  instructions: `\n      You are a helpful weather assistant that provides accurate weather information.\n\n      Your primary function is to help users get weather details for specific locations. When responding:\n      - Always ask for a location if none is provided\n      - If the location name isnâ€™t in English, please translate it\n      - If giving a location with multiple parts (e.g. \"New York, NY\"), use the most relevant part (e.g. \"New York\")\n      - Include relevant details like humidity, wind conditions, and precipitation\n      - Keep responses concise but informative\n\n      Use the weatherTool to fetch current weather data.\n`,\n  model: openai('gpt-4o-mini'),\n  tools: { weatherTool }\n});\n```\n\n### Register the Agent\n\nCreate the Mastra entry point and register agent:\n\n```bash copy\ntouch src/mastra/index.ts\n```\n\nAdd the following code:\n\n```ts filename=\"src/mastra/index.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { weatherAgent } from \"./agents/weather-agent\";\n\nexport const mastra = new Mastra({\n  agents: { weatherAgent }\n});\n```\n\nYou can now launch the [Mastra Development Server](/docs/server-db/local-dev-playground) and test your agent using the Mastra Playground.\n\n</Steps>\n\n## Add to an existing project\n\nMastra can be installed and integrated into a wide range of projects. Below are links to integration guides to help you get started:\n\n- [Next.js](/docs/frameworks/web-frameworks/next-js)\n- [Vite + React](/docs/frameworks/web-frameworks/vite-react)\n- [Astro](/docs/frameworks/web-frameworks/astro)\n- [Express](/docs/frameworks/servers/express)\n\n\n### `mastra init`\n\nTo install Mastra in an existing project, use the `mastra init` command.\n\n> See [mastra init](/reference/cli/init) for more information.\n\n## Next steps\n\n- [Local Development](/docs/server-db/local-dev-playground)\n- [Deploy to Mastra Cloud](/docs/deployment/overview)\n\n\n/docs/server-db/local-dev-playground\n\n\n## Model Capabilities\n[EN] Source: https://mastra.ai/en/docs/getting-started/model-capability\n\nimport { ProviderTable } from \"@/components/provider-table\";\n\nThe AI providers support different language models with various capabilities. Not all models support structured output, image input, object generation, tool usage, or tool streaming.\n\nHere are the capabilities of popular models:\n\n<ProviderTable />\n\nSource: [AI SDK | Model Capabilities](https://sdk.vercel.ai/docs/foundations/providers-and-models#model-capabilities)\n\n\n---\ntitle: \"Model Providers | Getting Started | Mastra Docs\"\ndescription: \"Learn how to configure and use different model providers with Mastra.\"\n---\n\nimport { Callout } from 'nextra/components'\n\n# Model Providers\n[EN] Source: https://mastra.ai/en/docs/getting-started/model-providers\n\nModel providers are used to interact with different language models. Mastra uses [Vercel's AI SDK](https://sdk.vercel.ai) as a model routing layer to provide a similar syntax for many models:\n\n```typescript showLineNumbers copy {1,7} filename=\"src/mastra/agents/weather-agent.ts\"\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"Instructions for the agent...\",\n  model: openai(\"gpt-4-turbo\"),\n});\n\nconst result = await agent.generate(\"What is the weather like?\");\n```\n\n## Types of AI SDK model providers\n\nModel providers from the AI SDK can be grouped into three main categories:\n\n- [Official providers maintained by the AI SDK team](/docs/getting-started/model-providers#official-providers)\n- [OpenAI-compatible providers](/docs/getting-started/model-providers#openai-compatible-providers)\n- [Community providers](/docs/getting-started/model-providers#community-providers)\n\n> You can find a list of all available model providers in the [AI SDK documentation](https://ai-sdk.dev/providers/ai-sdk-providers).\n\n<Callout>\nAI SDK model providers are packages that need to be installed in your Mastra project.\nThe default model provider selected during the installation process is installed in the project.\n\nIf you want to use a different model provider, you need to install it in your project as well.\n</Callout>\n\nHere are some examples of how Mastra agents can be configured to use the different types of model providers:\n\n### Official providers\n\nOfficial model providers are maintained by the AI SDK team.\nTheir packages are usually prefixed with `@ai-sdk/`, e.g. `@ai-sdk/anthropic`, `@ai-sdk/openai`, etc.\n\n```typescript showLineNumbers copy {1,7} filename=\"src/mastra/agents/weather-agent.ts\"\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n  name: \"WeatherAgent\",\n  instructions: \"Instructions for the agent...\",\n  model: openai(\"gpt-4-turbo\"),\n});\n```\n\nAdditional configuration may be done by importing a helper function from the AI SDK provider.\nHere's an example using the OpenAI provider:\n\n```typescript showLineNumbers copy filename=\"src/mastra/agents/weather-agent.ts\" {1,4-8,13}\nimport { createOpenAI } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\"\n\nconst openai = createOpenAI({\n    baseUrl: \"<your-custom-base-url>\",\n    apiKey: \"<your-custom-api-key>\",\n    ...otherOptions\n});\n\nconst agent = new Agent({\n    name: \"WeatherAgent\",\n    instructions: \"Instructions for the agent...\",\n    model: openai(\"<model-name>\"),\n});\n```\n\n### OpenAI-compatible providers\n\nSome language model providers implement the OpenAI API. For these providers, you can use the [`@ai-sdk/openai-compatible`](https://www.npmjs.com/package/@ai-sdk/openai-compatible) provider.\n\nHere's the general setup and provider instance creation:\n\n```typescript showLineNumbers copy filename=\"src/mastra/agents/weather-agent.ts\" {1,4-14,19}\nimport { createOpenAICompatible } from \"@ai-sdk/openai-compatible\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst openaiCompatible = createOpenAICompatible({\n    name: \"<model-name>\",\n    baseUrl: \"<base-url>\",\n    apiKey: \"<api-key>\",\n    headers: {},\n    queryParams: {},\n    fetch: async (url, options) => {\n        // custom fetch logic\n        return fetch(url, options);\n    }\n});\n\nconst agent = new Agent({\n    name: \"WeatherAgent\",\n    instructions: \"Instructions for the agent...\",\n    model: openaiCompatible(\"<model-name>\"),\n});\n```\n\nFor more information on the OpenAI-compatible provider, please refer to the [AI SDK documentation](https://ai-sdk.dev/providers/openai-compatible-providers).\n\n### Community providers\n\nThe AI SDK provides a [Language Model Specification](https://github.com/vercel/ai/tree/main/packages/provider/src/language-model/v1).\nFollowing this specification, you can create your own model provider compatible with the AI SDK.\n\nSome community providers have implemented this specification and are compatible with the AI SDK.\nWe will look at one such provider, the Ollama provider available in the [`ollama-ai-provider`](https://github.com/sgomez/ollama-ai-provider) package.\n\nHere's an example:\n\n```typescript showLineNumbers copy filename=\"src/mastra/agents/weather-agent.ts\" {1,7}\nimport { ollama } from \"ollama-ai-provider\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst agent = new Agent({\n    name: \"WeatherAgent\",\n    instructions: \"Instructions for the agent...\",\n    model: ollama(\"llama3.2:latest\"),\n});\n```\n\nYou can also configure the Ollama provider like so:\n\n```typescript showLineNumbers copy filename=\"src/mastra/agents/weather-agent.ts\" {1,4-7,12}\nimport { createOllama } from \"ollama-ai-provider\";\nimport { Agent } from \"@mastra/core/agent\";\n\nconst ollama = createOllama({\n    baseUrl: \"<your-custom-base-url>\",\n    ...otherOptions,\n});\n\nconst agent = new Agent({\n    name: \"WeatherAgent\",\n    instructions: \"Instructions for the agent...\",\n    model: ollama(\"llama3.2:latest\"),\n});\n```\n\nFor more information on the Ollama provider and other available community providers, please refer to the [AI SDK documentation](https://ai-sdk.dev/providers/community-providers).\n\n<Callout>\nWhile this example shows how to use the Ollama provider, other providers like `openrouter`, `azure`, etc. may also be used.\n</Callout>\n\nDifferent AI providers may have different options for configuration. Please refer to the [AI SDK documentation](https://ai-sdk.dev/providers/ai-sdk-providers) for more information.\n\n\n---\ntitle: \"Local Project Structure | Getting Started | Mastra Docs\"\ndescription: Guide on organizing folders and files in Mastra, including best practices and recommended structures.\n---\n\nimport { FileTree } from \"nextra/components\";\n\n# Project Structure\n[EN] Source: https://mastra.ai/en/docs/getting-started/project-structure\n\nThis page provides a guide for organizing folders and files in Mastra. Mastra is a modular framework, and you can use any of the modules separately or together.\n\nYou could write everything in a single file, or separate each agent, tool, and workflow into their own files.\n\nWe don't enforce a specific folder structure, but we do recommend some best practices, and the CLI will scaffold a project with a sensible structure.\n\n## Example Project Structure\n\nA default project created with the CLI looks like this:\n\n<FileTree>\n  <FileTree.Folder name=\"src\" defaultOpen>\n    <FileTree.Folder name=\"mastra\" defaultOpen>\n      <FileTree.Folder name=\"agents\" defaultOpen>\n        <FileTree.File name=\"agent-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.Folder name=\"tools\" defaultOpen>\n        <FileTree.File name=\"tool-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.Folder name=\"workflows\" defaultOpen>\n        <FileTree.File name=\"workflow-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.File name=\"index.ts\" />\n    </FileTree.Folder>\n  </FileTree.Folder>\n  <FileTree.File name=\".env\" />\n  <FileTree.File name=\"package.json\" />\n  <FileTree.File name=\"tsconfig.json\" />\n</FileTree>\n{/*\n```\nroot/\nâ”œâ”€â”€ src/\nâ”‚   â””â”€â”€ mastra/\nâ”‚       â”œâ”€â”€ agents/\nâ”‚       â”‚   â””â”€â”€ index.ts\nâ”‚       â”œâ”€â”€ tools/\nâ”‚       â”‚   â””â”€â”€ index.ts\nâ”‚       â”œâ”€â”€ workflows/\nâ”‚       â”‚   â””â”€â”€ index.ts\nâ”‚       â”œâ”€â”€ index.ts\nâ”œâ”€â”€ .env\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tssconfig.json\n``` */}\n\n### Top-level Folders\n\n| Folder                 | Description                          |\n| ---------------------- | ------------------------------------ |\n| `src/mastra`           | Core application folder              |\n| `src/mastra/agents`    | Agent configurations and definitions |\n| `src/mastra/tools`     | Custom tool definitions              |\n| `src/mastra/workflows` | Workflow definitions                 |\n\n### Top-level Files\n\n| File                  | Description                                         |\n| --------------------- | --------------------------------------------------- |\n| `src/mastra/index.ts` | Main configuration file for Mastra                  |\n| `.env`                | Environment variables                               |\n| `package.json`        | Node.js project metadata, scripts, and dependencies |\n| `tsconfig.json`       | TypeScript compiler configuration                   |\n\n\n---\ntitle: \"Introduction | Mastra Docs\"\ndescription: \"Mastra is a TypeScript agent framework. It helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals.\"\n---\n\n# About Mastra\n[EN] Source: https://mastra.ai/en/docs\n\nMastra is an open-source TypeScript agent framework.\n\nIt's designed to give you the primitives you need to build AI applications and features.\n\nYou can use Mastra to build [AI agents](/docs/agents/overview.mdx) that have memory and can execute functions, or chain LLM calls in deterministic [workflows](/docs/workflows/overview.mdx). You can chat with your agents in Mastra's [local dev environment](/docs/local-dev/mastra-dev.mdx), feed them application-specific knowledge with [RAG](/docs/rag/overview.mdx), and score their outputs with Mastra's [evals](/docs/evals/overview.mdx).\n\nThe main features include:\n\n- **[Model routing](https://sdk.vercel.ai/docs/introduction)**: Mastra uses the [Vercel AI SDK](https://sdk.vercel.ai/docs/introduction) for model routing, providing a unified interface to interact with any LLM provider including OpenAI, Anthropic, and Google Gemini.\n- **[Agent memory and tool calling](/docs/agents/agent-memory.mdx)**: With Mastra, you can give your agent tools (functions) that it can call. You can persist agent memory and retrieve it based on recency, semantic similarity, or conversation thread.\n- **[Workflow graphs](/docs/workflows/overview.mdx)**: When you want to execute LLM calls in a deterministic way, Mastra gives you a graph-based workflow engine. You can define discrete steps, log inputs and outputs at each step of each run, and pipe them into an observability tool. Mastra workflows have a simple syntax for control flow (`.then()`, `.branch()`, `.parallel()`) that allows branching and chaining.\n- **[Agent development environment](/docs/local-dev/mastra-dev.mdx)**: When you're developing an agent locally, you can chat with it and see its state and memory in Mastra's agent development environment.\n- **[Retrieval-augmented generation (RAG)](/docs/rag/overview.mdx)**: Mastra gives you APIs to process documents (text, HTML, Markdown, JSON) into chunks, create embeddings, and store them in a vector database. At query time, it retrieves relevant chunks to ground LLM responses in your data, with a unified API on top of multiple vector stores (Pinecone, pgvector, etc) and embedding providers (OpenAI, Cohere, etc).\n- **[Deployment](/docs/deployment/deployment.mdx)**: Mastra supports bundling your agents and workflows within an existing React, Next.js, or Node.js application, or into standalone endpoints. The Mastra deploy helper lets you easily bundle agents and workflows into a Node.js server using Hono, or deploy it onto a serverless platform like Vercel, Cloudflare Workers, or Netlify.\n- **[Evals](/docs/evals/overview.mdx)**: Mastra provides automated evaluation metrics that use model-graded, rule-based, and statistical methods to assess LLM outputs, with built-in metrics for toxicity, bias, relevance, and factual accuracy. You can also define your own evals.\n\n\n---\ntitle: Understanding the Mastra Cloud Dashboard\ndescription: Details of each feature available in Mastra Cloud\n---\n\nimport { MastraCloudCallout } from '@/components/mastra-cloud-callout'\n\n# Navigating the Dashboard\n[EN] Source: https://mastra.ai/en/docs/mastra-cloud/dashboard\n\nThis page explains how to navigate the Mastra Cloud dashboard, where you can configure your project, view deployment details, and interact with agents and workflows using the built-in [Playground](/docs/mastra-cloud/dashboard#playground).\n\n<MastraCloudCallout />\n\n## Overview\n\nThe **Overview** page provides details about your application, including its domain URL, status, latest deployment, and connected agents and workflows.\n\n![Project dashboard](/image/mastra-cloud/mastra-cloud-project-dashboard.jpg)\n\nKey features:\n\nEach project shows its current deployment status, active domains, and environment variables, so you can quickly understand how your application is running.\n\n## Deployments\n\nThe **Deployments** page shows recent builds and gives you quick access to detailed build logs. Click any row to view more information about a specific deployment.\n\n![Dashboard deployment](/image/mastra-cloud/mastra-cloud-dashboard-deployments.jpg)\n\nKey features:\n\nEach deployment includes its current status, the Git branch it was deployed from, and a title generated from the commit hash.\n\n## Logs\n\nThe **Logs** page is where you'll find detailed information to help debug and monitor your application's behavior in the production environment.\n\n![Dashboard logs](/image/mastra-cloud/mastra-cloud-dashboard-logs.jpg)\n\nKey features:\n\nEach log includes a severity level and detailed messages showing agent, workflow, and storage activity.\n\n## Settings\n\nOn the **Settings** page you can modify the configuration of your application.\n\n![Dashboard settings](/image/mastra-cloud/mastra-cloud-dashboard-settings.jpg)\n\nKey features:\n\nYou can manage environment variables, edit key project settings like the name and branch, configure storage with LibSQLStore, and set a stable URL for your endpoints.\n\n> Changes to configuration require a new deployment before taking effect.\n\n## Playground\n\n### Agents\n\nOn the **Agents** page you'll see all agents used in your application. Click any agent to interact using the chat interface.\n\n![Dashboard playground agents](/image/mastra-cloud/mastra-cloud-dashboard-playground-agents.jpg)\n\nKey features:\n\nTest your agents in real time using the chat interface, review traces of each interaction, and see evaluation scores for every response.\n\n### Workflows\n\nOn the **Workflows** page you'll see all workflows used in your application. Click any workflow to interact using the runner interface.\n\n![Dashboard playground workflows](/image/mastra-cloud/mastra-cloud-dashboard-playground-workflows.jpg)\n\nKey features:\n\nVisualize your workflow with a step-by-step graph, view execution traces, and run workflows directly using the built-in runner.\n\n### Tools\n\nOn the **Tools** page you'll see all tools used by your agents. Click any tool to interact using the input interface.\n\n![Dashboard playground tools](/image/mastra-cloud/mastra-cloud-dashboard-playground-tools.jpg)\n\nKey features:\n\nTest your tools by providing an input that matches the schema and viewing the structured output.\n\n## MCP Servers\n\nThe **MCP Servers** page lists all MCP Servers included in your application. Click any MCP Server for more information.\n\n![Dashboard playground mcp servers](/image/mastra-cloud/mastra-cloud-dashboard-playground-mcpservers.jpg)\n\nKey features:\n\nEach MCP Server includes API endpoints for HTTP and SSE, along with IDE configuration snippets for tools like Cursor and Windsurf.\n\n## Next steps\n\n- [Understanding Tracing and Logs](/docs/mastra-cloud/observability)\n\n\n---\ntitle: Observability in Mastra Cloud\ndescription: Monitoring and debugging tools for Mastra Cloud deployments\n---\n\nimport { MastraCloudCallout } from '@/components/mastra-cloud-callout'\n\n# Understanding Tracing and Logs\n[EN] Source: https://mastra.ai/en/docs/mastra-cloud/observability\n\nMastra Cloud captures execution data to help you monitor your application's behavior in the production environment.\n\n<MastraCloudCallout />\n\n## Logs\n\nYou can view detailed logs for debugging and monitoring your application's behavior on the [Logs](/docs/mastra-cloud/dashboard#logs) page of the Dashboard.\n\n![Dashboard logs](/image/mastra-cloud/mastra-cloud-dashboard-logs.jpg)\n\nKey features:\n\nEach log entry includes its severity level and a detailed message showing agent, workflow, or storage activity.\n\n## Traces\n\nMore detailed traces are available for both agents and workflows by using a [logger](/docs/observability/logging) or enabling [telemetry](/docs/observability/tracing) using one of our [supported providers](/reference/observability/providers).\n\n### Agents\n\nWith a [logger](/docs/observability/logging) enabled, you can view detailed outputs from your agents in the **Traces** section of the Agents Playground.\n\n![observability agents](/image/mastra-cloud/mastra-cloud-observability-agents.jpg)\n\nKey features:\n\nTools passed to the agent during generation are standardized using `convertTools`. This includes retrieving client-side tools, memory tools, and tools exposed from workflows.\n\n\n### Workflows\n\nWith a [logger](/docs/observability/logging) enabled, you can view detailed outputs from your workflows in the **Traces** section of the Workflows Playground.\n\n![observability workflows](/image/mastra-cloud/mastra-cloud-observability-workflows.jpg)\n\nKey features:\n\nWorkflows are created using `createWorkflow`, which sets up steps, metadata, and tools. You can run them with `runWorkflow` by passing input and options.\n\n## Next steps\n\n- [Logging](/docs/observability/logging)\n- [Tracing](/docs/observability/tracing)\n\n\n---\ntitle: Mastra Cloud\ndescription: Deployment and monitoring service for Mastra applications\n---\n\nimport { MastraCloudCallout } from '@/components/mastra-cloud-callout'\nimport { FileTree } from \"nextra/components\";\n\n# Mastra Cloud\n[EN] Source: https://mastra.ai/en/docs/mastra-cloud/overview\n\n[Mastra Cloud](https://mastra.ai/cloud) is a platform for deploying, managing, monitoring, and debugging Mastra applications. When you [deploy](/docs/mastra-cloud/setting-up) your application, Mastra Cloud exposes your agents, tools, and workflows as REST API endpoints.\n\n<MastraCloudCallout />\n\n## Platform features\n\nDeploy and manage your applications with automated builds, organized projects, and no additional configuration.\n\n![Platform features](/image/mastra-cloud/mastra-cloud-platform-features.jpg)\n\nKey features:\n\nMastra Cloud supports zero-config deployment, continuous integration with GitHub, and atomic deployments that package agents, tools, and workflows together.\n\n## Project Dashboard\n\nMonitor and debug your applications with detailed output logs, deployment state, and interactive tools.\n\n![Project dashboard](/image/mastra-cloud/mastra-cloud-project-dashboard.jpg)\n\nKey features:\n\nThe Project Dashboard gives you an overview of your application's status and deployments, with access to logs and a built-in playground for testing agents and workflows.\n\n## Project structure\n\nUse a standard Mastra project structure for proper detection and deployment.\n\n<FileTree>\n  <FileTree.Folder name=\"src\" defaultOpen>\n    <FileTree.Folder name=\"mastra\" defaultOpen>\n      <FileTree.Folder name=\"agents\" defaultOpen>\n        <FileTree.File name=\"agent-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.Folder name=\"tools\" defaultOpen>\n        <FileTree.File name=\"tool-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.Folder name=\"workflows\" defaultOpen>\n        <FileTree.File name=\"workflow-name.ts\" />\n      </FileTree.Folder>\n      <FileTree.File name=\"index.ts\" />\n    </FileTree.Folder>\n  </FileTree.Folder>\n  <FileTree.File name=\"package.json\" />\n</FileTree>\n\nMastra Cloud scans your repository for:\n\n- **Agents**: Defined using: `new Agent({...})`\n- **Tools**: Defined using: `createTool({...})`\n- **Workflows**: Defined using: `createWorkflow({...})`\n- **Steps**: Defined using: `createStep({...})`\n- **Environment Variables**: API keys and configuration variables\n\n## Technical implementation\n\nMastra Cloud is purpose-built for Mastra agents, tools, and workflows. It handles long-running requests, records detailed traces for every execution, and includes built-in support for evals.\n\n## Next steps\n\n- [Setting Up and Deploying](/docs/mastra-cloud/setting-up)\n\n\n---\ntitle: Setting Up a Project\ndescription: Configuration steps for Mastra Cloud projects\n---\n\nimport { MastraCloudCallout } from '@/components/mastra-cloud-callout'\nimport { Steps } from \"nextra/components\";\n\n# Setting Up and Deploying\n[EN] Source: https://mastra.ai/en/docs/mastra-cloud/setting-up\n\nThis page explains how to set up a project on [Mastra Cloud](https://mastra.ai/cloud) with automatic deployments using our GitHub integration.\n\n<MastraCloudCallout />\n\n## Prerequisites\n\n- A [Mastra Cloud](https://mastra.ai/cloud) account\n- A GitHub account / repository containing a Mastra application\n\n> See our [Getting started](/docs/getting-started/installation) guide to scaffold out a new Mastra project with sensible defaults.\n\n## Setup and Deploy process\n\n<Steps>\n\n### Sign in to Mastra Cloud\n\nHead over to [https://cloud.mastra.ai/](https://cloud.mastra.ai) and sign in with either:\n\n- **GitHub**\n- **Google**\n\n### Install the Mastra GitHub app\n\nWhen prompted, install the Mastra GitHub app.\n\n![Install GitHub](/image/mastra-cloud/mastra-cloud-install-github.jpg)\n\n### Create a new project\n\nClick the **Create new project** button to create a new project.\n\n![Create new project](/image/mastra-cloud/mastra-cloud-create-new-project.jpg)\n\n### Import a Git repository\n\nSearch for a repository, then click **Import**.\n\n![Import Git repository](/image/mastra-cloud/mastra-cloud-import-git-repository.jpg)\n\n### Configure the deployment\n\nMastra Cloud automatically detects the right build settings, but you can customize them using the options described below.\n\n![Deployment details](/image/mastra-cloud/mastra-cloud-deployment-details.jpg)\n\n- **Importing from GitHub**: The GitHub repository name\n- **Project name**: Customize the project name\n- **Branch**: The branch to deploy from\n- **Project root**: The root directory of your project\n- **Mastra directory**: Where Mastra files are located\n- **Environment variables**: Add environment variables used by the application\n- **Build and Store settings**:\n   - **Install command**: Runs pre-build to install project dependencies\n   - **Project setup command**: Runs pre-build to prepare any external dependencies\n   - **Port**: The network port the server will use\n   - **Store settings**: Use Mastra Cloud's built-in [LibSQLStore](/docs/storage/overview) storage\n- **Deploy Project**: Starts the deployment process\n\n### Deploy project\n\nClick **Deploy Project** to create and deploy your application using the configuration youâ€™ve set.\n\n</Steps>\n\n## Successful deployment\n\nAfter a successful deployment you'll be shown the **Overview** screen where you can view your project's status, domains, latest deployments and connected agents and workflows.\n\n![Successful deployment](/image/mastra-cloud/mastra-cloud-successful-deployment.jpg)\n\n## Continuous integration\n\nYour project is now configured with automatic deployments which occur whenever you push to the configured branch of your GitHub repository.\n\n## Testing your application\n\nAfter a successful deployment you can test your agents and workflows from the [Playground](/docs/mastra-cloud/dashboard#playground) in Mastra Cloud, or interact with them using our [Client SDK](/docs/client-js/overview).\n\n## Next steps\n\n- [Navigating the Dashboard](/docs/mastra-cloud/dashboard)\n\n\n---\ntitle: \"Logging | Mastra Observability Documentation\"\ndescription: Documentation on effective logging in Mastra, crucial for understanding application behavior and improving AI accuracy.\n---\n\nimport Image from \"next/image\";\n\n# Logging\n[EN] Source: https://mastra.ai/en/docs/observability/logging\n\nIn Mastra, logs can detail when certain functions run, what input data they receive, and how they respond.\n\n## Basic Setup\n\nHere's a minimal example that sets up a **console logger** at the `INFO` level. This will print out informational messages and above (i.e., `DEBUG`, `INFO`, `WARN`, `ERROR`) to the console.\n\n```typescript filename=\"mastra.config.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core\";\nimport { PinoLogger } from \"@mastra/loggers\";\n\nexport const mastra = new Mastra({\n  // Other Mastra configuration...\n  logger: new PinoLogger({\n    name: \"Mastra\",\n    level: \"info\",\n  }),\n});\n```\n\nIn this configuration:\n\n- `name: \"Mastra\"` specifies the name to group logs under.\n- `level: \"info\"` sets the minimum severity of logs to record.\n\n## Configuration\n\n- For more details on the options you can pass to `PinoLogger()`, see the [PinoLogger reference documentation](/reference/observability/logger).\n- Once you have a `Logger` instance, you can call its methods (e.g., `.info()`, `.warn()`, `.error()`) in the [Logger instance reference documentation](/reference/observability/logger).\n- If you want to send your logs to an external service for centralized collection, analysis, or storage, you can configure other logger types such as Upstash Redis. Consult the [Logger reference documentation](/reference/observability/logger) for details on parameters like `url`, `token`, and `key` when using the `UPSTASH` logger type.\n\n\n---\ntitle: \"Next.js Tracing | Mastra Observability Documentation\"\ndescription: \"Set up OpenTelemetry tracing for Next.js applications\"\n---\n\n# Next.js Tracing\n[EN] Source: https://mastra.ai/en/docs/observability/nextjs-tracing\n\nNext.js requires additional configuration to enable OpenTelemetry tracing.\n\n### Step 1: Next.js Configuration\n\nStart by enabling the instrumentation hook in your Next.js config:\n\n```ts filename=\"next.config.ts\" showLineNumbers copy\nimport type { NextConfig } from \"next\";\n\nconst nextConfig: NextConfig = {\n  experimental: {\n    instrumentationHook: true, // Not required in Next.js 15+\n  },\n};\n\nexport default nextConfig;\n```\n\n### Step 2: Mastra Configuration\n\nConfigure your Mastra instance:\n\n```typescript filename=\"mastra.config.ts\" copy\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"your-project-name\",\n    enabled: true,\n  },\n});\n```\n\n### Step 3: Configure your providers\n\nIf you're using Next.js, you have two options for setting up OpenTelemetry instrumentation:\n\n#### Option 1: Using a Custom Exporter\n\nThe default that will work across providers is to configure a custom exporter:\n\n1. Install the required dependencies (example using Langfuse):\n\n```bash copy\nnpm install @opentelemetry/api langfuse-vercel\n```\n\n2. Create an instrumentation file:\n\n```ts filename=\"instrumentation.ts\" copy\nimport {\n  NodeSDK,\n  ATTR_SERVICE_NAME,\n  resourceFromAttributes,\n} from \"@mastra/core/telemetry/otel-vendor\";\nimport { LangfuseExporter } from \"langfuse-vercel\";\n\nexport function register() {\n  const exporter = new LangfuseExporter({\n    // ... Langfuse config\n  });\n\n  const sdk = new NodeSDK({\n    resource: resourceFromAttributes({\n      [ATTR_SERVICE_NAME]: \"ai\",\n    }),\n    traceExporter: exporter,\n  });\n\n  sdk.start();\n}\n```\n\n#### Option 2: Using Vercel's Otel Setup\n\nIf you're deploying to Vercel, you can use their OpenTelemetry setup:\n\n1. Install the required dependencies:\n\n```bash copy\nnpm install @opentelemetry/api @vercel/otel\n```\n\n2. Create an instrumentation file at the root of your project (or in the src folder if using one):\n\n```ts filename=\"instrumentation.ts\" copy\nimport { registerOTel } from \"@vercel/otel\";\n\nexport function register() {\n  registerOTel({ serviceName: \"your-project-name\" });\n}\n```\n\n### Summary\n\nThis setup will enable OpenTelemetry tracing for your Next.js application and Mastra operations.\n\nFor more details, see the documentation for:\n\n- [Next.js Instrumentation](https://nextjs.org/docs/app/building-your-application/optimizing/instrumentation)\n- [Vercel OpenTelemetry](https://vercel.com/docs/observability/otel-overview/quickstart)\n\n\n---\ntitle: \"Tracing | Mastra Observability Documentation\"\ndescription: \"Set up OpenTelemetry tracing for Mastra applications\"\n---\n\nimport Image from \"next/image\";\n\n# Tracing\n[EN] Source: https://mastra.ai/en/docs/observability/tracing\n\nMastra supports the OpenTelemetry Protocol (OTLP) for tracing and monitoring your application. When telemetry is enabled, Mastra automatically traces all core primitives including agent operations, LLM interactions, tool executions, integration calls, workflow runs, and database operations. Your telemetry data can then be exported to any OTEL collector.\n\n### Basic Configuration\n\nHere's a simple example of enabling telemetry:\n\n```ts filename=\"mastra.config.ts\" showLineNumbers copy\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    sampling: {\n      type: \"always_on\",\n    },\n    export: {\n      type: \"otlp\",\n      endpoint: \"http://localhost:4318\", // SigNoz local endpoint\n    },\n  },\n});\n```\n\n### Configuration Options\n\nThe telemetry config accepts these properties:\n\n```ts\ntype OtelConfig = {\n  // Name to identify your service in traces (optional)\n  serviceName?: string;\n\n  // Enable/disable telemetry (defaults to true)\n  enabled?: boolean;\n\n  // Control how many traces are sampled\n  sampling?: {\n    type: \"ratio\" | \"always_on\" | \"always_off\" | \"parent_based\";\n    probability?: number; // For ratio sampling\n    root?: {\n      probability: number; // For parent_based sampling\n    };\n  };\n\n  // Where to send telemetry data\n  export?: {\n    type: \"otlp\" | \"console\";\n    endpoint?: string;\n    headers?: Record<string, string>;\n  };\n};\n```\n\nSee the [OtelConfig reference documentation](../../reference/observability/otel-config.mdx) for more details.\n\n### Environment Variables\n\nYou can configure the OTLP endpoint and headers through environment variables:\n\n```env filename=\".env\" copy\nOTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\nOTEL_EXPORTER_OTLP_HEADERS=x-api-key=your-api-key\n```\n\nThen in your config:\n\n```ts filename=\"mastra.config.ts\" showLineNumbers copy\nexport const mastra = new Mastra({\n  // ... other config\n  telemetry: {\n    serviceName: \"my-app\",\n    enabled: true,\n    export: {\n      type: \"otlp\",\n      // endpoint and headers will be picked up from env vars\n    },\n  },\n});\n```\n\n### Example: SigNoz Integration\n\nHere's what a traced agent interaction looks like in [SigNoz](https://signoz.io):\n\n<img\n  src=\"/image/signoz-telemetry-demo.png\"\n  alt=\"Agent interaction trace showing spans, LLM calls, and tool executions\"\n  style={{ maxWidth: \"800px\", width: \"100%\", margin: \"8px 0\" }}\n  className=\"nextra-image rounded-md\"\n  data-zoom\n  width={800}\n  height={400}\n/>\n\n### Other Supported Providers\n\nFor a complete list of supported observability providers and their configuration details, see the [Observability Providers reference](../../reference/observability/providers/).\n\n### Custom Instrumentation files\n\nYou can define custom instrumentation files in your Mastra project by placing them in the `/mastra` folder. Mastra automatically detects and bundles these files instead of using the default instrumentation.\n\n#### Supported File Types\n\nMastra looks for instrumentation files with these extensions:\n- `instrumentation.js`\n- `instrumentation.ts` \n- `instrumentation.mjs`\n\n#### Example\n\n```ts filename=\"/mastra/instrumentation.ts\" showLineNumbers copy\nimport { NodeSDK } from '@opentelemetry/sdk-node';\nimport { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';\n\nconst sdk = new NodeSDK({\n  traceExporter: new OTLPTraceExporter({\n    url: 'http://localhost:4318/v1/traces',\n  }),\n  instrumentations: [getNodeAutoInstrumentations()],\n});\n\nsdk.start();\n```\n\nWhen Mastra finds a custom instrumentation file, it automatically replaces the default instrumentation and bundles it during the build process.\n\n### Next.js-specific Tracing steps\n\nIf you're using Next.js, you have three additional configuration steps:\n\n1. Enable the instrumentation hook in `next.config.ts`\n2. Configure Mastra telemetry settings\n3. Set up an OpenTelemetry exporter\n\nFor implementation details, see the [Next.js Tracing](./nextjs-tracing) guide.\n\n\n---\ntitle: Chunking and Embedding Documents | RAG | Mastra Docs\ndescription: Guide on chunking and embedding documents in Mastra for efficient processing and retrieval.\n---\n\n## Chunking and Embedding Documents\n[EN] Source: https://mastra.ai/en/docs/rag/chunking-and-embedding\n\nBefore processing, create a MDocument instance from your content. You can initialize it from various formats:\n\n```ts showLineNumbers copy\nconst docFromText = MDocument.fromText(\"Your plain text content...\");\nconst docFromHTML = MDocument.fromHTML(\"<html>Your HTML content...</html>\");\nconst docFromMarkdown = MDocument.fromMarkdown(\"# Your Markdown content...\");\nconst docFromJSON = MDocument.fromJSON(`{ \"key\": \"value\" }`);\n```\n\n## Step 1: Document Processing\n\nUse `chunk` to split documents into manageable pieces. Mastra supports multiple chunking strategies optimized for different document types:\n\n- `recursive`: Smart splitting based on content structure\n- `character`: Simple character-based splits\n- `token`: Token-aware splitting\n- `markdown`: Markdown-aware splitting\n- `html`: HTML structure-aware splitting\n- `json`: JSON structure-aware splitting\n- `latex`: LaTeX structure-aware splitting\n\nHere's an example of how to use the `recursive` strategy:\n\n```ts showLineNumbers copy\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n  separator: \"\\n\",\n  extract: {\n    metadata: true, // Optionally extract metadata\n  },\n});\n```\n\n**Note:** Metadata extraction may use LLM calls, so ensure your API key is set.\n\nWe go deeper into chunking strategies in our [chunk documentation](/reference/rag/chunk.mdx).\n\n## Step 2: Embedding Generation\n\nTransform chunks into embeddings using your preferred provider. Mastra supports many embedding providers, including OpenAI and Cohere:\n\n### Using OpenAI\n\n```ts showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { embedMany } from \"ai\";\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\n### Using Cohere\n\n```ts showLineNumbers copy\nimport { cohere } from \"@ai-sdk/cohere\";\nimport { embedMany } from \"ai\";\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding(\"embed-english-v3.0\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\nThe embedding functions return vectors, arrays of numbers representing the semantic meaning of your text, ready for similarity searches in your vector database.\n\n### Configuring Embedding Dimensions\n\nEmbedding models typically output vectors with a fixed number of dimensions (e.g., 1536 for OpenAI's `text-embedding-3-small`).\nSome models support reducing this dimensionality, which can help:\n\n- Decrease storage requirements in vector databases\n- Reduce computational costs for similarity searches\n\nHere are some supported models:\n\nOpenAI (text-embedding-3 models):\n\n```ts\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\", {\n    dimensions: 256, // Only supported in text-embedding-3 and later\n  }),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\nGoogle (text-embedding-004):\n\n```ts\nconst { embeddings } = await embedMany({\n  model: google.textEmbeddingModel(\"text-embedding-004\", {\n    outputDimensionality: 256, // Truncates excessive values from the end\n  }),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\n### Vector Database Compatibility\n\nWhen storing embeddings, the vector database index must be configured to match the output size of your embedding model. If the dimensions do not match, you may get errors or data corruption.\n\n## Example: Complete Pipeline\n\nHere's an example showing document processing and embedding generation with both providers:\n\n```ts showLineNumbers copy\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { cohere } from \"@ai-sdk/cohere\";\n\nimport { MDocument } from \"@mastra/rag\";\n\n// Initialize document\nconst doc = MDocument.fromText(`\n  Climate change poses significant challenges to global agriculture.\n  Rising temperatures and changing precipitation patterns affect crop yields.\n`);\n\n// Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 256,\n  overlap: 50,\n});\n\n// Generate embeddings with OpenAI\nconst { embeddings: openAIEmbeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n\n// OR\n\n// Generate embeddings with Cohere\nconst { embeddings: cohereEmbeddings } = await embedMany({\n  model: cohere.embedding(\"embed-english-v3.0\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n\n// Store embeddings in your vector database\nawait vectorStore.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n});\n```\n\n##\n\nFor more examples of different chunking strategies and embedding configurations, see:\n\n- [Adjust Chunk Size](/reference/rag/chunk.mdx#adjust-chunk-size)\n- [Adjust Chunk Delimiters](/reference/rag/chunk.mdx#adjust-chunk-delimiters)\n- [Embed Text with Cohere](/reference/rag/embeddings.mdx#using-cohere)\n\nFor more details on vector databases and embeddings, see:\n\n- [Vector Databases](./vector-databases.mdx)\n- [Embedding API Reference](/reference/rag/embeddings.mdx)\n\n\n---\ntitle: RAG (Retrieval-Augmented Generation) in Mastra | Mastra Docs\ndescription: Overview of Retrieval-Augmented Generation (RAG) in Mastra, detailing its capabilities for enhancing LLM outputs with relevant context.\n---\n\n# RAG (Retrieval-Augmented Generation) in Mastra\n[EN] Source: https://mastra.ai/en/docs/rag/overview\n\nRAG in Mastra helps you enhance LLM outputs by incorporating relevant context from your own data sources, improving accuracy and grounding responses in real information.\n\nMastra's RAG system provides:\n\n- Standardized APIs to process and embed documents\n- Support for multiple vector stores\n- Chunking and embedding strategies for optimal retrieval\n- Observability for tracking embedding and retrieval performance\n\n## Example\n\nTo implement RAG, you process your documents into chunks, create embeddings, store them in a vector database, and then retrieve relevant context at query time.\n\n```ts showLineNumbers copy\nimport { embedMany } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { MDocument } from \"@mastra/rag\";\nimport { z } from \"zod\";\n\n// 1. Initialize document\nconst doc = MDocument.fromText(`Your document text here...`);\n\n// 2. Create chunks\nconst chunks = await doc.chunk({\n  strategy: \"recursive\",\n  size: 512,\n  overlap: 50,\n});\n\n// 3. Generate embeddings; we need to pass the text of each chunk\nconst { embeddings } = await embedMany({\n  values: chunks.map((chunk) => chunk.text),\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\n// 4. Store in vector database\nconst pgVector = new PgVector({\n  connectionString: process.env.POSTGRES_CONNECTION_STRING,\n});\nawait pgVector.upsert({\n  indexName: \"embeddings\",\n  vectors: embeddings,\n}); // using an index name of 'embeddings'\n\n// 5. Query similar chunks\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryVector,\n  topK: 3,\n}); // queryVector is the embedding of the query\n\nconsole.log(\"Similar chunks:\", results);\n```\n\nThis example shows the essentials: initialize a document, create chunks, generate embeddings, store them, and query for similar content.\n\n## Document Processing\n\nThe basic building block of RAG is document processing. Documents can be chunked using various strategies (recursive, sliding window, etc.) and enriched with metadata. See the [chunking and embedding doc](./chunking-and-embedding.mdx).\n\n## Vector Storage\n\nMastra supports multiple vector stores for embedding persistence and similarity search, including pgvector, Pinecone, Qdrant, and MongoDB. See the [vector database doc](./vector-databases.mdx).\n\n## Observability and Debugging\n\nMastra's RAG system includes observability features to help you optimize your retrieval pipeline:\n\n- Track embedding generation performance and costs\n- Monitor chunk quality and retrieval relevance\n- Analyze query patterns and cache hit rates\n- Export metrics to your observability platform\n\nSee the [OTel Configuration](../../reference/observability/otel-config.mdx) page for more details.\n\n## More resources\n\n- [Chain of Thought RAG Example](../../examples/rag/usage/cot-rag.mdx)\n- [All RAG Examples](../../examples/) (including different chunking strategies, embedding models, and vector stores)\n\n\n---\ntitle: \"Retrieval, Semantic Search, Reranking | RAG | Mastra Docs\"\ndescription: Guide on retrieval processes in Mastra's RAG systems, including semantic search, filtering, and re-ranking.\n---\n\nimport { Tabs } from \"nextra/components\";\n\n## Retrieval in RAG Systems\n[EN] Source: https://mastra.ai/en/docs/rag/retrieval\n\nAfter storing embeddings, you need to retrieve relevant chunks to answer user queries.\n\nMastra provides flexible retrieval options with support for semantic search, filtering, and re-ranking.\n\n## How Retrieval Works\n\n1. The user's query is converted to an embedding using the same model used for document embeddings\n2. This embedding is compared to stored embeddings using vector similarity\n3. The most similar chunks are retrieved and can be optionally:\n\n- Filtered by metadata\n- Re-ranked for better relevance\n- Processed through a knowledge graph\n\n## Basic Retrieval\n\nThe simplest approach is direct semantic search. This method uses vector similarity to find chunks that are semantically similar to the query:\n\n```ts showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { embed } from \"ai\";\nimport { PgVector } from \"@mastra/pg\";\n\n// Convert query to embedding\nconst { embedding } = await embed({\n  value: \"What are the main points in the article?\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n\n// Query vector store\nconst pgVector = new PgVector({\n  connectionString: process.env.POSTGRES_CONNECTION_STRING,\n});\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n});\n\n// Display results\nconsole.log(results);\n```\n\nResults include both the text content and a similarity score:\n\n```ts showLineNumbers copy\n[\n  {\n    text: \"Climate change poses significant challenges...\",\n    score: 0.89,\n    metadata: { source: \"article1.txt\" },\n  },\n  {\n    text: \"Rising temperatures affect crop yields...\",\n    score: 0.82,\n    metadata: { source: \"article1.txt\" },\n  },\n  // ... more results\n];\n```\n\nFor an example of how to use the basic retrieval method, see the [Retrieve Results](../../examples/rag/query/retrieve-results.mdx) example.\n\n## Advanced Retrieval options\n\n### Metadata Filtering\n\nFilter results based on metadata fields to narrow down the search space. This is useful when you have documents from different sources, time periods, or with specific attributes. Mastra provides a unified MongoDB-style query syntax that works across all supported vector stores.\n\nFor detailed information about available operators and syntax, see the [Metadata Filters Reference](/reference/rag/metadata-filters).\n\nBasic filtering examples:\n\n```ts showLineNumbers copy\n// Simple equality filter\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    source: \"article1.txt\",\n  },\n});\n\n// Numeric comparison\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    price: { $gt: 100 },\n  },\n});\n\n// Multiple conditions\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    category: \"electronics\",\n    price: { $lt: 1000 },\n    inStock: true,\n  },\n});\n\n// Array operations\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    tags: { $in: [\"sale\", \"new\"] },\n  },\n});\n\n// Logical operators\nconst results = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: embedding,\n  topK: 10,\n  filter: {\n    $or: [{ category: \"electronics\" }, { category: \"accessories\" }],\n    $and: [{ price: { $gt: 50 } }, { price: { $lt: 200 } }],\n  },\n});\n```\n\nCommon use cases for metadata filtering:\n\n- Filter by document source or type\n- Filter by date ranges\n- Filter by specific categories or tags\n- Filter by numerical ranges (e.g., price, rating)\n- Combine multiple conditions for precise querying\n- Filter by document attributes (e.g., language, author)\n\nFor an example of how to use metadata filtering, see the [Hybrid Vector Search](../../examples/rag/query/hybrid-vector-search.mdx) example.\n\n### Vector Query Tool\n\nSometimes you want to give your agent the ability to query a vector database directly. The Vector Query Tool allows your agent to be in charge of retrieval decisions, combining semantic search with optional filtering and reranking based on the agent's understanding of the user's needs.\n\n```ts showLineNumbers copy\nconst vectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n});\n```\n\nWhen creating the tool, pay special attention to the tool's name and description - these help the agent understand when and how to use the retrieval capabilities. For example, you might name it \"SearchKnowledgeBase\" and describe it as \"Search through our documentation to find relevant information about X topic.\"\n\nThis is particularly useful when:\n\n- Your agent needs to dynamically decide what information to retrieve\n- The retrieval process requires complex decision-making\n- You want the agent to combine multiple retrieval strategies based on context\n\n#### Database-Specific Configurations\n\nThe Vector Query Tool supports database-specific configurations that enable you to leverage unique features and optimizations of different vector stores:\n\n```ts showLineNumbers copy\n// Pinecone with namespace\nconst pineconeQueryTool = createVectorQueryTool({\n  vectorStoreName: \"pinecone\",\n  indexName: \"docs\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  databaseConfig: {\n    pinecone: {\n      namespace: \"production\"  // Isolate data by environment\n    }\n  }\n});\n\n// pgVector with performance tuning\nconst pgVectorQueryTool = createVectorQueryTool({\n  vectorStoreName: \"postgres\",\n  indexName: \"embeddings\", \n  model: openai.embedding(\"text-embedding-3-small\"),\n  databaseConfig: {\n    pgvector: {\n      minScore: 0.7,    // Filter low-quality results\n      ef: 200,          // HNSW search parameter\n      probes: 10        // IVFFlat probe parameter\n    }\n  }\n});\n\n// Chroma with advanced filtering\nconst chromaQueryTool = createVectorQueryTool({\n  vectorStoreName: \"chroma\",\n  indexName: \"documents\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  databaseConfig: {\n    chroma: {\n      where: { \"category\": \"technical\" },\n      whereDocument: { \"$contains\": \"API\" }\n    }\n  }\n});\n\n// LanceDB with table specificity\nconst lanceQueryTool = createVectorQueryTool({\n  vectorStoreName: \"lance\",\n  indexName: \"documents\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  databaseConfig: {\n    lance: {\n      tableName: \"myVectors\",     // Specify which table to query\n      includeAllColumns: true     // Include all metadata columns in results\n    }\n  }\n});\n```\n\n**Key Benefits:**\n- **Pinecone namespaces**: Organize vectors by tenant, environment, or data type\n- **pgVector optimization**: Control search accuracy and speed with ef/probes parameters\n- **Quality filtering**: Set minimum similarity thresholds to improve result relevance\n- **LanceDB tables**: Separate data into tables for better organization and performance\n- **Runtime flexibility**: Override configurations dynamically based on context\n\n**Common Use Cases:**\n- Multi-tenant applications using Pinecone namespaces\n- Performance optimization in high-load scenarios\n- Environment-specific configurations (dev/staging/prod)\n- Quality-gated search results\n- Embedded, file-based vector storage with LanceDB for edge deployment scenarios\n\nYou can also override these configurations at runtime using the runtime context:\n\n```ts showLineNumbers copy\nimport { RuntimeContext } from '@mastra/core/runtime-context';\n\nconst runtimeContext = new RuntimeContext();\nruntimeContext.set('databaseConfig', {\n  pinecone: {\n    namespace: 'runtime-namespace'\n  }\n});\n\nawait pineconeQueryTool.execute({\n  context: { queryText: 'search query' },\n  mastra,\n  runtimeContext\n});\n```\n\nFor detailed configuration options and advanced usage, see the [Vector Query Tool Reference](/reference/tools/vector-query-tool).\n\n### Vector Store Prompts\n\nVector store prompts define query patterns and filtering capabilities for each vector database implementation.\nWhen implementing filtering, these prompts are required in the agent's instructions to specify valid operators and syntax for each vector store implementation.\n\n{/* \nLLM CONTEXT: This Tabs component displays vector store configuration examples for different database providers.\nEach tab shows how to configure a RAG agent with the appropriate prompt for that specific vector store.\nThe tabs demonstrate the consistent pattern of importing the store-specific prompt and adding it to agent instructions.\nThis helps users understand how to properly configure their RAG agents for different vector database backends.\nThe providers include Pg Vector, Pinecone, Qdrant, Chroma, Astra, LibSQL, Upstash, Cloudflare, MongoDB, and OpenSearch.\n*/}\n<Tabs items={['Pg Vector', 'Pinecone', 'Qdrant', 'Chroma', 'Astra', 'LibSQL', 'Upstash', 'Cloudflare', 'MongoDB', 'OpenSearch']}>\n  <Tabs.Tab>\n```ts showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { PGVECTOR_PROMPT } from \"@mastra/pg\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${PGVECTOR_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { PINECONE_PROMPT } from \"@mastra/pinecone\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${PINECONE_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { QDRANT_PROMPT } from \"@mastra/qdrant\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${QDRANT_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { CHROMA_PROMPT } from \"@mastra/chroma\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${CHROMA_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { ASTRA_PROMPT } from \"@mastra/astra\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${ASTRA_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { LIBSQL_PROMPT } from \"@mastra/libsql\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${LIBSQL_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { UPSTASH_PROMPT } from \"@mastra/upstash\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${UPSTASH_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { VECTORIZE_PROMPT } from \"@mastra/vectorize\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${VECTORIZE_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { MONGODB_PROMPT } from \"@mastra/mongodb\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${MONGODB_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { openai } from '@ai-sdk/openai';\nimport { OPENSEARCH_PROMPT } from \"@mastra/opensearch\";\n\nexport const ragAgent = new Agent({\n  name: 'RAG Agent',\n  model: openai('gpt-4o-mini'),\n  instructions: `\n  Process queries using the provided context. Structure responses to be concise and relevant.\n  ${OPENSEARCH_PROMPT}\n  `,\n  tools: { vectorQueryTool },\n});\n```\n</Tabs.Tab>\n\n</Tabs>\n\n### Re-ranking\n\nInitial vector similarity search can sometimes miss nuanced relevance. Re-ranking is a more computationally expensive process, but more accurate algorithm that improves results by:\n\n- Considering word order and exact matches\n- Applying more sophisticated relevance scoring\n- Using a method called cross-attention between query and documents\n\nHere's how to use re-ranking:\n\n```ts showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { \n  rerankWithScorer as rerank, \n  MastraAgentRelevanceScorer \n} from \"@mastra/rag\";\n\n// Get initial results from vector search\nconst initialResults = await pgVector.query({\n  indexName: \"embeddings\",\n  queryVector: queryEmbedding,\n  topK: 10,\n});\n\n// Create a relevance scorer\nconst relevanceProvider = new MastraAgentRelevanceScorer('relevance-scorer', openai(\"gpt-4o-mini\"));\n\n// Re-rank the results\nconst rerankedResults = await rerank({\n  results: initialResults,\n  query,\n  provider: relevanceProvider,\n  options: {\n    topK: 10,\n  },\n);\n```\n\n> **Note:** For semantic scoring to work properly during re-ranking, each result must include the text content in its `metadata.text` field.\n\nYou can also use other relevance score providers like Cohere or ZeroEntropy:\n\n```ts showLineNumbers copy\nconst relevanceProvider = new CohereRelevanceScorer('rerank-v3.5');\n```\n\n```ts showLineNumbers copy\nconst relevanceProvider = new ZeroEntropyRelevanceScorer('zerank-1');\n```\n\nThe re-ranked results combine vector similarity with semantic understanding to improve retrieval quality.\n\nFor more details about re-ranking, see the [rerank()](/reference/rag/rerankWithScorer) method.\n\nFor an example of how to use the re-ranking method, see the [Re-ranking Results](../../examples/rag/rerank/rerank.mdx) example.\n\n### Graph-based Retrieval\n\nFor documents with complex relationships, graph-based retrieval can follow connections between chunks. This helps when:\n\n- Information is spread across multiple documents\n- Documents reference each other\n- You need to traverse relationships to find complete answers\n\nExample setup:\n\n```ts showLineNumbers copy\nconst graphQueryTool = createGraphQueryTool({\n  vectorStoreName: \"pgVector\",\n  indexName: \"embeddings\",\n  model: openai.embedding(\"text-embedding-3-small\"),\n  graphOptions: {\n    threshold: 0.7,\n  },\n});\n```\n\nFor more details about graph-based retrieval, see the [GraphRAG](/reference/rag/graph-rag) class and the [createGraphQueryTool()](/reference/tools/graph-rag-tool) function.\n\nFor an example of how to use the graph-based retrieval method, see the [Graph-based Retrieval](../../examples/rag/usage/graph-rag.mdx) example.\n\n\n---\ntitle: \"Storing Embeddings in A Vector Database | Mastra Docs\"\ndescription: Guide on vector storage options in Mastra, including embedded and dedicated vector databases for similarity search.\n---\n\nimport { Tabs } from \"nextra/components\";\n\n## Storing Embeddings in A Vector Database\n[EN] Source: https://mastra.ai/en/docs/rag/vector-databases\n\nAfter generating embeddings, you need to store them in a database that supports vector similarity search. Mastra provides a consistent interface for storing and querying embeddings across various vector databases.\n\n## Supported Databases\n\n{/*\nLLM CONTEXT: This Tabs component showcases different vector database implementations supported by Mastra.\nEach tab demonstrates the setup and configuration for a specific vector database provider.\nThe tabs show consistent API patterns across different databases, helping users understand how to switch between providers.\nEach tab includes import statements, initialization code, and basic operations (createIndex, upsert) for that specific database.\nThe providers include Pg Vector, Pinecone, Qdrant, Chroma, Astra, LibSQL, Upstash, Cloudflare, MongoDB, OpenSearch, and Couchbase.\n*/}\n\n<Tabs items={['MongoDB', 'Pg Vector', 'Pinecone', 'Qdrant', 'Chroma', 'Astra', 'LibSQL', 'Upstash', 'Cloudflare', 'OpenSearch', 'Couchbase', 'LanceDB']}>\n  <Tabs.Tab>\n    ```ts filename=\"vector-store.ts\" showLineNumbers copy\n    import { MongoDBVector } from '@mastra/mongodb'\n\n    const store = new MongoDBVector({\n      uri: process.env.MONGODB_URI,\n      dbName: process.env.MONGODB_DATABASE\n    })\n    await store.createIndex({\n      indexName: \"myCollection\",\n      dimension: 1536,\n    });\n    await store.upsert({\n      indexName: \"myCollection\",\n      vectors: embeddings,\n      metadata: chunks.map(chunk => ({ text: chunk.text })),\n    });\n\n    ```\n    ### Using MongoDB Atlas Vector search\n\n    For detailed setup instructions and best practices, see the [official MongoDB Atlas Vector Search documentation](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-overview/?utm_campaign=devrel&utm_source=third-party-content&utm_medium=cta&utm_content=mastra-docs). \n  </Tabs.Tab>\n\n  <Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { PgVector } from '@mastra/pg';\n\n  const store = new PgVector({ connectionString: process.env.POSTGRES_CONNECTION_STRING })\n\n  await store.createIndex({\n    indexName: \"myCollection\",\n    dimension: 1536,\n  });\n\n  await store.upsert({\n    indexName: \"myCollection\",\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n```\n\n### Using PostgreSQL with pgvector\n\nPostgreSQL with the pgvector extension is a good solution for teams already using PostgreSQL who want to minimize infrastructure complexity.\nFor detailed setup instructions and best practices, see the [official pgvector repository](https://github.com/pgvector/pgvector).\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { PineconeVector } from '@mastra/pinecone'\n\nconst store = new PineconeVector({\n  apiKey: process.env.PINECONE_API_KEY,\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { QdrantVector } from '@mastra/qdrant'\n\n  const store = new QdrantVector({\n    url: process.env.QDRANT_URL,\n    apiKey: process.env.QDRANT_API_KEY\n  })\n\n  await store.createIndex({\n    indexName: \"myCollection\",\n    dimension: 1536,\n  });\n\n  await store.upsert({\n    indexName: \"myCollection\",\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { ChromaVector } from '@mastra/chroma'\n\nconst store = new ChromaVector()\n\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\n\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { AstraVector } from '@mastra/astra'\n\n  const store = new AstraVector({\n    token: process.env.ASTRA_DB_TOKEN,\n    endpoint: process.env.ASTRA_DB_ENDPOINT,\n    keyspace: process.env.ASTRA_DB_KEYSPACE\n  })\n\n  await store.createIndex({\n    indexName: \"myCollection\",\n    dimension: 1536,\n  });\n\n  await store.upsert({\n    indexName: \"myCollection\",\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n\n```\n</Tabs.Tab>\n\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { LibSQLVector } from \"@mastra/core/vector/libsql\";\n\nconst store = new LibSQLVector({\n  connectionUrl: process.env.DATABASE_URL,\n  authToken: process.env.DATABASE_AUTH_TOKEN // Optional: for Turso cloud databases\n})\n\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\n\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { UpstashVector } from '@mastra/upstash'\n\n  // In upstash they refer to the store as an index\n  const store = new UpstashVector({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN\n  })\n\n  // There is no store.createIndex call here, Upstash creates indexes (known as namespaces in Upstash) automatically\n  // when you upsert if that namespace does not exist yet.\n  await store.upsert({\n    indexName: \"myCollection\", // the namespace name in Upstash\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n```\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { CloudflareVector } from '@mastra/vectorize'\n\nconst store = new CloudflareVector({\n  accountId: process.env.CF_ACCOUNT_ID,\n  apiToken: process.env.CF_API_TOKEN\n})\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n</Tabs.Tab>\n\n<Tabs.Tab>\n```ts filename=\"vector-store.ts\" showLineNumbers copy\nimport { OpenSearchVector } from '@mastra/opensearch'\n\nconst store = new OpenSearchVector({ url: process.env.OPENSEARCH_URL })\n\nawait store.createIndex({\n  indexName: \"my-collection\",\n  dimension: 1536,\n});\n\nawait store.upsert({\n  indexName: \"my-collection\",\n  vectors: embeddings,\n  metadata: chunks.map(chunk => ({ text: chunk.text })),\n});\n```\n\n</Tabs.Tab>\n<Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { CouchbaseVector } from '@mastra/couchbase'\n\n  const store = new CouchbaseVector({\n    connectionString: process.env.COUCHBASE_CONNECTION_STRING,\n    username: process.env.COUCHBASE_USERNAME,\n    password: process.env.COUCHBASE_PASSWORD,\n    bucketName: process.env.COUCHBASE_BUCKET,\n    scopeName: process.env.COUCHBASE_SCOPE,\n    collectionName: process.env.COUCHBASE_COLLECTION,\n  })\n  await store.createIndex({\n    indexName: \"myCollection\",\n    dimension: 1536,\n  });\n  await store.upsert({\n    indexName: \"myCollection\",\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n  ```\n</Tabs.Tab>\n<Tabs.Tab>\n  ```ts filename=\"vector-store.ts\" showLineNumbers copy\n  import { LanceVectorStore } from '@mastra/lance'\n\n  const store = await LanceVectorStore.create('/path/to/db')\n  \n  await store.createIndex({\n    tableName: \"myVectors\",\n    indexName: \"myCollection\",\n    dimension: 1536,\n  });\n  \n  await store.upsert({\n    tableName: \"myVectors\",\n    vectors: embeddings,\n    metadata: chunks.map(chunk => ({ text: chunk.text })),\n  });\n  ```\n\n  ### Using LanceDB\n  \n  LanceDB is an embedded vector database built on the Lance columnar format, suitable for local development or cloud deployment.\n  For detailed setup instructions and best practices, see the [official LanceDB documentation](https://lancedb.github.io/lancedb/).\n</Tabs.Tab>\n</Tabs>\n\n## Using Vector Storage\n\nOnce initialized, all vector stores share the same interface for creating indexes, upserting embeddings, and querying.\n\n### Creating Indexes\n\nBefore storing embeddings, you need to create an index with the appropriate dimension size for your embedding model:\n\n```ts filename=\"store-embeddings.ts\" showLineNumbers copy\n// Create an index with dimension 1536 (for text-embedding-3-small)\nawait store.createIndex({\n  indexName: \"myCollection\",\n  dimension: 1536,\n});\n```\n\nThe dimension size must match the output dimension of your chosen embedding model. Common dimension sizes are:\n\n- OpenAI text-embedding-3-small: 1536 dimensions (or custom, e.g., 256)\n- Cohere embed-multilingual-v3: 1024 dimensions\n- Google `text-embedding-004`: 768 dimensions (or custom)\n\n> **Important**: Index dimensions cannot be changed after creation. To use a different model, delete and recreate the index with the new dimension size.\n\n### Naming Rules for Databases\n\nEach vector database enforces specific naming conventions for indexes and collections to ensure compatibility and prevent conflicts.\n\n{/*\nLLM CONTEXT: This Tabs component displays naming convention rules for different vector databases.\nEach tab explains the specific naming requirements and restrictions for that database provider.\nThis helps users understand the constraints and avoid naming conflicts when creating indexes or collections.\nThe tabs provide examples of valid and invalid names to clarify the rules for each database.\n*/}\n\n<Tabs items={['MongoDB', 'Pg Vector', 'Pinecone', 'Qdrant', 'Chroma', 'Astra', 'LibSQL', 'Upstash', 'Cloudflare', 'OpenSearch']}>\n  <Tabs.Tab>\n    Collection (index) names must:\n    - Start with a letter or underscore\n    - Be up to 120 bytes long\n    - Contain only letters, numbers, underscores, or dots\n    - Cannot contain `$` or the null character\n    - Example: `my_collection.123` is valid\n    - Example: `my-index` is not valid (contains hyphen)\n    - Example: `My$Collection` is not valid (contains `$`)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Index names must:\n    - Start with a letter or underscore\n    - Contain only letters, numbers, and underscores\n    - Example: `my_index_123` is valid\n    - Example: `my-index` is not valid (contains hyphen)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Index names must:\n    - Use only lowercase letters, numbers, and dashes\n    - Not contain dots (used for DNS routing)\n    - Not use non-Latin characters or emojis\n    - Have a combined length (with project ID) under 52 characters\n      - Example: `my-index-123` is valid\n      - Example: `my.index` is not valid (contains dot)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Collection names must:\n    - Be 1-255 characters long\n    - Not contain any of these special characters:\n      - `< > : \" / \\ | ? *`\n      - Null character (`\\0`)\n      - Unit separator (`\\u{1F}`)\n    - Example: `my_collection_123` is valid\n    - Example: `my/collection` is not valid (contains slash)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Collection names must:\n    - Be 3-63 characters long\n    - Start and end with a letter or number\n    - Contain only letters, numbers, underscores, or hyphens\n    - Not contain consecutive periods (..)\n    - Not be a valid IPv4 address\n    - Example: `my-collection-123` is valid\n    - Example: `my..collection` is not valid (consecutive periods)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Collection names must:\n    - Not be empty\n    - Be 48 characters or less\n    - Contain only letters, numbers, and underscores\n    - Example: `my_collection_123` is valid\n    - Example: `my-collection` is not valid (contains hyphen)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Index names must:\n    - Start with a letter or underscore\n    - Contain only letters, numbers, and underscores\n    - Example: `my_index_123` is valid\n    - Example: `my-index` is not valid (contains hyphen)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Namespace names must:\n    - Be 2-100 characters long\n    - Contain only:\n      - Alphanumeric characters (a-z, A-Z, 0-9)\n      - Underscores, hyphens, dots\n    - Not start or end with special characters (_, -, .)\n    - Can be case-sensitive\n    - Example: `MyNamespace123` is valid\n    - Example: `_namespace` is not valid (starts with underscore)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Index names must:\n    - Start with a letter\n    - Be shorter than 32 characters\n    - Contain only lowercase ASCII letters, numbers, and dashes\n    - Use dashes instead of spaces\n    - Example: `my-index-123` is valid\n    - Example: `My_Index` is not valid (uppercase and underscore)\n  </Tabs.Tab>\n  <Tabs.Tab>\n    Index names must:\n    - Use only lowercase letters\n    - Not begin with underscores or hyphens\n    - Not contain spaces, commas\n    - Not contain special characters (e.g. `:`, `\"`, `*`, `+`, `/`, `\\`, `|`, `?`, `#`, `>`, `<`)\n    - Example: `my-index-123` is valid\n    - Example: `My_Index` is not valid (contains uppercase letters)\n    - Example: `_myindex` is not valid (begins with underscore)\n  </Tabs.Tab>\n</Tabs>\n\n### Upserting Embeddings\n\nAfter creating an index, you can store embeddings along with their basic metadata:\n\n```ts filename=\"store-embeddings.ts\" showLineNumbers copy\n// Store embeddings with their corresponding metadata\nawait store.upsert({\n  indexName: \"myCollection\", // index name\n  vectors: embeddings, // array of embedding vectors\n  metadata: chunks.map((chunk) => ({\n    text: chunk.text, // The original text content\n    id: chunk.id, // Optional unique identifier\n  })),\n});\n```\n\nThe upsert operation:\n\n- Takes an array of embedding vectors and their corresponding metadata\n- Updates existing vectors if they share the same ID\n- Creates new vectors if they don't exist\n- Automatically handles batching for large datasets\n\nFor complete examples of upserting embeddings in different vector stores, see the [Upsert Embeddings](../../examples/rag/upsert/upsert-embeddings.mdx) guide.\n\n## Adding Metadata\n\nVector stores support rich metadata (any JSON-serializable fields) for filtering and organization. Since metadata is stored with no fixed schema, use consistent field naming to avoid unexpected query results.\n\n**Important**: Metadata is crucial for vector storage - without it, you'd only have numerical embeddings with no way to return the original text or filter results. Always store at least the source text as metadata.\n\n```ts showLineNumbers copy\n// Store embeddings with rich metadata for better organization and filtering\nawait store.upsert({\n  indexName: \"myCollection\",\n  vectors: embeddings,\n  metadata: chunks.map((chunk) => ({\n    // Basic content\n    text: chunk.text,\n    id: chunk.id,\n\n    // Document organization\n    source: chunk.source,\n    category: chunk.category,\n\n    // Temporal metadata\n    createdAt: new Date().toISOString(),\n    version: \"1.0\",\n\n    // Custom fields\n    language: chunk.language,\n    author: chunk.author,\n    confidenceScore: chunk.score,\n  })),\n});\n```\n\nKey metadata considerations:\n\n- Be strict with field naming - inconsistencies like 'category' vs 'Category' will affect queries\n- Only include fields you plan to filter or sort by - extra fields add overhead\n- Add timestamps (e.g., 'createdAt', 'lastUpdated') to track content freshness\n\n## Best Practices\n\n- Create indexes before bulk insertions\n- Use batch operations for large insertions (the upsert method handles batching automatically)\n- Only store metadata you'll query against\n- Match embedding dimensions to your model (e.g., 1536 for `text-embedding-3-small`)\n\n\n---\ntitle: \"Advanced Tool Usage | Tools & MCP | Mastra Docs\"\ndescription: This page covers advanced features for Mastra tools, including abort signals and compatibility with the Vercel AI SDK tool format.\n---\n\n# Advanced Tool Usage\n[EN] Source: https://mastra.ai/en/docs/tools-mcp/advanced-usage\n\nThis page covers more advanced techniques and features related to using tools in Mastra.\n\n## Abort Signals\n\nWhen you initiate an agent interaction using `generate()` or `stream()`, you can provide an `AbortSignal`. Mastra automatically forwards this signal to any tool executions that occur during that interaction.\n\nThis allows you to cancel long-running operations within your tools, such as network requests or intensive computations, if the parent agent call is aborted.\n\nYou access the `abortSignal` in the second parameter of the tool's `execute` function.\n\n```typescript\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nexport const longRunningTool = createTool({\n  id: \"long-computation\",\n  description: \"Performs a potentially long computation\",\n  inputSchema: z.object({ /* ... */ }),\n  execute: async ({ context }, { abortSignal }) => {\n    // Example: Forwarding signal to fetch\n    const response = await fetch(\"https://api.example.com/data\", {\n      signal: abortSignal, // Pass the signal here\n    });\n\n    if (abortSignal?.aborted) {\n      console.log(\"Tool execution aborted.\");\n      throw new Error(\"Aborted\");\n    }\n\n    // Example: Checking signal during a loop\n    for (let i = 0; i < 1000000; i++) {\n      if (abortSignal?.aborted) {\n        console.log(\"Tool execution aborted during loop.\");\n        throw new Error(\"Aborted\");\n      }\n      // ... perform computation step ...\n    }\n\n    const data = await response.json();\n    return { result: data };\n  },\\n});\n```\n\nTo use this, provide an `AbortController`'s signal when calling the agent:\n\n```typescript\nimport { Agent } from \"@mastra/core/agent\";\n// Assume 'agent' is an Agent instance with longRunningTool configured\n\nconst controller = new AbortController();\n\n// Start the agent call\nconst promise = agent.generate(\"Perform the long computation.\", {\n  abortSignal: controller.signal,\n});\n\n// Sometime later, if needed:\n// controller.abort();\n\ntry {\n  const result = await promise;\n  console.log(result.text);\n} catch (error) {\n  if (error.name === \"AbortError\") {\n    console.log(\"Agent generation was aborted.\");\n  } else {\n    console.error(\"An error occurred:\", error);\n  }\n}\n```\n\n## AI SDK Tool Format\n\nMastra maintains compatibility with the tool format used by the Vercel AI SDK (`ai` package). You can define tools using the `tool` function from the `ai` package and use them directly within your Mastra agents alongside tools created with Mastra's `createTool`.\n\nFirst, ensure you have the `ai` package installed:\n\n```bash npm2yarn copy\nnpm install ai\n```\n\nHere's an example of a tool defined using the Vercel AI SDK format:\n\n```typescript filename=\"src/mastra/tools/vercelWeatherTool.ts\" copy\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\n\nexport const vercelWeatherTool = tool({\n  description: \"Fetches current weather using Vercel AI SDK format\",\n  parameters: z.object({\n    city: z.string().describe(\"The city to get weather for\"),\n  }),\n  execute: async ({ city }) => {\n    console.log(`Fetching weather for ${city} (Vercel format tool)`);\n    // Replace with actual API call\n    const data = await fetch(`https://api.example.com/weather?city=${city}`);\n    return data.json();\n  },\n});\n```\n\nYou can then add this tool to your Mastra agent just like any other tool:\n\n```typescript filename=\"src/mastra/agents/mixedToolsAgent.ts\"\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { vercelWeatherTool } from \"../tools/vercelWeatherTool\"; // Vercel AI SDK tool\nimport { mastraTool } from \"../tools/mastraTool\"; // Mastra createTool tool\n\nexport const mixedToolsAgent = new Agent({\n  name: \"Mixed Tools Agent\",\n  instructions: \"You can use tools defined in different formats.\",\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    weatherVercel: vercelWeatherTool,\n    someMastraTool: mastraTool,\n  },\n});\n```\n\nMastra supports both tool formats, allowing you to mix and match as needed.\n\n\n---\ntitle: \"Dynamic Tool Context | Tools & MCP | Mastra Docs\"\ndescription: Learn how to use Mastra's RuntimeContext to provide dynamic, request-specific configuration to tools.\n---\n\nimport { Callout } from \"nextra/components\";\n\n# Dynamic Tool Context\n[EN] Source: https://mastra.ai/en/docs/tools-mcp/dynamic-context\n\nMastra provides `RuntimeContext`, a system based on dependency injection, that allows you to pass dynamic, request-specific configuration to your tools during execution. This is useful when a tool's behavior needs to change based on user identity, request headers, or other runtime factors, without altering the tool's core code.\n\n<Callout>\n  **Note:** `RuntimeContext` is primarily used for passing data *into* tool\n  executions. It's distinct from agent memory, which handles conversation\n  history and state persistence across multiple calls.\n</Callout>\n\n## Basic Usage\n\nTo use `RuntimeContext`, first define a type structure for your dynamic configuration. Then, create an instance of `RuntimeContext` typed with your definition and set the desired values. Finally, include the `runtimeContext` instance in the options object when calling `agent.generate()` or `agent.stream()`.\n\n```typescript\nimport { RuntimeContext } from \"@mastra/core/di\";\n// Assume 'agent' is an already defined Mastra Agent instance\n\n// Define the context type\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\";\n};\n\n// Instantiate RuntimeContext and set values\nconst runtimeContext = new RuntimeContext<WeatherRuntimeContext>();\nruntimeContext.set(\"temperature-scale\", \"celsius\");\n\n// Pass to agent call\nconst response = await agent.generate(\"What's the weather like today?\", {\n  runtimeContext, // Pass the context here\n});\n\nconsole.log(response.text);\n```\n\n## Accessing Context in Tools\n\nTools receive the `runtimeContext` as part of the second argument to their `execute` function. You can then use the `.get()` method to retrieve values.\n\n```typescript filename=\"src/mastra/tools/weather-tool.ts\"\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n// Assume WeatherRuntimeContext is defined as above and accessible here\n\n// Dummy fetch function\nasync function fetchWeather(\n  location: string,\n  options: { temperatureUnit: \"celsius\" | \"fahrenheit\" },\n): Promise<any> {\n  console.log(`Fetching weather for ${location} in ${options.temperatureUnit}`);\n  // Replace with actual API call\n  return { temperature: options.temperatureUnit === \"celsius\" ? 20 : 68 };\n}\n\nexport const weatherTool = createTool({\n  id: \"getWeather\",\n  description: \"Get the current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"The location to get weather for\"),\n  }),\n  // The tool's execute function receives runtimeContext\n  execute: async ({ context, runtimeContext }) => {\n    // Type-safe access to runtimeContext variables\n    const temperatureUnit = runtimeContext.get(\"temperature-scale\");\n\n    // Use the context value in the tool logic\n    const weather = await fetchWeather(context.location, {\n      temperatureUnit,\n    });\n\n    return {\n      result: `The temperature is ${weather.temperature}Â°${temperatureUnit === \"celsius\" ? \"C\" : \"F\"}`,\n    };\n  },\n});\n```\n\nWhen the agent uses `weatherTool`, the `temperature-scale` value set in the `runtimeContext` during the `agent.generate()` call will be available inside the tool's `execute` function.\n\n## Using with Server Middleware\n\nIn server environments (like Express or Next.js), you can use middleware to automatically populate `RuntimeContext` based on incoming request data, such as headers or user sessions.\n\nHere's an example using Mastra's built-in server middleware support (which uses Hono internally) to set the temperature scale based on the Cloudflare `CF-IPCountry` header:\n\n```typescript filename=\"src/mastra/index.ts\"\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { weatherAgent } from \"./agents/weather\"; // Assume agent is defined elsewhere\n\n// Define RuntimeContext type\ntype WeatherRuntimeContext = {\n  \"temperature-scale\": \"celsius\" | \"fahrenheit\";\n};\n\nexport const mastra = new Mastra({\n  agents: {\n    weather: weatherAgent,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        // Get the RuntimeContext instance\n        const runtimeContext =\n          c.get<RuntimeContext<WeatherRuntimeContext>>(\"runtimeContext\");\n\n        // Get country code from request header\n        const country = c.req.header(\"CF-IPCountry\");\n\n        // Set temperature scale based on country\n        runtimeContext.set(\n          \"temperature-scale\",\n          country === \"US\" ? \"fahrenheit\" : \"celsius\",\n        );\n\n        // Continue request processing\n        await next();\n      },\n    ],\n  },\n});\n```\n\nWith this middleware in place, any agent call handled by this Mastra server instance will automatically have the `temperature-scale` set in its `RuntimeContext` based on the user's inferred country, and tools like `weatherTool` will use it accordingly.\n\n\n---\ntitle: \"MCP Overview | Tools & MCP | Mastra Docs\"\ndescription: Learn about the Model Context Protocol (MCP), how to use third-party tools via MCPClient, connect to registries, and share your own tools using MCPServer.\n---\n\nimport { Tabs } from \"nextra/components\";\n\n# MCP Overview\n[EN] Source: https://mastra.ai/en/docs/tools-mcp/mcp-overview\n\n[Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction) is an open standard designed to let AI models discover and interact with external tools and resources. Think of it as a universal plugin system for AI agents, allowing them to use tools regardless of the language they were written in or where they are hosted.\n\nMastra uses MCP to connect agents to external tool servers.\n\n## Use third-party tools with an MCP Client\n\nMastra provides the `MCPClient` class to manage connections to one or more MCP servers and access their tools.\n\n### Installation\n\nIf you haven't already, install the Mastra MCP package:\n\n```bash npm2yarn copy\nnpm install @mastra/mcp@latest\n```\n\n### Registering the MCPServer\n\nRegister your MCP server with Mastra to enable logging and access to configured tools and integrations:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { myMcpServer } from \"./mcpServers\";\n\nexport const mastra = new Mastra({\n  mcpServers: { myMcpServer },\n});\n```\n\n### Configuring `MCPClient`\n\nYou configure `MCPClient` with a map of servers you want to connect to. It supports connections via subprocess (Stdio) or HTTP (Streamable HTTP with SSE fallback).\n\n```typescript\nimport { MCPClient } from \"@mastra/mcp\";\n\nconst mcp = new MCPClient({\n  servers: {\n    // Stdio example\n    sequential: {\n      command: \"npx\",\n      args: [\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"],\n    },\n    // HTTP example\n    weather: {\n      url: new URL(\"http://localhost:8080/mcp\"),\n      requestInit: {\n        headers: {\n          Authorization: \"Bearer your-token\",\n        },\n      },\n    },\n  },\n});\n```\n\nFor detailed configuration options, see the [`MCPClient` reference documentation](/reference/tools/mcp-client).\n\n### Static vs Dynamic Tool Configurations\n\n`MCPClient` offers two approaches to retrieving tools from connected servers, suitable for different application architectures:\n\n| Feature           | Static Configuration (`await mcp.getTools()`) | Dynamic Configuration (`await mcp.getToolsets()`)  |\n| :---------------- | :-------------------------------------------- | :------------------------------------------------- |\n| **Use Case**      | Single-user, static config (e.g., CLI tool)   | Multi-user, dynamic config (e.g., SaaS app)        |\n| **Configuration** | Fixed at agent initialization                 | Per-request, dynamic                               |\n| **Credentials**   | Shared across all uses                        | Can vary per user/request                          |\n| **Agent Setup**   | Tools added in `Agent` constructor            | Tools passed in `generate()` or `stream()` options |\n\n- **Static Configuration (`getTools()`):** Fetches all tools from all configured servers. Best when the tool configuration (like API keys) is static and shared across all users or requests. You typically call this once and pass the result to the `tools` property when defining your `Agent`.\n  [Reference: `getTools()`](/reference/tools/mcp-client#gettools)\n\n  ```typescript\n  import { Agent } from \"@mastra/core/agent\";\n  // ... mcp client setup\n\n  const agent = new Agent({\n    // ... other agent config\n    tools: await mcp.getTools(),\n  });\n  ```\n\n- **Dynamic Configuration (`getToolsets()`):** Designed for scenarios where configuration might change per request or per user (e.g., different API keys for different tenants in a multi-user application). You pass the result of `getToolsets()` to the `toolsets` option in the agent's `generate()` or `stream()` method.\n  [Reference: `getToolsets()`](/reference/tools/mcp-client#gettoolsets)\n\n  ```typescript\n  import { Agent } from \"@mastra/core/agent\";\n  // ... agent setup without tools initially\n\n  async function handleRequest(userPrompt: string, userApiKey: string) {\n    const userMcp = new MCPClient({\n      /* config with userApiKey */\n    });\n    const toolsets = await userMcp.getToolsets();\n\n    const response = await agent.stream(userPrompt, {\n      toolsets, // Pass dynamic toolsets\n    });\n    // ... handle response\n    await userMcp.disconnect();\n  }\n  ```\n\n## Connecting to an MCP registry\n\nMCP servers can be discovered through registries. Here's how to connect to some popular ones using `MCPClient`:\n\n\n{/*\nLLM CONTEXT: This Tabs component shows how to connect to different MCP (Model Context Protocol) registries.\nEach tab demonstrates the configuration for a specific MCP registry service (mcp.run, Composio.dev, Smithery.ai).\nThe tabs help users understand how to connect to various MCP server providers and their different authentication methods.\nEach tab shows the specific URL patterns and configuration needed for that registry service.\n*/}\n\n<Tabs items={[\"mcp.run\", \"Composio.dev\", \"Smithery.ai\", \"Ampersand\"]}>\n  <Tabs.Tab>\n    [mcp.run](https://www.mcp.run/) provides pre-authenticated, managed MCP servers. Tools are grouped into Profiles, each with a unique, signed URL.\n\n    ```typescript\n    import { MCPClient } from \"@mastra/mcp\";\n\n    const mcp = new MCPClient({\n      servers: {\n        marketing: { // Example profile name\n          url: new URL(process.env.MCP_RUN_SSE_URL!), // Get URL from mcp.run profile\n        },\n      },\n    });\n    ```\n\n    > **Important:** Treat the mcp.run SSE URL like a password. Store it securely, for example, in an environment variable.\n    > ```bash filename=\".env\"\n    > MCP_RUN_SSE_URL=https://www.mcp.run/api/mcp/sse?nonce=...\n    > ```\n\n  </Tabs.Tab>\n  <Tabs.Tab>\n    [Composio.dev](https://composio.dev) offers a registry of [SSE-based MCP servers](https://mcp.composio.dev). You can use the SSE URL generated for tools like Cursor directly.\n\n    ```typescript\n    import { MCPClient } from \"@mastra/mcp\";\n\n    const mcp = new MCPClient({\n      servers: {\n        googleSheets: {\n          url: new URL(\"https://mcp.composio.dev/googlesheets/[private-url-path]\"),\n        },\n        gmail: {\n          url: new URL(\"https://mcp.composio.dev/gmail/[private-url-path]\"),\n        },\n      },\n    });\n    ```\n\n    Authentication with services like Google Sheets often happens interactively through the agent conversation.\n\n    *Note: Composio URLs are typically tied to a single user account, making them best suited for personal automation rather than multi-tenant applications.*\n\n  </Tabs.Tab>\n  <Tabs.Tab>\n    [Smithery.ai](https://smithery.ai) provides a registry accessible via their CLI.\n\n    ```typescript\n    // Unix/Mac\n    import { MCPClient } from \"@mastra/mcp\";\n\n    const mcp = new MCPClient({\n      servers: {\n        sequentialThinking: {\n          command: \"npx\",\n          args: [\n            \"-y\",\n            \"@smithery/cli@latest\",\n            \"run\",\n            \"@smithery-ai/server-sequential-thinking\",\n            \"--config\",\n            \"{}\",\n          ],\n        },\n      },\n    });\n    ```\n\n    ```typescript\n    // Windows\n    import { MCPClient } from \"@mastra/mcp\";\n\n    const mcp = new MCPClient({\n      servers: {\n        sequentialThinking: {\n          command: \"npx\",\n          args: [\n            \"-y\",\n            \"@smithery/cli@latest\",\n            \"run\",\n            \"@smithery-ai/server-sequential-thinking\",\n            \"--config\",\n            \"{}\",\n          ],\n        },\n      },\n    });\n    ```\n\n  </Tabs.Tab>\n    <Tabs.Tab>\n\n    [Ampersand](https://withampersand.com?utm_source=mastra-docs) offers an [MCP Server](https://docs.withampersand.com/mcp) that allows you to connect your agent to 150+ integrations with SaaS products like Salesforce, Hubspot, and Zendesk.\n    \n\n    ```typescript\n\n    // MCPClient with Ampersand MCP Server using SSE\n    export const mcp = new MCPClient({\n        servers: {\n        \"@amp-labs/mcp-server\": {\n          \"url\": `https://mcp.withampersand.com/v1/sse?${new URLSearchParams({\n            apiKey: process.env.AMPERSAND_API_KEY,\n            project: process.env.AMPERSAND_PROJECT_ID,\n            integrationName: process.env.AMPERSAND_INTEGRATION_NAME,\n            groupRef: process.env.AMPERSAND_GROUP_REF\n          })}`\n        }\n      }\n    });\n\n    ```\n\n    ```typescript\n    // If you prefer to run the MCP server locally:\n    \n    import { MCPClient } from \"@mastra/mcp\";\n\n    // MCPClient with Ampersand MCP Server using stdio transport\n    export const mcp = new MCPClient({\n        servers: {\n          \"@amp-labs/mcp-server\": {\n            command: \"npx\",\n            args: [\n              \"-y\",\n              \"@amp-labs/mcp-server@latest\",\n              \"--transport\",\n              \"stdio\",\n              \"--project\",\n              process.env.AMPERSAND_PROJECT_ID,\n              \"--integrationName\",\n              process.env.AMPERSAND_INTEGRATION_NAME,\n              \"--groupRef\",\n              process.env.AMPERSAND_GROUP_REF, // optional\n            ],\n            env: {\n              AMPERSAND_API_KEY: process.env.AMPERSAND_API_KEY,\n            },\n          },\n        },\n    });\n    ```\n\n    As an alternative to MCP, Ampersand's AI SDK also has an adapter for Mastra, so you can [directly import Ampersand tools](https://docs.withampersand.com/ai-sdk#use-with-mastra) for your agent to access.\n\n  </Tabs.Tab>\n</Tabs>\n\n## Share your tools with an MCP server\n\nIf you have created your own Mastra tools, you can expose them to any MCP-compatible client using Mastra's `MCPServer` class.\n\nSimilarly, Mastra `Agent` and `Workflow` instances can also be exposed as tools via `MCPServer`. This allows other MCP clients to interact with your agents by \"asking\" them questions or run your workflows. Each agent provided in the `MCPServer` configuration will be converted into a tool named `ask_<agentKey>`, using the agent's `description` property. Each workflow will be converted into a tool named `run_<workflowKey>`, using its `inputSchema` and `description`.\n\nThis allows others to use your tools, agents, and workflows without needing direct access to your codebase.\n\n### Using `MCPServer`\n\nYou initialize `MCPServer` with a name, version, and the Mastra tools, agents, and/or workflows you want to share.\n\n```typescript\nimport { MCPServer } from \"@mastra/mcp\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { weatherTool } from \"./tools\"; // Your Mastra tool\nimport { weatherAgent } from \"./agents\"; // Your Mastra Agent\nimport { dataWorkflow } from \"./workflows\"; // Your Mastra Workflow\n\nconst server = new MCPServer({\n  name: \"My Custom Server\",\n  version: \"1.0.0\",\n  tools: { weatherTool }, // Provide your tool(s) here\n  agents: { weatherAgent }, // Provide your agent(s) here\n  workflows: { dataWorkflow }, // Provide your workflow(s) here\n});\n\n// Start the server (e.g., using stdio for a CLI tool)\n// await server.startStdio();\n\n// Or integrate with an HTTP server using startSSE()\n// See MCPServer reference for details\n```\n\nFor an agent to be exposed as a tool, it must have a non-empty `description` string. Similarly, for a workflow to be exposed, its `description` must also be a non-empty string. If the description is missing or empty for either, `MCPServer` will throw an error during initialization.\nWorkflows will use their `inputSchema` for the tool's input.\n\n### Tools with Structured Outputs\n\nYou can define an `outputSchema` for your tools to enforce a specific structure for the tool's output. This is useful for ensuring that the tool returns data in a consistent and predictable format, which can then be validated by the client.\n\nWhen a tool includes an `outputSchema`, its `execute` function **must** return an object. The value of the object must conform to the `outputSchema`. Mastra will automatically validate this output on both the server and client sides.\n\nHere's an example of a tool with an `outputSchema`:\n\n```typescript filename=\"src/tools/structured-tool.ts\"\nimport { createTool } from '@mastra/core';\nimport { z } from 'zod';\n\nexport const structuredTool = createTool({\n  description: 'A test tool that returns structured data.',\n  parameters: z.object({\n    input: z.string().describe('Some input string.'),\n  }),\n  outputSchema: z.object({\n    processedInput: z.string().describe('The processed input string.'),\n    timestamp: z.string().describe('An ISO timestamp.'),\n  }),\n  execute: async ({ input }) => {\n    // When outputSchema is defined, you must return an object\n    return {\n      processedInput: `processed: ${input}`,\n      timestamp: new Date().toISOString(),\n    };\n  },\n});\n```\n\nWhen this tool is called, the MCP client will receive both the structured data and a text representation of it.\n\n```\nTool result\n\n{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"{\\\"processedInput\\\": \\\"hello\\\", \\\"timestamp\\\": \\\"2025-06-19T16:53:16.472Z\\\"}\"\n    }\n  ],\n  \"structuredContent\": {\n    \"processedInput\": \"processed: hello\",\n    \"timestamp\": \"2025-06-19T16:53:16.472Z\",\n  }\n}\n```\n\nFor detailed usage and examples, see the [`MCPServer` reference documentation](/reference/tools/mcp-server).\n\n\n---\ntitle: \"Tools Overview | Tools & MCP | Mastra Docs\"\ndescription: Understand what tools are in Mastra, how to add them to agents, and best practices for designing effective tools.\n---\n\n# Tools Overview\n[EN] Source: https://mastra.ai/en/docs/tools-mcp/overview\n\nTools are functions that agents can execute to perform specific tasks or access external information. They extend an agent's capabilities beyond simple text generation, allowing interaction with APIs, databases, or other systems.\n\nEach tool typically defines:\n\n- **Inputs:** What information the tool needs to run (defined with an `inputSchema`, often using Zod).\n- **Outputs:** The structure of the data the tool returns (defined with an `outputSchema`).\n- **Execution Logic:** The code that performs the tool's action.\n- **Description:** Text that helps the agent understand what the tool does and when to use it.\n\n## Creating Tools\n\nIn Mastra, you create tools using the [`createTool`](/reference/tools/create-tool) function from the `@mastra/core/tools` package.\n\n```typescript filename=\"src/mastra/tools/weatherInfo.ts\" copy\nimport { createTool } from \"@mastra/core/tools\";\nimport { z } from \"zod\";\n\nconst getWeatherInfo = async (city: string) => {\n  // Replace with an actual API call to a weather service\n  console.log(`Fetching weather for ${city}...`);\n  // Example data structure\n  return { temperature: 20, conditions: \"Sunny\" };\n};\n\nexport const weatherTool = createTool({\n  id: \"Get Weather Information\",\n  description: `Fetches the current weather information for a given city`,\n  inputSchema: z.object({\n    city: z.string().describe(\"City name\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    conditions: z.string(),\n  }),\n  execute: async ({ context: { city } }) => {\n    console.log(\"Using tool to fetch weather information for\", city);\n    return await getWeatherInfo(city);\n  },\n});\n```\n\nThis example defines a `weatherTool` with an input schema for the city, an output schema for the weather data, and an `execute` function that contains the tool's logic.\n\nWhen creating tools, keep tool descriptions simple and focused on **what** the tool does and **when** to use it, emphasizing its primary use case. Technical details belong in the parameter schemas, guiding the agent on _how_ to use the tool correctly with descriptive names, clear descriptions, and explanations of default values.\n\n## Adding Tools to an Agent\n\nTo make tools available to an agent, you configure them in the agent's definition. Mentioning available tools and their general purpose in the agent's system prompt can also improve tool usage. For detailed steps and examples, see the guide on [Using Tools and MCP with Agents](/docs/agents/using-tools-and-mcp#add-tools-to-an-agent).\n\n## Compatibility Layer for Tool Schemas\n\nDifferent models interpret schemas differely. Some error when certain schema properties are passed and some ignore certain schema properties but don't throw an error. Mastra adds a compatibility layer for tool schemas, ensuring tools work consistently across different model providers and that the schema constraints are respected.\n\nSome providers that we include this layer for:\n\n- **Google Gemini & Anthropic:** Remove unsupported schema properties and append relevant constraints to the tool description.\n- **OpenAI (including reasoning models):** Strip or adapt schema fields that are ignored or unsupported, and add instructions to the description for agent guidance.\n- **DeepSeek & Meta:** Apply similar compatibility logic to ensure schema alignment and tool usability.\n\nThis approach makes tool usage more reliable and model-agnostic for both custom and MCP tools.\n\n\n---\ntitle: \"Branching, Merging, Conditions | Workflows | Mastra Docs\"\ndescription: \"Control flow in Mastra workflows allows you to manage branching, merging, and conditions to construct workflows that meet your logic requirements.\"\n---\n\n# Control Flow\n[EN] Source: https://mastra.ai/en/docs/workflows/control-flow\n\nWhen you build a workflow, you typically break down operations into smaller tasks that can be linked and reused. **Steps** provide a structured way to manage these tasks by defining inputs, outputs, and execution logic.\n\n- If the schemas match, the `outputSchema` from each step is automatically passed to the `inputSchema` of the next step.\n- If the schemas don't match, use [Input data mapping](./input-data-mapping.mdx) to transform the `outputSchema` into the expected `inputSchema`.\n\n## Chaining steps with `.then()`\n\nChain steps to execute sequentially using `.then()`:\n\n![Chaining steps with .then()](/image/workflows/workflows-control-flow-then.jpg)\n\n```typescript {8-9,4-5} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .then(step2)\n  .commit();\n```\n\nThis does what you'd expect: it executes `step1`, then it executes `step2`.\n\n## Simultaneous steps with `.parallel()`\n\nExecute steps simultaneously using `.parallel()`:\n\n![Concurrent steps with .parallel()](/image/workflows/workflows-control-flow-parallel.jpg)\n\n```typescript {8,4-5} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\nconst step3 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .parallel([step1, step2])\n  .then(step3)\n  .commit();\n```\n\nThis executes `step1` and `step2` concurrently, then continues to `step3` after both complete.\n\n> See [Parallel Execution with Steps](/examples/workflows/parallel-steps) for more information.\n\n## Conditional logic with `.branch()`\n\nExecute steps conditionally using `.branch()`:\n\n![Conditional branching with .branch()](/image/workflows/workflows-control-flow-branch.jpg)\n\n```typescript {8-11,4-5} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst lessThanStep = createStep({...});\nconst greaterThanStep = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .branch([\n    [async ({ inputData: { value } }) => (value < 9), lessThanStep],\n    [async ({ inputData: { value } }) => (value >= 9), greaterThanStep]\n  ])\n  .commit();\n```\n\nBranch conditions are evaluated sequentially, but steps with matching conditions are executed in parallel.\n\n> See [Workflow with Conditional Branching](/examples/workflows/conditional-branching) for more information.\n\n## Looping steps\n\nWorkflows support two types of loops. When looping a step, or any step-compatible construct like a nested workflow, the initial `inputData` is sourced from the output of the previous step.\n\nTo ensure compatibility, the loopâ€™s initial input must either match the shape of the previous stepâ€™s output, or be explicitly transformed using the `map` function.\n\n- Match the shape of the previous stepâ€™s output, or\n- Be explicitly transformed using the `map` function.\n\n### Repeating with `.dowhile()`\n\nExecutes step repeatedly while a condition is true.\n\n![Repeating with .dowhile()](/image/workflows/workflows-control-flow-dowhile.jpg)\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst counterStep = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .dowhile(counterStep, async ({ inputData: { number } }) => number < 10)\n  .commit();\n```\n\n### Repeating with `.dountil()`\n\nExecutes step repeatedly until a condition becomes true.\n\n![Repeating with .dountil()](/image/workflows/workflows-control-flow-dountil.jpg)\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst counterStep = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .dountil(counterStep, async ({ inputData: { number } }) => number > 10)\n  .commit();\n```\n\n### Repeating with `.foreach()`\n\nSequentially executes the same step for each item from the `inputSchema`.\n\n![Repeating with .foreach()](/image/workflows/workflows-control-flow-foreach.jpg)\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst mapStep = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .foreach(mapStep)\n  .commit();\n```\n\n#### Setting concurrency limits\n\nUse `concurrency` to execute steps in parallel with a limit on the number of concurrent executions.\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst mapStep = createStep({...})\n\nexport const testWorkflow = createWorkflow({...})\n  .foreach(mapStep, { concurrency: 2 })\n  .commit();\n```\n\n## Using a nested workflow\n\nUse a nested workflow as a step by passing it to `.then()`. This runs each of its steps in sequence as part of the parent workflow.\n\n```typescript {4,7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nexport const nestedWorkflow = createWorkflow({...})\n\nexport const testWorkflow = createWorkflow({...})\n  .then(nestedWorkflow)\n  .commit();\n```\n\n## Cloning a workflow\n\nUse `cloneWorkflow` to duplicate an existing workflow. This lets you reuse its structure while overriding parameters like `id`.\n\n```typescript {6,10} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep, cloneWorkflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst parentWorkflow = createWorkflow({...})\nconst clonedWorkflow = cloneWorkflow(parentWorkflow, { id: \"cloned-workflow\" });\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .then(clonedWorkflow)\n  .commit();\n```\n\n## Exiting early with `bail()`\n\nUse `bail()` in a step to exit early with a successful result. This returns the provided payload as the step output and ends workflow execution.\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({\n  id: 'step1',\n  execute: async ({ bail }) => {\n    return bail({ result: 'bailed' });\n  },\n  inputSchema: z.object({ value: z.string() }),\n  outputSchema: z.object({ result: z.string() }),\n});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .commit();\n```\n\n## Exiting early with `Error()`\n\nUse `throw new Error()` in a step to exit with an error.\n\n```typescript {7} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({\n  id: 'step1',\n  execute: async () => {\n    throw new Error('bailed');\n  },\n  inputSchema: z.object({ value: z.string() }),\n  outputSchema: z.object({ result: z.string() }),\n});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .commit();\n```\n\nThis throws an error from the step and stops workflow execution, returning the error as the result.\n\n## Example Run Instance\n\nThe following example demonstrates how to start a run with multiple inputs. Each input will pass through the `mapStep` sequentially.\n\n```typescript {6} filename=\"src/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.start({\n  inputData: [{ number: 10 }, { number: 100 }, { number: 200 }]\n});\n```\n\nTo execute this run from your terminal:\n\n```bash copy\nnpx tsx src/test-workflow.ts\n```\n\n\n---\ntitle: \"Inngest Workflows | Workflows | Mastra Docs\"\ndescription: \"Inngest workflow allows you to run Mastra workflows with Inngest\"\n---\n\n# Inngest Workflow\n[EN] Source: https://mastra.ai/en/docs/workflows/inngest-workflow\n\n[Inngest](https://www.inngest.com/docs) is a developer platform for building and running background workflows, without managing infrastructure.\n\n## How Inngest Works with Mastra\n\nInngest and Mastra integrate by aligning their workflow models: Inngest organizes logic into functions composed of steps, and Mastra workflows defined using `createWorkflow` and `createStep` map directly onto this paradigm. Each Mastra workflow becomes an Inngest function with a unique identifier, and each step within the workflow maps to an Inngest step.\n\nThe `serve` function bridges the two systems by registering Mastra workflows as Inngest functions and setting up the necessary event handlers for execution and monitoring.\n\nWhen an event triggers a workflow, Inngest executes it step by step, memoizing each stepâ€™s result. This means if a workflow is retried or resumed, completed steps are skipped, ensuring efficient and reliable execution. Control flow primitives in Mastra, such as loops, conditionals, and nested workflows are seamlessly translated into the same Inngestâ€™s function/step model, preserving advanced workflow features like composition, branching, and suspension.\n\nReal-time monitoring, suspend/resume, and step-level observability are enabled via Inngestâ€™s publish-subscribe system and dashboard. As each step executes, its state and output are tracked using Mastra storage and can be resumed as needed.\n\n## Setup\n\n```sh\nnpm install @mastra/inngest @mastra/core @mastra/deployer\n```\n\n## Building an Inngest Workflow\n\nThis guide walks through creating a workflow with Inngest and Mastra, demonstrating a counter application that increments a value until it reaches 10.\n\n### Inngest Initialization\n\nInitialize the Inngest integration to obtain Mastra-compatible workflow helpers. The createWorkflow and createStep functions are used to create workflow and step objects that are compatible with Mastra and inngest.\n\nIn development\n\n```ts showLineNumbers copy filename=\"src/mastra/inngest/index.ts\"\nimport { Inngest } from \"inngest\";\nimport { realtimeMiddleware } from \"@inngest/realtime\";\n\nexport const inngest = new Inngest({\n  id: \"mastra\",\n  baseUrl:\"http://localhost:3000\",\n  isDev: true,\n  middleware: [realtimeMiddleware()],\n});\n```\n\nIn production\n\n```ts showLineNumbers copy filename=\"src/mastra/inngest/index.ts\"\nimport { Inngest } from \"inngest\";\nimport { realtimeMiddleware } from \"@inngest/realtime\";\n\nexport const inngest = new Inngest({\n  id: \"mastra\",\n  middleware: [realtimeMiddleware()],\n});\n```\n\n### Creating Steps\n\nDefine the individual steps that will compose your workflow:\n\n```ts showLineNumbers copy filename=\"src/mastra/workflows/index.ts\"\nimport { z } from \"zod\";\nimport { inngest } from \"../inngest\";\nimport { init } from \"@mastra/inngest\";\n\n// Initialize Inngest with Mastra, pointing to your local Inngest server\nconst { createWorkflow, createStep } = init(inngest);\n\n// Step: Increment the counter value\nconst incrementStep = createStep({\n  id: \"increment\",\n  inputSchema: z.object({\n    value: z.number(),\n  }),\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n  execute: async ({ inputData }) => {\n    return { value: inputData.value + 1 };\n  },\n});\n```\n\n### Creating the Workflow\n\nCompose the steps into a workflow using the `dountil` loop pattern. The createWorkflow function creates a function on inngest server that is invocable.\n\n```ts showLineNumbers copy filename=\"src/mastra/workflows/index.ts\"\n// workflow that is registered as a function on inngest server\nconst workflow = createWorkflow({\n  id: \"increment-workflow\",\n  inputSchema: z.object({\n    value: z.number(),\n  }),\n  outputSchema: z.object({\n    value: z.number(),\n  }),\n}).then(incrementStep);\n\nworkflow.commit();\n\nexport { workflow as incrementWorkflow };\n```\n\n### Configuring the Mastra Instance and Executing the Workflow\n\nRegister the workflow with Mastra and configure the Inngest API endpoint:\n\n```ts showLineNumbers copy filename=\"src/mastra/index.ts\"\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { serve as inngestServe } from \"@mastra/inngest\";\nimport { incrementWorkflow } from \"./workflows\";\nimport { inngest } from \"./inngest\";\nimport { PinoLogger } from \"@mastra/loggers\";\n\n// Configure Mastra with the workflow and Inngest API endpoint\nexport const mastra = new Mastra({\n  workflows: {\n    incrementWorkflow,\n  },\n  server: {\n    // The server configuration is required to allow local docker container can connect to the mastra server\n    host: \"0.0.0.0\",\n    apiRoutes: [\n      // This API route is used to register the Mastra workflow (inngest function) on the inngest server\n      {\n        path: \"/api/inngest\",\n        method: \"ALL\",\n        createHandler: async ({ mastra }) => inngestServe({ mastra, inngest }),\n        // The inngestServe function integrates Mastra workflows with Inngest by:\n        // 1. Creating Inngest functions for each workflow with unique IDs (workflow.${workflowId})\n        // 2. Setting up event handlers that:\n        //    - Generate unique run IDs for each workflow execution\n        //    - Create an InngestExecutionEngine to manage step execution\n        //    - Handle workflow state persistence and real-time updates\n        // 3. Establishing a publish-subscribe system for real-time monitoring\n        //    through the workflow:${workflowId}:${runId} channel\n      },\n    ],\n  },\n  logger: new PinoLogger({\n    name: \"Mastra\",\n    level: \"info\",\n  }),\n});\n```\n\n### Running the Workflow locally\n\n> **Prerequisites:**\n>\n> - Docker installed and running\n> - Mastra project set up\n> - Dependencies installed (`npm install`)\n\n1. Run `npx mastra dev` to start the Mastra server on local to serve the server on port 5000.\n2. Start the Inngest Dev Server (via Docker)\n   In a new terminal, run:\n\n```sh\ndocker run --rm -p 3000:3000 \\\n  inngest/inngest \\\n  inngest dev -u http://host.docker.internal:5000/api/inngest\n```\n\n> **Note:** The URL after `-u` tells the Inngest dev server where to find your Mastra `/api/inngest` endpoint.\n\n3. Open the Inngest Dashboard\n\n- Visit [http://localhost:3000](http://localhost:3000) in your browser.\n- Go to the **Apps** section in the sidebar.\n- You should see your Mastra workflow registered.\n  ![Inngest Dashboard](/inngest-apps-dashboard.png)\n\n4. Invoke the Workflow\n\n- Go to the **Functions** section in the sidebar.\n- Select your Mastra workflow.\n- Click **Invoke** and use the following input:\n\n```json\n{\n  \"data\": {\n    \"inputData\": {\n      \"value\": 5\n    }\n  }\n}\n```\n\n![Inngest Function](/inngest-function-dashboard.png)\n\n5. **Monitor the Workflow Execution**\n\n- Go to the **Runs** tab in the sidebar.\n- Click on the latest run to see step-by-step execution progress.\n  ![Inngest Function Run](/inngest-runs-dashboard.png)\n\n### Running the Workflow in Production\n\n> **Prerequisites:**\n>\n> - Vercel account and Vercel CLI installed (`npm i -g vercel`)\n> - Inngest account\n> - Vercel token (recommended: set as environment variable)\n\n1. Add Vercel Deployer to Mastra instance\n\n```ts showLineNumbers copy filename=\"src/mastra/index.ts\"\nimport { VercelDeployer } from \"@mastra/deployer-vercel\";\n\nexport const mastra = new Mastra({\n  // ...other config\n  deployer: new VercelDeployer({\n    teamSlug: \"your_team_slug\",\n    projectName: \"your_project_name\",\n    // you can get your vercel token from the vercel dashboard by clicking on the user icon in the top right corner\n    // and then clicking on \"Account Settings\" and then clicking on \"Tokens\" on the left sidebar.\n    token: \"your_vercel_token\",\n  }),\n});\n```\n\n> **Note:** Set your Vercel token in your environment:\n>\n> ```sh\n> export VERCEL_TOKEN=your_vercel_token\n> ```\n\n2. Build the mastra instance\n\n```sh\nnpx mastra build\n```\n\n3. Deploy to Vercel\n\n```sh\ncd .mastra/output\nvercel --prod\n```\n\n> **Tip:** If you haven't already, log in to Vercel CLI with `vercel login`.\n\n4. Sync with Inngest Dashboard\n\n- Go to the [Inngest dashboard](https://app.inngest.com/env/production/apps).\n- Click **Sync new app with Vercel** and follow the instructions.\n- You should see your Mastra workflow registered as an app.\n  ![Inngest Dashboard](/inngest-apps-dashboard-prod.png)\n\n5. Invoke the Workflow\n\n- In the **Functions** section, select `workflow.increment-workflow`.\n- Click **All actions** (top right) > **Invoke**.\n- Provide the following input:\n\n```json\n{\n  \"data\": {\n    \"inputData\": {\n      \"value\": 5\n    }\n  }\n}\n```\n\n![Inngest Function Run](/inngest-function-dashboard-prod.png)\n\n6.  Monitor Execution\n\n- Go to the **Runs** tab.\n- Click the latest run to see step-by-step execution progress.\n  ![Inngest Function Run](/inngest-runs-dashboard-prod.png)\n\n\n---\ntitle: \"Input Data Mapping with Workflow | Mastra Docs\"\ndescription: \"Learn how to use workflow input mapping to create more dynamic data flows in your Mastra workflows.\"\n---\n\n# Input Data Mapping\n[EN] Source: https://mastra.ai/en/docs/workflows/input-data-mapping\n\nInput data mapping allows explicit mapping of values for the inputs of the next step. These values can come from a number of sources:\n\n- The outputs of a previous step\n- The runtime context\n- A constant value\n- The initial input of the workflow\n\n## Mapping with `.map()`\n\nIn this example the `output` from `step1` is transformed to match the `inputSchema` required for the `step2`. The value from `step1` is available using the `inputData` parameter of the `.map` function.\n\n![Mapping with .map()](/image/workflows/workflows-data-mapping-map.jpg)\n\n```typescript {9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .map(async ({ inputData }) => {\n    const { value } = inputData;\n    return {\n      output: `new ${value}`\n    };\n  })\n  .then(step2)\n  .commit();\n```\n\n## Using `inputData`\n\nUse `inputData` to access the full output of the previous step:\n\n```typescript {3} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\n  .then(step1)\n  .map(({ inputData }) => {\n    console.log(inputData);\n  })\n```\n\n## Using `getStepResult()`\n\nUse `getStepResult` to access the full output of a specific step by referencing the step's instance:\n\n```typescript {3} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\n  .then(step1)\n  .map(async ({ getStepResult }) => {\n    console.log(getStepResult(step1));\n  })\n```\n\n## Using `getInitData()`\n\nUse `getInitData` to access the initial input data provided to the workflow:\n\n```typescript {3} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\n  .then(step1)\n  .map(async ({ getInitData }) => {\n      console.log(getInitData());\n  })\n```\n\n## Using `mapVariable()`\n\nTo use `mapVariable` import the necessary function from the workflows module:\n\n```typescript filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { mapVariable } from \"@mastra/core/workflows\";\n```\n\n### Renaming step with `mapVariable()`\n\nYou can rename step outputs using the object syntax in `.map()`. In the example below, the `value` output from `step1` is renamed to `details`:\n\n```typescript {3-6} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\n  .then(step1)\n  .map({\n    details: mapVariable({\n      step: step,\n      path: \"value\"\n    })\n  })\n```\n\n### Renaming workflows with `mapVariable()`\n\nYou can rename workflow outputs by using **referential composition**. This involves passing the workflow instance as the `initData`.\n\n```typescript {6-9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nexport const testWorkflow = createWorkflow({...});\n\ntestWorkflow\n  .then(step1)\n  .map({\n    details: mapVariable({\n      initData: testWorkflow,\n      path: \"value\"\n    })\n  })\n```\n\n\n---\ntitle: \"Handling Complex LLM Operations | Workflows | Mastra\"\ndescription: \"Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.\"\n---\n\nimport { Steps } from \"nextra/components\";\n\n# Workflows overview\n[EN] Source: https://mastra.ai/en/docs/workflows/overview\n\nWorkflows let you define and orchestrate complex sequences of tasks as **typed steps** connected by data flows. Each step has clearly defined inputs and outputs validated by Zod schemas.\n\nA workflow manages execution order, dependencies, branching, parallelism, and error handling â€” enabling you to build robust, reusable processes. Steps can be nested or cloned to compose larger workflows.\n\n![Workflows overview](/image/workflows/workflows-overview.jpg)\n\nYou create workflows by:\n\n- Defining **steps** with `createStep`, specifying input/output schemas and business logic.\n- Composing **steps** with `createWorkflow` to define the execution flow.\n- Running **workflows** to execute the entire sequence, with built-in support for suspension, resumption, and streaming results.\n\nThis structure provides full type safety and runtime validation, ensuring data integrity across the entire workflow.\n\n\n## Getting started\n\nTo use workflows, first import the necessary functions from the workflows module:\n\n```typescript filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\n### Create step\n\nSteps are the building blocks of workflows. Create a step using `createStep`:\n\n```typescript filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nconst step1 = createStep({...});\n```\n\n> See [createStep](/reference/workflows/step) for more information.\n\n### Create workflow\n\nCreate a workflow using `createWorkflow` and complete it with `.commit()`.\n\n```typescript {6,17} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\n\nexport const testWorkflow = createWorkflow({\n  id: \"test-workflow\",\n  description: 'Test workflow',\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  })\n})\n  .then(step1)\n  .commit();\n```\n\n> See [workflow](/reference/workflows/workflow) for more information.\n\n#### Composing steps\n\nWorkflow steps can be composed and executed sequentially using `.then()`.\n\n```typescript {17,18} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({\n  id: \"test-workflow\",\n  description: 'Test workflow',\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  })\n})\n  .then(step1)\n  .then(step2)\n  .commit();\n```\n\n> Steps can be composed using a number of different methods. See [Control Flow](/docs/workflows/control-flow)  for more information.\n\n#### Cloning steps\n\nWorkflow steps can be cloned using `cloneStep()`, and used with any workflow method.\n\n```typescript {5,19} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep, cloneStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst clonedStep = cloneStep(step1, { id: \"cloned-step\" });\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({\n  id: \"test-workflow\",\n  description: 'Test workflow',\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  })\n})\n  .then(step1)\n  .then(clonedStep)\n  .then(step2)\n  .commit();\n```\n\n### Register workflow\n\nRegister a workflow using `workflows` in the main Mastra instance:\n\n```typescript {8} filename=\"src/mastra/index.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { PinoLogger } from \"@mastra/loggers\";\nimport { LibSQLStore } from \"@mastra/libsql\";\n\nimport { testWorkflow } from \"./workflows/test-workflow\";\n\nexport const mastra = new Mastra({\n  workflows: { testWorkflow },\n  storage: new LibSQLStore({\n    // stores telemetry, evals, ... into memory storage, if it needs to persist, change to file:../mastra.db\n    url: \":memory:\"\n  }),\n  logger: new PinoLogger({\n    name: \"Mastra\",\n    level: \"info\"\n  })\n});\n```\n\n### Run workflow\nThere are two ways to run and test workflows.\n\n<Steps>\n\n#### Mastra Playground\n\nWith the Mastra Dev Server running you can run the workflow from the Mastra Playground by visiting [http://localhost:5000/workflows](http://localhost:5000/workflows) in your browser.\n\n#### Command line\n\nCreate a run instance of any Mastra workflow using `createRunAsync` and `start`:\n\n```typescript {3,5} filename=\"src/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.start({\n  inputData: {\n    city: \"London\"\n  }\n});\n\nconsole.log(JSON.stringify(result, null, 2));\n```\n> see [createRunAsync](/reference/workflows/create-run) and [start](/reference/workflows/start) for more information.\n\nTo trigger this workflow, run the following:\n\n```bash copy\nnpx tsx src/test-workflow.ts\n```\n\n</Steps>\n\n#### Run workflow results\n\nThe result of running a workflow using either `start()` or `resume()` will look like one of the following, depending on the outcome.\n\n##### Status success\n\n```json\n{\n  \"status\": \"success\",\n  \"steps\": {\n    // ...\n    \"step-1\": {\n      // ...\n      \"status\": \"success\",\n    }\n  },\n  \"result\": {\n    \"output\": \"London + step-1\"\n  }\n}\n```\n\n- **status**: Shows the final state of the workflow execution, either: `success`, `suspended`, or `error`\n- **steps**: Lists each step in the workflow, including inputs and outputs\n- **status**: Shows the outcome of each individual step\n- **result**: Includes the final output of the workflow, typed according to the `outputSchema`\n\n\n##### Status suspended\n\n```json\n{\n  \"status\": \"suspended\",\n  \"steps\": {\n    // ...\n    \"step-1\": {\n      // ...\n      \"status\": \"suspended\",\n    }\n  },\n  \"suspended\": [\n    [\n      \"step-1\"\n    ]\n  ]\n}\n```\n\n- **suspended**: An optional array listing any steps currently awaiting input before continuing\n\n##### Status failed\n\n```json\n{\n  \"status\": \"failed\",\n  \"steps\": {\n    // ...\n    \"step-1\": {\n      // ...\n      \"status\": \"failed\",\n      \"error\": \"Test error\",\n    }\n  },\n  \"error\": \"Test error\"\n}\n```\n- **error**: An optional field that includes the error message if the workflow fails\n\n### Stream workflow\n\nSimilar to the run method shown above, workflows can also be streamed:\n\n```typescript {5} filename=\"src/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.stream({\n  inputData: {\n    city: \"London\"\n  }\n});\n\nfor await (const chunk of result.stream) {\n  console.log(chunk);\n}\n```\n\n> See [stream](/reference/workflows/stream) and [messages](/reference/workflows/stream#messages) for more information.\n\n### Watch Workflow\n\nA workflow can also be watched, allowing you to inspect each event that is emitted.\n\n```typescript {5} filename=\"src/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nrun.watch((event) => {\n  console.log(event);\n});\n\nconst result = await run.start({\n  inputData: {\n    city: \"London\"\n  }\n});\n```\n\n> See [watch](/reference/workflows/watch) for more information.\n\n## More resources\n\n- The [Workflow Guide](../../guides/guide/ai-recruiter.mdx) in the Guides section is a tutorial that covers the main concepts.\n- [Parallel Steps workflow example](../../examples/workflows/parallel-steps.mdx)\n- [Conditional Branching workflow example](../../examples/workflows/conditional-branching.mdx)\n- [Inngest workflow example](../../examples/workflows/inngest-workflow.mdx)\n- [Suspend and Resume workflow example](../../examples/workflows/human-in-the-loop.mdx)\n\n\n## Workflows (Legacy)\n\nFor legacy workflow documentation, see [Workflows (Legacy)](/docs/workflows-legacy/overview).\n\n\n\n---\ntitle: \"Pausing Execution | Mastra Docs\"\ndescription: \"Pausing execution in Mastra workflows allows you to pause execution while waiting for external input or resources via .sleep(), .sleepUntil() and .waitForEvent().\"\n---\n\n# Sleep & Events\n[EN] Source: https://mastra.ai/en/docs/workflows/pausing-execution\n\nMastra lets you pause workflow execution when waiting for external input or timing conditions. This can be useful for things like polling, delayed retries, or waiting on user actions.\n\nYou can pause execution using:\n\n- `sleep()`: Pause for a set number of milliseconds\n- `sleepUntil()`: Pause until a specific timestamp\n- `waitForEvent()`: Pause until an external event is received\n- `sendEvent()`: Send an event to resume a waiting workflow\n\nWhen using any of these methods, the workflow status is set to `waiting` until execution resumes.\n\n## Pausing with `.sleep()`\n\nThe `sleep()` method pauses execution between steps for a specified number of milliseconds.\n\n```typescript {9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .sleep(1000)\n  .then(step2)\n  .commit();\n```\n\n### Pausing with `.sleep(callback)`\n\nThe `sleep()` method also accepts a callback that returns the number of milliseconds to pause. The callback receives `inputData`, allowing the delay to be computed dynamically.\n\n```typescript {9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .sleep(async ({ inputData }) => {\n    const { delayInMs }  = inputData\n    return delayInMs;\n  })\n  .then(step2)\n  .commit();\n```\n\n## Pausing with `.sleepUntil()`\n\nThe `sleepUntil()` method pauses execution between steps until a specified date.\n\n```typescript {9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .sleepUntil(new Date(Date.now() + 5000))\n  .then(step2)\n  .commit();\n```\n\n### Pausing with `.sleepUntil(callback)`\n\nThe `sleepUntil()` method also accepts a callback that returns a `Date` object. The callback receives `inputData`, allowing the target time to be computed dynamically.\n\n```typescript {9} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .sleepUntil(async ({ inputData }) => {\n    const { delayInMs }  = inputData\n    return new Date(Date.now() + delayInMs);\n  })\n  .then(step2)\n  .commit();\n```\n\n\n> `Date.now()` is evaluated when the workflow starts, not at the moment the `sleepUntil()` method is called.\n\n## Pausing with `.waitForEvent()`\n\nThe `waitForEvent()` method pauses execution until a specific event is received. Use `run.sendEvent()` to send the event. You must provide both the event name and the step to resume.\n\n![Pausing with .waitForEvent()](/image/workflows/workflows-sleep-events-waitforevent.jpg)\n\n```typescript {10} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { createWorkflow, createStep } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n\nconst step1 = createStep({...});\nconst step2 = createStep({...});\nconst step3 = createStep({...});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .waitForEvent(\"my-event-name\", step2)\n  .then(step3)\n  .commit();\n```\n## Sending an event with `.sendEvent()`\n\nThe `.sendEvent()` method sends an event to the workflow. It accepts the event name and optional event data, which can be any JSON-serializable value.\n\n```typescript {5,12,15} filename=\"src/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = run.start({\n  inputData: {\n    value: \"hello\"\n  }\n});\n\nsetTimeout(() => {\n  run.sendEvent(\"my-event-name\", { value: \"from event\" });\n}, 3000);\n\nconsole.log(JSON.stringify(await result, null, 2));\n```\n\n> In this example, avoid using `await run.start()` directly, it would block sending the event before the workflow reaches its waiting state.\n\n\n---\ntitle: \"Suspend & Resume Workflows | Human-in-the-Loop | Mastra Docs\"\ndescription: \"Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.\"\n---\n\n# Suspend & Resume\n[EN] Source: https://mastra.ai/en/docs/workflows/suspend-and-resume\n\nWorkflows can be paused at any step, with their current state persisted as a snapshot in storage. Execution can then be resumed from this saved snapshot when ready. Persisting the snapshot ensures the workflow state is maintained across sessions, deployments, and server restarts, essential for workflows that may remain suspended while awaiting external input or resources.\n\nCommon scenarios for suspending workflows include:\n\n- Waiting for human approval or input\n- Pausing until external API resources become available\n- Collecting additional data needed for later steps\n- Rate limiting or throttling expensive operations\n- Handling event-driven processes with external triggers\n\n## Workflow status types\n\nWhen running a workflow, its `status` can be one of the following:\n\n- `running` - The workflow is currently running\n- `suspended` - The workflow is suspended\n- `success` - The workflow has completed\n- `failed` - The workflow has failed\n\n## Suspending a workflow with `suspend()`\n\nWhen the state is `suspended`, you can identify any and all steps that have been suspended by looking at the `suspended` array of the workflow result output.\n\n![Suspending a workflow with suspend()](/image/workflows/workflows-suspend-resume-suspend.jpg)\n\n```typescript {18} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nconst step1 = createStep({\n  id: \"step-1\",\n  description: \"Test suspend\",\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  }),\n  suspendSchema: z.object({}),\n  resumeSchema: z.object({\n    city: z.string()\n  }),\n  execute: async ({ resumeData, suspend }) => {\n    const { city } = resumeData ?? {};\n\n    if (!city) {\n      await suspend({});\n      return { output: \"\" };\n    }\n\n    return { output: \"\" };\n  }\n});\n\nexport const testWorkflow = createWorkflow({})\n  .then(step1)\n  .commit();\n```\n\n> See [Define Suspendable workflow](/examples/workflows/human-in-the-loop#define-suspendable-workflow) for more information.\n\n### Identifying suspended steps\n\nTo resume a suspended workflow, inspect the `suspended` array in the result to determine which step needs input:\n\n```typescript {15} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.start({\n  inputData: {\n    city: \"London\"\n  }\n});\n\nconsole.log(JSON.stringify(result, null, 2));\n\nif (result.status === \"suspended\") {\n  const resumedResult = await run.resume({\n    step: result.suspended[0],\n    resumeData: {\n      city: \"Berlin\"\n    }\n  });\n}\n\n```\n\nIn this case, the logic resumes the first step listed in the `suspended` array. A `step` can also be defined using it's `id`, for example: 'step-1'.\n\n```json\n{\n  \"status\": \"suspended\",\n  \"steps\": {\n    // ...\n    \"step-1\": {\n      // ...\n      \"status\": \"suspended\",\n    }\n  },\n  \"suspended\": [\n    [\n      \"step-1\"\n    ]\n  ]\n}\n```\n\n> See [Run Workflow Results](/workflows/overview#run-workflow-results) for more details.\n\n## Resuming a workflow with `resume()`\n\nA workflow can be resumed by calling `resume` and providing the required `resumeData`.\n\n```typescript {16-18} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { mastra } from \"./mastra\";\n\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.start({\n   inputData: {\n    city: \"London\"\n  }\n});\n\nconsole.log(JSON.stringify(result, null, 2));\n\nif (result.status === \"suspended\") {\n  const resumedResult = await run.resume({\n    step: 'step-1',\n    resumeData: {\n      city: \"Berlin\"\n    }\n  });\n\n  console.log(JSON.stringify(resumedResult, null, 2));\n}\n```\n\n### Resuming nested workflows\n\nTo resume a suspended nested workflow pass the workflow instance to the `step` parameter of the `resume` function.\n\n```typescript {33-34} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nconst dowhileWorkflow = createWorkflow({\n  id: 'dowhile-workflow',\n  inputSchema: z.object({ value: z.number() }),\n  outputSchema: z.object({ value: z.number() }),\n})\n  .dountil(\n    createWorkflow({\n      id: 'simple-resume-workflow',\n      inputSchema: z.object({ value: z.number() }),\n      outputSchema: z.object({ value: z.number() }),\n      steps: [incrementStep, resumeStep],\n    })\n      .then(incrementStep)\n      .then(resumeStep)\n      .commit(),\n    async ({ inputData }) => inputData.value >= 10,\n  )\n  .then(\n    createStep({\n      id: 'final',\n      inputSchema: z.object({ value: z.number() }),\n      outputSchema: z.object({ value: z.number() }),\n      execute: async ({ inputData }) => ({ value: inputData.value }),\n    }),\n  )\n  .commit();\n\nconst run = await dowhileWorkflow.createRunAsync();\nconst result = await run.start({ inputData: { value: 0 } });\n\nif (result.status === \"suspended\") {\n  const resumedResult = await run.resume({\n    resumeData: { value: 2 },\n    step: ['simple-resume-workflow', 'resume'],\n  });\n\n  console.log(JSON.stringify(resumedResult, null, 2));\n}\n```\n\n## Using `RuntimeContext` with suspend/resume\n\nWhen using suspend/resume with `RuntimeContext`, you can create the instance yourself, and pass it to the `start` and `resume` functions.\n`RuntimeContext` is not automatically shared on a workflow run.\n\n```typescript {1,4,9,16} filename=\"src/mastra/workflows/test-workflow.tss\" showLineNumbers copy\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { mastra } from \"./mastra\";\n\nconst runtimeContext = new RuntimeContext();\nconst run = await mastra.getWorkflow(\"testWorkflow\").createRunAsync();\n\nconst result = await run.start({\n  inputData: { suggestions: [\"London\", \"Paris\", \"New York\"] },\n  runtimeContext\n});\n\nif (result.status === \"suspended\") {\n  const resumedResult = await run.resume({\n    step: 'step-1',\n    resumeData: { city: \"New York\" },\n    runtimeContext\n  });\n}\n```\n\n\n---\ntitle: \"Using Workflows with Agents and Tools | Workflows | Mastra Docs\"\ndescription: \"Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.\"\n---\n\n# Agents and Tools\n[EN] Source: https://mastra.ai/en/docs/workflows/using-with-agents-and-tools\n\nWorkflow steps are composable and typically run logic directly within the `execute` function. However, there are cases where calling an agent or tool is more appropriate. This pattern is especially useful when:\n\n- Generating natural language responses from user input using an LLM.\n- Abstracting complex or reusable logic into a dedicated tool.\n- Interacting with third-party APIs in a structured or reusable way.\n\nWorkflows can use Mastra agents or tools directly as steps, for example: `createStep(testAgent)` or `createStep(testTool)`.\n\n## Using agents in workflows\n\nTo include an agent in a workflow, define it in the usual way, then either add it directly to the workflow using `createStep(testAgent)` or, invoke it from within a step's `execute` function using `.generate()`.\n\n### Example agent\n\nThis agent uses OpenAI to generate a fact about a city, country, and timezone.\n\n```typescript filename=\"src/mastra/agents/test-agent.ts\" showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\n\nexport const testAgent = new Agent({\n  name: \"test-agent\",\n  description: \"Create facts for a country based on the city\",\n  instructions: `Return an interesting fact about the country based on the city provided`,\n  model: openai(\"gpt-4o\")\n});\n```\n\n### Adding an agent as a step\n\nIn this example, `step1` uses the `testAgent` to generate an interesting fact about the country based on a given city.\n\nThe `.map` method transforms the workflow input into a `prompt` string compatible with the `testAgent`.\n\nThe step is composed into the workflow using `.then()`, allowing it to receive the mapped input and return the agent's structured output. The workflow is finalized with `.commit()`.\n\n\n![Agent as step](/image/workflows/workflows-agent-tools-agent-step.jpg)\n\n\n```typescript {3} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { testAgent } from \"../agents/test-agent\";\n\nconst step1 = createStep(testAgent);\n\nexport const testWorkflow = createWorkflow({\n  id: \"test-workflow\",\n  description: 'Test workflow',\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  })\n})\n  .map(({ inputData }) => {\n    const { input } = inputData;\n    return {\n      prompt: `Provide facts about the city: ${input}`\n    };\n  })\n  .then(step1)\n  .commit();\n```\n\n### Calling an agent with `.generate()`\n\nIn this example, the `step1` builds a prompt using the provided `input` and passes it to the `testAgent`, which returns a plain-text response containing facts about the city and its country.\n\nThe step is added to the workflow using the sequential `.then()` method, allowing it to receive input from the workflow and return structured output. The workflow is finalized with `.commit()`.\n\n```typescript {1,18, 29} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { testAgent } from \"../agents/test-agent\";\n\nconst step1 = createStep({\n  id: \"step-1\",\n  description: \"Create facts for a country based on the city\",\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  }),\n\n  execute: async ({ inputData }) => {\n    const { input } = inputData;\n\n    const  prompt = `Provide facts about the city: ${input}`\n\n    const { text } = await testAgent.generate([\n      { role: \"user\", content: prompt }\n    ]);\n\n    return {\n      output: text\n    };\n  }\n});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .commit();\n```\n\n## Using tools in workflows\n\nTo use a tool within a workflow, define it in the usual way, then either add it directly to the workflow using `createStep(testTool)` or, invoke it from within a step's `execute` function using `.execute()`.\n\n### Example tool\n\nThe example below uses the Open Meteo API to retrieve geolocation details for a city, returning its name, country, and timezone.\n\n```typescript filename=\"src/mastra/tools/test-tool.ts\" showLineNumbers copy\nimport { createTool } from \"@mastra/core\";\nimport { z } from \"zod\";\n\nexport const testTool = createTool({\n  id: \"test-tool\",\n  description: \"Gets country for a city\",\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    country_name: z.string()\n  }),\n  execute: async ({ context }) => {\n    const { input } = context;\n    const geocodingResponse = await fetch(`https://geocoding-api.open-meteo.com/v1/search?name=${input}`);\n    const geocodingData = await geocodingResponse.json();\n\n    const { country } = geocodingData.results[0];\n\n    return {\n      country_name: country\n    };\n  }\n});\n```\n\n### Adding a tool as a step\n\nIn this example, `step1` uses the `testTool`, which performs a geocoding lookup using the provided `city` and returns the resolved `country`.\n\nThe step is added to the workflow using the sequential `.then()` method, allowing it to receive input from the workflow and return structured output. The workflow is finalized with `.commit()`.\n\n![Tool as step](/image/workflows/workflows-agent-tools-tool-step.jpg)\n\n```typescript {1,3,6} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { testTool } from \"../tools/test-tool\";\n\nconst step1 = createStep(testTool);\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .commit();\n```\n\n### Calling a tool with `.execute()`\n\nIn this example, `step1` directly invokes `testTool` using its `.execute()` method. The tool performs a geocoding lookup with the provided `city` and returns the corresponding `country`.\n\nThe result is returned as structured output from the step. The step is composed into the workflow using `.then()`, enabling it to process workflow input and produce typed output. The workflow is finalized with `.commit()`\n\n```typescript {3,20,32} filename=\"src/mastra/workflows/test-workflow.ts\" showLineNumbers copy\nimport { RuntimeContext } from \"@mastra/core/di\";\n\nimport { testTool } from \"../tools/test-tool\";\n\nconst runtimeContext = new RuntimeContext();\n\nconst step1 = createStep({\n  id: \"step-1\",\n  description: \"Gets country for a city\",\n  inputSchema: z.object({\n    input: z.string()\n  }),\n  outputSchema: z.object({\n    output: z.string()\n  }),\n\n  execute: async ({ inputData }) => {\n    const { input } = inputData;\n\n    const { country_name } = await testTool.execute({\n      context: { input },\n      runtimeContext\n    });\n\n    return {\n      output: country_name\n    };\n  }\n});\n\nexport const testWorkflow = createWorkflow({...})\n  .then(step1)\n  .commit();\n```\n\n## Using workflows as tools\n\nIn this example the `cityStringWorkflow` workflow has been added to the main Mastra instance.\n\n\n```typescript {7} filename=\"src/mastra/index.ts\" showLineNumbers copy\nimport { Mastra } from \"@mastra/core/mastra\";\n\nimport { testWorkflow, cityStringWorkflow } from \"./workflows/test-workflow\";\n\nexport const mastra = new Mastra({\n  ...\n  workflows: { testWorkflow, cityStringWorkflow },\n});\n```\n\nOnce a workflow has been registered it can be referenced using `getWorkflow` from withing a tool.\n\n```typescript {10,17-27} filename=\"src/mastra/tools/test-tool.ts\" showLineNumbers copy\nexport const cityCoordinatesTool = createTool({\n  id: \"city-tool\",\n  description: \"Convert city details\",\n  inputSchema: z.object({\n    city: z.string()\n  }),\n  outputSchema: z.object({\n    outcome: z.string()\n  }),\n  execute: async ({ context, mastra }) => {\n    const { city } = context;\n    const geocodingResponse = await fetch(`https://geocoding-api.open-meteo.com/v1/search?name=${city}`);\n    const geocodingData = await geocodingResponse.json();\n\n    const { name, country, timezone } = geocodingData.results[0];\n\n    const workflow = mastra?.getWorkflow(\"cityStringWorkflow\");\n\n    const run = await workflow?.createRunAsync();\n\n    const { result } = await run?.start({\n      inputData: {\n        city_name: name,\n        country_name: country,\n        country_timezone: timezone\n      }\n    });\n\n    return {\n      outcome: result.outcome\n    };\n  }\n});\n```\n\n## Exposing workflows with `MCPServer`\n\nYou can convert your workflows into tools by passing them into an instance of a Mastra `MCPServer`. This allows any MCP-compatible client to access your workflow.\n\nThe workflow description becomes the tool description and the input schema becomes the tool's input schema.\n\nWhen you provide workflows to the server, each workflow is automatically exposed as a callable tool for example:\n\n- `run_testWorkflow`.\n\n```typescript filename=\"src/test-mcp-server.ts\" showLineNumbers copy\nimport { MCPServer } from \"@mastra/mcp\";\n\nimport { testAgent } from \"./mastra/agents/test-agent\";\nimport { testTool } from \"./mastra/tools/test-tool\";\nimport { testWorkflow } from \"./mastra/workflows/test-workflow\";\n\nasync function startServer() {\n  const server = new MCPServer({\n    name: \"test-mcp-server\",\n    version: \"1.0.0\",\n    workflows: {\n      testWorkflow\n    }\n  });\n\n  await server.startStdio();\n  console.log(\"MCPServer started on stdio\");\n}\n\nstartServer().catch(console.error);\n```\n\nTo verify that your workflow is available on the server, you can connect with an MCPClient.\n\n```typescript filename=\"src/test-mcp-client.ts\" showLineNumbers copy\nimport { MCPClient } from \"@mastra/mcp\";\n\nasync function main() {\n  const mcp = new MCPClient({\n    servers: {\n      local: {\n        command: \"npx\",\n        args: [\"tsx\", \"src/test-mcp-server.ts\"]\n      }\n    }\n  });\n\n  const tools = await mcp.getTools();\n  console.log(tools);\n}\n\nmain().catch(console.error);\n```\n\nRun the client script to see your workflow tool.\n\n```bash\nnpx tsx src/test-mcp-client.ts\n```\n\n## More resources\n\n- [MCPServer reference documentation](/reference/tools/mcp-server).\n- [MCPClient reference documentation](/reference/tools/mcp-client).\n\n\n---\ntitle: \"Branching, Merging, Conditions | Workflows (Legacy) | Mastra Docs\"\ndescription: \"Control flow in Mastra legacy workflows allows you to manage branching, merging, and conditions to construct legacy workflows that meet your logic requirements.\"\n---\n\n# Control Flow in Legacy Workflows: Branching, Merging, and Conditions\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/control-flow\n\nWhen you create a multi-step process, you may need to run steps in parallel, chain them sequentially, or follow different paths based on outcomes. This page describes how you can manage branching, merging, and conditions to construct workflows that meet your logic requirements. The code snippets show the key patterns for structuring complex control flow.\n\n## Parallel Execution\n\nYou can run multiple steps at the same time if they don't depend on each other. This approach can speed up your workflow when steps perform independent tasks. The code below shows how to add two steps in parallel:\n\n```typescript\nmyWorkflow.step(fetchUserData).step(fetchOrderData);\n```\n\nSee the [Parallel Steps](../../examples/workflows_legacy/parallel-steps.mdx) example for more details.\n\n## Sequential Execution\n\nSometimes you need to run steps in strict order to ensure outputs from one step become inputs for the next. Use .then() to link dependent operations. The code below shows how to chain steps sequentially:\n\n```typescript\nmyWorkflow.step(fetchOrderData).then(validateData).then(processOrder);\n```\n\nSee the [Sequential Steps](../../examples/workflows_legacy/sequential-steps.mdx) example for more details.\n\n## Branching and Merging Paths\n\nWhen different outcomes require different paths, branching is helpful. You can also merge paths later once they complete. The code below shows how to branch after stepA and later converge on stepF:\n\n```typescript\nmyWorkflow\n  .step(stepA)\n  .then(stepB)\n  .then(stepD)\n  .after(stepA)\n  .step(stepC)\n  .then(stepE)\n  .after([stepD, stepE])\n  .step(stepF);\n```\n\nIn this example:\n\n- stepA leads to stepB, then to stepD.\n- Separately, stepA also triggers stepC, which in turn leads to stepE.\n- Separately, stepF is triggered when both stepD and stepE are completed.\n\nSee the [Branching Paths](../../examples/workflows_legacy/branching-paths.mdx) example for more details.\n\n## Merging Multiple Branches\n\nSometimes you need a step to execute only after multiple other steps have completed. Mastra provides a compound `.after([])` syntax that allows you to specify multiple dependencies for a step.\n\n```typescript\nmyWorkflow\n  .step(fetchUserData)\n  .then(validateUserData)\n  .step(fetchProductData)\n  .then(validateProductData)\n  // This step will only run after BOTH validateUserData AND validateProductData have completed\n  .after([validateUserData, validateProductData])\n  .step(processOrder);\n```\n\nIn this example:\n\n- `fetchUserData` and `fetchProductData` run in parallel branches\n- Each branch has its own validation step\n- The `processOrder` step only executes after both validation steps have completed successfully\n\nThis pattern is particularly useful for:\n\n- Joining parallel execution paths\n- Implementing synchronization points in your workflow\n- Ensuring all required data is available before proceeding\n\nYou can also create complex dependency patterns by combining multiple `.after([])` calls:\n\n```typescript\nmyWorkflow\n  // First branch\n  .step(stepA)\n  .then(stepB)\n  .then(stepC)\n\n  // Second branch\n  .step(stepD)\n  .then(stepE)\n\n  // Third branch\n  .step(stepF)\n  .then(stepG)\n\n  // This step depends on the completion of multiple branches\n  .after([stepC, stepE, stepG])\n  .step(finalStep);\n```\n\n## Cyclical Dependencies and Loops\n\nWorkflows often need to repeat steps until certain conditions are met. Mastra provides two powerful methods for creating loops: `until` and `while`. These methods offer an intuitive way to implement repetitive tasks.\n\n### Using Manual Cyclical Dependencies (Legacy Approach)\n\nIn earlier versions, you could create loops by manually defining cyclical dependencies with conditions:\n\n```typescript\nmyWorkflow\n  .step(fetchData)\n  .then(processData)\n  .after(processData)\n  .step(finalizeData, {\n    when: { \"processData.status\": \"success\" },\n  })\n  .step(fetchData, {\n    when: { \"processData.status\": \"retry\" },\n  });\n```\n\nWhile this approach still works, the newer `until` and `while` methods provide a cleaner and more maintainable way to create loops.\n\n### Using `until` for Condition-Based Loops\n\nThe `until` method repeats a step until a specified condition becomes true. It takes these arguments:\n\n1. A condition that determines when to stop looping\n2. The step to repeat\n3. Optional variables to pass to the repeated step\n\n```typescript\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Step that increments a counter until target is reached\nconst incrementStep = new LegacyStep({\n  id: \"increment\",\n  inputSchema: z.object({\n    // Current counter value\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .until(\n    async ({ context }) => {\n      // Stop when counter reaches 10\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) >= 10;\n    },\n    incrementStep,\n    {\n      // Pass current counter to next iteration\n      counter: {\n        step: incrementStep,\n        path: \"updatedCounter\",\n      },\n    },\n  )\n  .then(finalStep);\n```\n\nYou can also use a reference-based condition:\n\n```typescript\nworkflow\n  .step(incrementStep)\n  .until(\n    {\n      ref: { step: incrementStep, path: \"updatedCounter\" },\n      query: { $gte: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: \"updatedCounter\",\n      },\n    },\n  )\n  .then(finalStep);\n```\n\n### Using `while` for Condition-Based Loops\n\nThe `while` method repeats a step as long as a specified condition remains true. It takes the same arguments as `until`:\n\n1. A condition that determines when to continue looping\n2. The step to repeat\n3. Optional variables to pass to the repeated step\n\n```typescript\n// Step that increments a counter while below target\nconst incrementStep = new LegacyStep({\n  id: \"increment\",\n  inputSchema: z.object({\n    // Current counter value\n    counter: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { counter = 0 } = context.inputData;\n    return { updatedCounter: counter + 1 };\n  },\n});\n\nworkflow\n  .step(incrementStep)\n  .while(\n    async ({ context }) => {\n      // Continue while counter is less than 10\n      const result = context.getStepResult(incrementStep);\n      return (result?.updatedCounter ?? 0) < 10;\n    },\n    incrementStep,\n    {\n      // Pass current counter to next iteration\n      counter: {\n        step: incrementStep,\n        path: \"updatedCounter\",\n      },\n    },\n  )\n  .then(finalStep);\n```\n\nYou can also use a reference-based condition:\n\n```typescript\nworkflow\n  .step(incrementStep)\n  .while(\n    {\n      ref: { step: incrementStep, path: \"updatedCounter\" },\n      query: { $lt: 10 },\n    },\n    incrementStep,\n    {\n      counter: {\n        step: incrementStep,\n        path: \"updatedCounter\",\n      },\n    },\n  )\n  .then(finalStep);\n```\n\n### Comparison Operators for Reference Conditions\n\nWhen using reference-based conditions, you can use these comparison operators:\n\n| Operator | Description              |\n| -------- | ------------------------ |\n| `$eq`    | Equal to                 |\n| `$ne`    | Not equal to             |\n| `$gt`    | Greater than             |\n| `$gte`   | Greater than or equal to |\n| `$lt`    | Less than                |\n| `$lte`   | Less than or equal to    |\n\n## Conditions\n\nUse the when property to control whether a step runs based on data from previous steps. Below are three ways to specify conditions.\n\n### Option 1: Function\n\n```typescript\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: async ({ context }) => {\n      const fetchData = context?.getStepResult<{ status: string }>(\"fetchData\");\n      return fetchData?.status === \"success\";\n    },\n  },\n);\n```\n\n### Option 2: Query Object\n\n```typescript\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      ref: {\n        step: {\n          id: \"fetchData\",\n        },\n        path: \"status\",\n      },\n      query: { $eq: \"success\" },\n    },\n  },\n);\n```\n\n### Option 3: Simple Path Comparison\n\n```typescript\nmyWorkflow.step(\n  new Step({\n    id: \"processData\",\n    execute: async ({ context }) => {\n      // Action logic\n    },\n  }),\n  {\n    when: {\n      \"fetchData.status\": \"success\",\n    },\n  },\n);\n```\n\n## Data Access Patterns\n\nMastra provides several ways to pass data between steps:\n\n1. **Context Object** - Access step results directly through the context object\n2. **Variable Mapping** - Explicitly map outputs from one step to inputs of another\n3. **getStepResult Method** - Type-safe method to retrieve step outputs\n\nEach approach has its advantages depending on your use case and requirements for type safety.\n\n### Using getStepResult Method\n\nThe `getStepResult` method provides a type-safe way to access step results. This is the recommended approach when working with TypeScript as it preserves type information.\n\n#### Basic Usage\n\nFor better type safety, you can provide a type parameter to `getStepResult`:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/get-step-result.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new LegacyStep({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    name: z.string(),\n    userId: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return { name: \"John Doe\", userId: \"123\" };\n  },\n});\n\nconst analyzeDataStep = new LegacyStep({\n  id: \"analyzeData\",\n  execute: async ({ context }) => {\n    // Type-safe access to previous step result\n    const userData = context.getStepResult<{ name: string; userId: string }>(\n      \"fetchUser\",\n    );\n\n    if (!userData) {\n      return { status: \"error\", message: \"User data not found\" };\n    }\n\n    return {\n      analysis: `Analyzed data for user ${userData.name}`,\n      userId: userData.userId,\n    };\n  },\n});\n```\n\n#### Using Step References\n\nThe most type-safe approach is to reference the step directly in the `getStepResult` call:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/step-reference.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define step with output schema\nconst fetchUserStep = new LegacyStep({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\",\n    };\n  },\n});\n\nconst processUserStep = new LegacyStep({\n  id: \"processUser\",\n  execute: async ({ context }) => {\n    // TypeScript will infer the correct type from fetchUserStep's outputSchema\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      processed: true,\n      userName: userData?.name,\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"user-workflow\",\n});\n\nworkflow.step(fetchUserStep).then(processUserStep).commit();\n```\n\n### Using Variable Mapping\n\nVariable mapping is an explicit way to define data flow between steps.\nThis approach makes dependencies clear and provides good type safety.\nThe data injected into the step is available in the `context.inputData` object, and typed based on the `inputSchema` of the step.\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/variable-mapping.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new LegacyStep({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\",\n    };\n  },\n});\n\nconst sendEmailStep = new LegacyStep({\n  id: \"sendEmail\",\n  inputSchema: z.object({\n    recipientEmail: z.string(),\n    recipientName: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const { recipientEmail, recipientName } = context.inputData;\n\n    // Send email logic here\n    return {\n      status: \"sent\",\n      to: recipientEmail,\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"email-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(sendEmailStep, {\n    variables: {\n      // Map specific fields from fetchUser to sendEmail inputs\n      recipientEmail: { step: fetchUserStep, path: \"email\" },\n      recipientName: { step: fetchUserStep, path: \"name\" },\n    },\n  })\n  .commit();\n```\n\nFor more details on variable mapping, see the [Data Mapping with Workflow Variables](./variables.mdx) documentation.\n\n### Using the Context Object\n\nThe context object provides direct access to all step results and their outputs. This approach is more flexible but requires careful handling to maintain type safety.\nYou can access step results directly through the `context.steps` object:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/context-access.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new LegacyStep({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // Access data from a previous step\n    let userData: { name: string; userId: string };\n    if (context.steps[\"fetchUser\"]?.status === \"success\") {\n      userData = context.steps.fetchUser.output;\n    } else {\n      throw new Error(\"User data not found\");\n    }\n\n    return {\n      orderId: \"order123\",\n      userId: userData.userId,\n      status: \"processing\",\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"order-workflow\",\n});\n\nworkflow.step(fetchUserStep).then(processOrderStep).commit();\n```\n\n### Workflow-Level Type Safety\n\nFor comprehensive type safety across your entire workflow, you can define types for all steps and pass them to the Workflow\nThis allows you to get type safety for the context object on conditions, and on step results in the final workflow output.\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/workflow-typing.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Create steps with typed outputs\nconst fetchUserStep = new LegacyStep({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\",\n    };\n  },\n});\n\nconst processOrderStep = new LegacyStep({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of userData\n    const userData = context.getStepResult(fetchUserStep);\n\n    return {\n      orderId: \"order123\",\n      status: \"processing\",\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow<\n  [typeof fetchUserStep, typeof processOrderStep]\n>({\n  name: \"typed-workflow\",\n});\n\nworkflow\n  .step(fetchUserStep)\n  .then(processOrderStep)\n  .until(async ({ context }) => {\n    // TypeScript knows the shape of userData here\n    const res = context.getStepResult(\"fetchUser\");\n    return res?.userId === \"123\";\n  }, processOrderStep)\n  .commit();\n```\n\n### Accessing Trigger Data\n\nIn addition to step results, you can access the original trigger data that started the workflow:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/trigger-data.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define trigger schema\nconst triggerSchema = z.object({\n  customerId: z.string(),\n  orderItems: z.array(z.string()),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\nconst processOrderStep = new LegacyStep({\n  id: \"processOrder\",\n  execute: async ({ context }) => {\n    // Access trigger data with type safety\n    const triggerData = context.getStepResult<TriggerType>(\"trigger\");\n\n    return {\n      customerId: triggerData?.customerId,\n      itemCount: triggerData?.orderItems.length || 0,\n      status: \"processing\",\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"order-workflow\",\n  triggerSchema,\n});\n\nworkflow.step(processOrderStep).commit();\n```\n\n### Accessing Resume Data\n\nThe data injected into the step is available in the `context.inputData` object, and typed based on the `inputSchema` of the step.\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/resume-data.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst processOrderStep = new LegacyStep({\n  id: \"processOrder\",\n  inputSchema: z.object({\n    orderId: z.string(),\n  }),\n  execute: async ({ context, suspend }) => {\n    const { orderId } = context.inputData;\n\n    if (!orderId) {\n      await suspend();\n      return;\n    }\n\n    return {\n      orderId,\n      status: \"processed\",\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"order-workflow\",\n});\n\nworkflow.step(processOrderStep).commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\nconst resumedResult = await workflow.resume({\n  runId: result.runId,\n  stepId: \"processOrder\",\n  inputData: {\n    orderId: \"123\",\n  },\n});\n\nconsole.log({ resumedResult });\n```\n\n### Accessing Workflow Results\n\nYou can get typed access to the results of a workflow by injecting the step types into the `Workflow` type params:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/get-results.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst fetchUserStep = new LegacyStep({\n  id: \"fetchUser\",\n  outputSchema: z.object({\n    userId: z.string(),\n    name: z.string(),\n    email: z.string(),\n  }),\n  execute: async () => {\n    return {\n      userId: \"user123\",\n      name: \"John Doe\",\n      email: \"john@example.com\",\n    };\n  },\n});\n\nconst processOrderStep = new LegacyStep({\n  id: \"processOrder\",\n  outputSchema: z.object({\n    orderId: z.string(),\n    status: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const userData = context.getStepResult(fetchUserStep);\n    return {\n      orderId: \"order123\",\n      status: \"processing\",\n    };\n  },\n});\n\nconst workflow = new LegacyWorkflow<\n  [typeof fetchUserStep, typeof processOrderStep]\n>({\n  name: \"typed-workflow\",\n});\n\nworkflow.step(fetchUserStep).then(processOrderStep).commit();\n\nconst run = workflow.createRun();\nconst result = await run.start();\n\n// The result is a discriminated union of the step results\n// So it needs to be narrowed down via status checks\nif (result.results.processOrder.status === \"success\") {\n  // TypeScript will know the shape of the results\n  const orderId = result.results.processOrder.output.orderId;\n  console.log({ orderId });\n}\n\nif (result.results.fetchUser.status === \"success\") {\n  const userId = result.results.fetchUser.output.userId;\n  console.log({ userId });\n}\n```\n\n### Best Practices for Data Flow\n\n1. **Use getStepResult with Step References for Type Safety**\n\n   - Ensures TypeScript can infer the correct types\n   - Catches type errors at compile time\n\n2. \\*_Use Variable Mapping for Explicit Dependencies_\n\n   - Makes data flow clear and maintainable\n   - Provides good documentation of step dependencies\n\n3. **Define Output Schemas for Steps**\n\n   - Validates data at runtime\n   - Validates return type of the `execute` function\n   - Improves type inference in TypeScript\n\n4. **Handle Missing Data Gracefully**\n\n   - Always check if step results exist before accessing properties\n   - Provide fallback values for optional data\n\n5. **Keep Data Transformations Simple**\n   - Transform data in dedicated steps rather than in variable mappings\n   - Makes workflows easier to test and debug\n\n### Comparison of Data Flow Methods\n\n| Method           | Type Safety | Explicitness | Use Case                                          |\n| ---------------- | ----------- | ------------ | ------------------------------------------------- |\n| getStepResult    | Highest     | High         | Complex workflows with strict typing requirements |\n| Variable Mapping | High        | High         | When dependencies need to be clear and explicit   |\n| context.steps    | Medium      | Low          | Quick access to step data in simple workflows     |\n\nBy choosing the right data flow method for your use case, you can create workflows that are both type-safe and maintainable.\n\n\n---\ntitle: \"Dynamic Workflows (Legacy) | Mastra Docs\"\ndescription: \"Learn how to create dynamic workflows within legacy workflow steps, allowing for flexible workflow creation based on runtime conditions.\"\n---\n\n# Dynamic Workflows (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/dynamic-workflows\n\nThis guide demonstrates how to create dynamic workflows within a workflow step. This advanced pattern allows you to create and execute workflows on the fly based on runtime conditions.\n\n## Overview\n\nDynamic workflows are useful when you need to create workflows based on runtime data.\n\n## Implementation\n\nThe key to creating dynamic workflows is accessing the Mastra instance from within a step's `execute` function and using it to create and run a new workflow.\n\n### Basic Example\n\n```typescript\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === \"object\" && mastra instanceof Mastra;\n};\n\n// Step that creates and runs a dynamic workflow\nconst createDynamicWorkflow = new LegacyStep({\n  id: \"createDynamicWorkflow\",\n  outputSchema: z.object({\n    dynamicWorkflowResult: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error(\"Mastra instance not available\");\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error(\"Invalid Mastra instance\");\n    }\n\n    const inputData = context.triggerData.inputData;\n\n    // Create a new dynamic workflow\n    const dynamicWorkflow = new LegacyWorkflow({\n      name: \"dynamic-workflow\",\n      mastra, // Pass the mastra instance to the new workflow\n      triggerSchema: z.object({\n        dynamicInput: z.string(),\n      }),\n    });\n\n    // Define steps for the dynamic workflow\n    const dynamicStep = new LegacyStep({\n      id: \"dynamicStep\",\n      execute: async ({ context }) => {\n        const dynamicInput = context.triggerData.dynamicInput;\n        return {\n          processedValue: `Processed: ${dynamicInput}`,\n        };\n      },\n    });\n\n    // Build and commit the dynamic workflow\n    dynamicWorkflow.step(dynamicStep).commit();\n\n    // Create a run and execute the dynamic workflow\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        dynamicInput: inputData,\n      },\n    });\n\n    let dynamicWorkflowResult;\n\n    if (result.results[\"dynamicStep\"]?.status === \"success\") {\n      dynamicWorkflowResult =\n        result.results[\"dynamicStep\"]?.output.processedValue;\n    } else {\n      throw new Error(\"Dynamic workflow failed\");\n    }\n\n    // Return the result from the dynamic workflow\n    return {\n      dynamicWorkflowResult,\n    };\n  },\n});\n\n// Main workflow that uses the dynamic workflow creator\nconst mainWorkflow = new LegacyWorkflow({\n  name: \"main-workflow\",\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n  mastra: new Mastra(),\n});\n\nmainWorkflow.step(createDynamicWorkflow).commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { mainWorkflow },\n});\n\nconst run = mainWorkflow.createRun();\nconst result = await run.start({\n  triggerData: {\n    inputData: \"test\",\n  },\n});\n```\n\n## Advanced Example: Workflow Factory\n\nYou can create a workflow factory that generates different workflows based on input parameters:\n\n```typescript\nconst isMastra = (mastra: any): mastra is Mastra => {\n  return mastra && typeof mastra === \"object\" && mastra instanceof Mastra;\n};\n\nconst workflowFactory = new LegacyStep({\n  id: \"workflowFactory\",\n  inputSchema: z.object({\n    workflowType: z.enum([\"simple\", \"complex\"]),\n    inputData: z.string(),\n  }),\n  outputSchema: z.object({\n    result: z.any(),\n  }),\n  execute: async ({ context, mastra }) => {\n    if (!mastra) {\n      throw new Error(\"Mastra instance not available\");\n    }\n\n    if (!isMastra(mastra)) {\n      throw new Error(\"Invalid Mastra instance\");\n    }\n\n    // Create a new dynamic workflow based on the type\n    const dynamicWorkflow = new LegacyWorkflow({\n      name: `dynamic-${context.workflowType}-workflow`,\n      mastra,\n      triggerSchema: z.object({\n        input: z.string(),\n      }),\n    });\n\n    if (context.workflowType === \"simple\") {\n      // Simple workflow with a single step\n      const simpleStep = new Step({\n        id: \"simpleStep\",\n        execute: async ({ context }) => {\n          return {\n            result: `Simple processing: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(simpleStep).commit();\n    } else {\n      // Complex workflow with multiple steps\n      const step1 = new LegacyStep({\n        id: \"step1\",\n        outputSchema: z.object({\n          intermediateResult: z.string(),\n        }),\n        execute: async ({ context }) => {\n          return {\n            intermediateResult: `First processing: ${context.triggerData.input}`,\n          };\n        },\n      });\n\n      const step2 = new LegacyStep({\n        id: \"step2\",\n        execute: async ({ context }) => {\n          const intermediate = context.getStepResult(step1).intermediateResult;\n          return {\n            finalResult: `Second processing: ${intermediate}`,\n          };\n        },\n      });\n\n      dynamicWorkflow.step(step1).then(step2).commit();\n    }\n\n    // Execute the dynamic workflow\n    const run = dynamicWorkflow.createRun();\n    const result = await run.start({\n      triggerData: {\n        input: context.inputData,\n      },\n    });\n\n    // Return the appropriate result based on workflow type\n    if (context.workflowType === \"simple\") {\n      return {\n        // @ts-ignore\n        result: result.results[\"simpleStep\"]?.output,\n      };\n    } else {\n      return {\n        // @ts-ignore\n        result: result.results[\"step2\"]?.output,\n      };\n    }\n  },\n});\n```\n\n## Important Considerations\n\n1. **Mastra Instance**: The `mastra` parameter in the `execute` function provides access to the Mastra instance, which is essential for creating dynamic workflows.\n\n2. **Error Handling**: Always check if the Mastra instance is available before attempting to create a dynamic workflow.\n\n3. **Resource Management**: Dynamic workflows consume resources, so be mindful of creating too many workflows in a single execution.\n\n4. **Workflow Lifecycle**: Dynamic workflows are not automatically registered with the main Mastra instance. They exist only for the duration of the step execution unless you explicitly register them.\n\n5. **Debugging**: Debugging dynamic workflows can be challenging. Consider adding detailed logging to track their creation and execution.\n\n## Use Cases\n\n- **Conditional Workflow Selection**: Choose different workflow patterns based on input data\n- **Parameterized Workflows**: Create workflows with dynamic configurations\n- **Workflow Templates**: Use templates to generate specialized workflows\n- **Multi-tenant Applications**: Create isolated workflows for different tenants\n\n## Conclusion\n\nDynamic workflows provide a powerful way to create flexible, adaptable workflow systems. By leveraging the Mastra instance within step execution, you can create workflows that respond to runtime conditions and requirements.\n\n\n---\ntitle: \"Error Handling in Workflows (Legacy) | Mastra Docs\"\ndescription: \"Learn how to handle errors in Mastra legacy workflows using step retries, conditional branching, and monitoring.\"\n---\n\n# Error Handling in Workflows (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/error-handling\n\nRobust error handling is essential for production workflows. Mastra provides several mechanisms to handle errors gracefully, allowing your workflows to recover from failures or gracefully degrade when necessary.\n\n## Overview\n\nError handling in Mastra workflows can be implemented using:\n\n1. **Step Retries** - Automatically retry failed steps\n2. **Conditional Branching** - Create alternative paths based on step success or failure\n3. **Error Monitoring** - Watch workflows for errors and handle them programmatically\n4. **Result Status Checks** - Check the status of previous steps in subsequent steps\n\n## Step Retries\n\nMastra provides a built-in retry mechanism for steps that fail due to transient errors. This is particularly useful for steps that interact with external services or resources that might experience temporary unavailability.\n\n### Basic Retry Configuration\n\nYou can configure retries at the workflow level or for individual steps:\n\n```typescript\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\n// Workflow-level retry configuration\nconst workflow = new LegacyWorkflow({\n  name: \"my-workflow\",\n  retryConfig: {\n    attempts: 3, // Number of retry attempts\n    delay: 1000, // Delay between retries in milliseconds\n  },\n});\n\n// Step-level retry configuration (overrides workflow-level)\nconst apiStep = new LegacyStep({\n  id: \"callApi\",\n  execute: async () => {\n    // API call that might fail\n  },\n  retryConfig: {\n    attempts: 5, // This step will retry up to 5 times\n    delay: 2000, // With a 2-second delay between retries\n  },\n});\n```\n\nFor more details about step retries, see the [Step Retries](../../reference/legacyWorkflows/step-retries.mdx) reference.\n\n## Conditional Branching\n\nYou can create alternative workflow paths based on the success or failure of previous steps using conditional logic:\n\n```typescript\n// Create a workflow with conditional branching\nconst workflow = new LegacyWorkflow({\n  name: \"error-handling-workflow\",\n});\n\nworkflow\n  .step(fetchDataStep)\n  .then(processDataStep, {\n    // Only execute processDataStep if fetchDataStep was successful\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === \"success\";\n    },\n  })\n  .then(fallbackStep, {\n    // Execute fallbackStep if fetchDataStep failed\n    when: ({ context }) => {\n      return context.steps.fetchDataStep?.status === \"failed\";\n    },\n  })\n  .commit();\n```\n\n## Error Monitoring\n\nYou can monitor workflows for errors using the `watch` method:\n\n```typescript\nconst { start, watch } = workflow.createRun();\n\nwatch(async ({ results }) => {\n  // Check for any failed steps\n  const failedSteps = Object.entries(results)\n    .filter(([_, step]) => step.status === \"failed\")\n    .map(([stepId]) => stepId);\n\n  if (failedSteps.length > 0) {\n    console.error(`Workflow has failed steps: ${failedSteps.join(\", \")}`);\n    // Take remedial action, such as alerting or logging\n  }\n});\n\nawait start();\n```\n\n## Handling Errors in Steps\n\nWithin a step's execution function, you can handle errors programmatically:\n\n```typescript\nconst robustStep = new LegacyStep({\n  id: \"robustStep\",\n  execute: async ({ context }) => {\n    try {\n      // Attempt the primary operation\n      const result = await someRiskyOperation();\n      return { success: true, data: result };\n    } catch (error) {\n      // Log the error\n      console.error(\"Operation failed:\", error);\n\n      // Return a graceful fallback result instead of throwing\n      return {\n        success: false,\n        error: error.message,\n        fallbackData: \"Default value\",\n      };\n    }\n  },\n});\n```\n\n## Checking Previous Step Results\n\nYou can make decisions based on the results of previous steps:\n\n```typescript\nconst finalStep = new LegacyStep({\n  id: \"finalStep\",\n  execute: async ({ context }) => {\n    // Check results of previous steps\n    const step1Success = context.steps.step1?.status === \"success\";\n    const step2Success = context.steps.step2?.status === \"success\";\n\n    if (step1Success && step2Success) {\n      // All steps succeeded\n      return { status: \"complete\", result: \"All operations succeeded\" };\n    } else if (step1Success) {\n      // Only step1 succeeded\n      return { status: \"partial\", result: \"Partial completion\" };\n    } else {\n      // Critical failure\n      return { status: \"failed\", result: \"Critical steps failed\" };\n    }\n  },\n});\n```\n\n## Best Practices for Error Handling\n\n1. **Use retries for transient failures**: Configure retry policies for steps that might experience temporary issues.\n\n2. **Provide fallback paths**: Design workflows with alternative paths for when critical steps fail.\n\n3. **Be specific about error scenarios**: Use different handling strategies for different types of errors.\n\n4. **Log errors comprehensively**: Include context information when logging errors to aid in debugging.\n\n5. **Return meaningful data on failure**: When a step fails, return structured data about the failure to help downstream steps make decisions.\n\n6. **Consider idempotency**: Ensure steps can be safely retried without causing duplicate side effects.\n\n7. **Monitor workflow execution**: Use the `watch` method to actively monitor workflow execution and detect errors early.\n\n## Advanced Error Handling\n\nFor more complex error handling scenarios, consider:\n\n- **Implementing circuit breakers**: If a step fails repeatedly, stop retrying and use a fallback strategy\n- **Adding timeout handling**: Set time limits for steps to prevent workflows from hanging indefinitely\n- **Creating dedicated error recovery workflows**: For critical workflows, create separate recovery workflows that can be triggered when the main workflow fails\n\n## Related\n\n- [Step Retries Reference](../../reference/legacyWorkflows/step-retries.mdx)\n- [Watch Method Reference](../../reference/legacyWorkflows/watch.mdx)\n- [Step Conditions](../../reference/legacyWorkflows/step-condition.mdx)\n- [Control Flow](./control-flow.mdx)\n\n\n# Nested Workflows (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/nested-workflows\n\nMastra allows you to use workflows as steps within other workflows, enabling you to create modular and reusable workflow components. This feature helps in organizing complex workflows into smaller, manageable pieces and promotes code reuse.\n\nIt is also visually easier to understand the flow of a workflow when you can see the nested workflows as steps in the parent workflow.\n\n## Basic Usage\n\nYou can use a workflow as a step directly in another workflow using the `step()` method:\n\n```typescript\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\n// Create a nested workflow\nconst nestedWorkflow = new LegacyWorkflow({ name: \"nested-workflow\" })\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// Use the nested workflow in a parent workflow\nconst parentWorkflow = new LegacyWorkflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"myTriggerInput\",\n      },\n    },\n  })\n  .then(stepC)\n  .commit();\n```\n\nWhen a workflow is used as a step:\n\n- It is automatically converted to a step using the workflow's name as the step ID\n- The workflow's results are available in the parent workflow's context\n- The nested workflow's steps are executed in their defined order\n\n## Accessing Results\n\nResults from a nested workflow are available in the parent workflow's context under the nested workflow's name. The results include all step outputs from the nested workflow:\n\n```typescript\nconst { results } = await parentWorkflow.start();\n// Access nested workflow results\nconst nestedWorkflowResult = results[\"nested-workflow\"];\nif (nestedWorkflowResult.status === \"success\") {\n  const nestedResults = nestedWorkflowResult.output.results;\n}\n```\n\n## Control Flow with Nested Workflows\n\nNested workflows support all the control flow features available to regular steps:\n\n### Parallel Execution\n\nMultiple nested workflows can be executed in parallel:\n\n```typescript\nparentWorkflow\n  .step(nestedWorkflowA)\n  .step(nestedWorkflowB)\n  .after([nestedWorkflowA, nestedWorkflowB])\n  .step(finalStep);\n```\n\nOr using `step()` with an array of workflows:\n\n```typescript\nparentWorkflow.step([nestedWorkflowA, nestedWorkflowB]).then(finalStep);\n```\n\nIn this case, `then()` will implicitly wait for all the workflows to finish before executing the final step.\n\n### If-Else Branching\n\nNested workflows can be used in if-else branches using the new syntax that accepts both branches as arguments:\n\n```typescript\n// Create nested workflows for different paths\nconst workflowA = new LegacyWorkflow({ name: \"workflow-a\" })\n  .step(stepA1)\n  .then(stepA2)\n  .commit();\n\nconst workflowB = new LegacyWorkflow({ name: \"workflow-b\" })\n  .step(stepB1)\n  .then(stepB2)\n  .commit();\n\n// Use the new if-else syntax with nested workflows\nparentWorkflow\n  .step(initialStep)\n  .if(\n    async ({ context }) => {\n      // Your condition here\n      return someCondition;\n    },\n    workflowA, // if branch\n    workflowB, // else branch\n  )\n  .then(finalStep)\n  .commit();\n```\n\nThe new syntax is more concise and clearer when working with nested workflows. When the condition is:\n\n- `true`: The first workflow (if branch) is executed\n- `false`: The second workflow (else branch) is executed\n\nThe skipped workflow will have a status of `skipped` in the results:\n\nThe `.then(finalStep)` call following the if-else block will merge the if and else branches back into a single execution path.\n\n### Looping\n\nNested workflows can use `.until()` and `.while()` loops same as any other step. One interesting new pattern is to pass a workflow directly as the loop-back argument to keep executing that nested workflow until something is true about its results:\n\n```typescript\nparentWorkflow\n  .step(firstStep)\n  .while(\n    ({ context }) =>\n      context.getStepResult(\"nested-workflow\").output.results.someField ===\n      \"someValue\",\n    nestedWorkflow,\n  )\n  .step(finalStep)\n  .commit();\n```\n\n## Watching Nested Workflows\n\nYou can watch the state changes of nested workflows using the `watch` method on the parent workflow. This is useful for monitoring the progress and state transitions of complex workflows:\n\n```typescript\nconst parentWorkflow = new LegacyWorkflow({ name: \"parent-workflow\" })\n  .step([nestedWorkflowA, nestedWorkflowB])\n  .then(finalStep)\n  .commit();\n\nconst run = parentWorkflow.createRun();\nconst unwatch = parentWorkflow.watch((state) => {\n  console.log(\"Current state:\", state.value);\n  // Access nested workflow states in state.context\n});\n\nawait run.start();\nunwatch(); // Stop watching when done\n```\n\n## Suspending and Resuming\n\nNested workflows support suspension and resumption, allowing you to pause and continue workflow execution at specific points. You can suspend either the entire nested workflow or specific steps within it:\n\n```typescript\n// Define a step that may need to suspend\nconst suspendableStep = new LegacyStep({\n  id: \"other\",\n  description: \"Step that may need to suspend\",\n  execute: async ({ context, suspend }) => {\n    if (!wasSuspended) {\n      wasSuspended = true;\n      await suspend();\n    }\n    return { other: 26 };\n  },\n});\n\n// Create a nested workflow with suspendable steps\nconst nestedWorkflow = new LegacyWorkflow({ name: \"nested-workflow-a\" })\n  .step(startStep)\n  .then(suspendableStep)\n  .then(finalStep)\n  .commit();\n\n// Use in parent workflow\nconst parentWorkflow = new LegacyWorkflow({ name: \"parent-workflow\" })\n  .step(beginStep)\n  .then(nestedWorkflow)\n  .then(lastStep)\n  .commit();\n\n// Start the workflow\nconst run = parentWorkflow.createRun();\nconst { runId, results } = await run.start({ triggerData: { startValue: 1 } });\n\n// Check if a specific step in the nested workflow is suspended\nif (results[\"nested-workflow-a\"].output.results.other.status === \"suspended\") {\n  // Resume the specific suspended step using dot notation\n  const resumedResults = await run.resume({\n    stepId: \"nested-workflow-a.other\",\n    context: { startValue: 1 },\n  });\n\n  // The resumed results will contain the completed nested workflow\n  expect(resumedResults.results[\"nested-workflow-a\"].output.results).toEqual({\n    start: { output: { newValue: 1 }, status: \"success\" },\n    other: { output: { other: 26 }, status: \"success\" },\n    final: { output: { finalValue: 27 }, status: \"success\" },\n  });\n}\n```\n\nWhen resuming a nested workflow:\n\n- Use the nested workflow's name as the `stepId` when calling `resume()` to resume the entire workflow\n- Use dot notation (`nested-workflow.step-name`) to resume a specific step within the nested workflow\n- The nested workflow will continue from the suspended step with the provided context\n- You can check the status of specific steps in the nested workflow's results using `results[\"nested-workflow\"].output.results`\n\n## Result Schemas and Mapping\n\nNested workflows can define their result schema and mapping, which helps in type safety and data transformation. This is particularly useful when you want to ensure the nested workflow's output matches a specific structure or when you need to transform the results before they're used in the parent workflow.\n\n```typescript\n// Create a nested workflow with result schema and mapping\nconst nestedWorkflow = new LegacyWorkflow({\n  name: \"nested-workflow\",\n  result: {\n    schema: z.object({\n      total: z.number(),\n      items: z.array(\n        z.object({\n          id: z.string(),\n          value: z.number(),\n        }),\n      ),\n    }),\n    mapping: {\n      // Map values from step results using variables syntax\n      total: { step: \"step-a\", path: \"count\" },\n      items: { step: \"step-b\", path: \"items\" },\n    },\n  },\n})\n  .step(stepA)\n  .then(stepB)\n  .commit();\n\n// Use in parent workflow with type-safe results\nconst parentWorkflow = new LegacyWorkflow({ name: \"parent-workflow\" })\n  .step(nestedWorkflow)\n  .then(async ({ context }) => {\n    const result = context.getStepResult(\"nested-workflow\");\n    // TypeScript knows the structure of result\n    console.log(result.total); // number\n    console.log(result.items); // Array<{ id: string, value: number }>\n    return { success: true };\n  })\n  .commit();\n```\n\n## Best Practices\n\n1. **Modularity**: Use nested workflows to encapsulate related steps and create reusable workflow components.\n2. **Naming**: Give nested workflows descriptive names as they will be used as step IDs in the parent workflow.\n3. **Error Handling**: Nested workflows propagate their errors to the parent workflow, so handle errors appropriately.\n4. **State Management**: Each nested workflow maintains its own state but can access the parent workflow's context.\n5. **Suspension**: When using suspension in nested workflows, consider the entire workflow's state and handle resumption appropriately.\n\n## Example\n\nHere's a complete example showing various features of nested workflows:\n\n```typescript\nconst workflowA = new LegacyWorkflow({\n  name: \"workflow-a\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst workflowB = new LegacyWorkflow({\n  name: \"workflow-b\",\n  result: {\n    schema: z.object({\n      activities: z.string(),\n    }),\n    mapping: {\n      activities: {\n        step: planActivities,\n        path: \"activities\",\n      },\n    },\n  },\n})\n  .step(fetchWeather)\n  .then(planActivities)\n  .commit();\n\nconst weatherWorkflow = new LegacyWorkflow({\n  name: \"weather-workflow\",\n  triggerSchema: z.object({\n    cityA: z.string().describe(\"The city to get the weather for\"),\n    cityB: z.string().describe(\"The city to get the weather for\"),\n  }),\n  result: {\n    schema: z.object({\n      activitiesA: z.string(),\n      activitiesB: z.string(),\n    }),\n    mapping: {\n      activitiesA: {\n        step: workflowA,\n        path: \"result.activities\",\n      },\n      activitiesB: {\n        step: workflowB,\n        path: \"result.activities\",\n      },\n    },\n  },\n})\n  .step(workflowA, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityA\",\n      },\n    },\n  })\n  .step(workflowB, {\n    variables: {\n      city: {\n        step: \"trigger\",\n        path: \"cityB\",\n      },\n    },\n  });\n\nweatherWorkflow.commit();\n```\n\nIn this example:\n\n1. We define schemas for type safety across all workflows\n2. Each step has proper input and output schemas\n3. The nested workflows have their own trigger schemas and result mappings\n4. Data is passed through using variables syntax in the `.step()` calls\n5. The main workflow combines data from both nested workflows\n\n\n---\ntitle: \"Handling Complex LLM Operations | Workflows (Legacy) | Mastra\"\ndescription: \"Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.\"\n---\n\n# Handling Complex LLM Operations with Workflows (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/overview\n\nAll the legacy workflow documentation is available on the links below.\n\n- [Steps](/docs/workflows-legacy/steps/)\n- [Control Flow](/docs/workflows-legacy/control-flow/)\n- [Variables](/docs/workflows-legacy/variables/)\n- [Suspend & Resume](/docs/workflows-legacy/suspend-and-resume/)\n- [Dynamic Workflows](/docs/workflows-legacy/dynamic-workflows/)\n- [Error Handling](/docs/workflows-legacy/error-handling/)\n- [Nested Workflows](/docs/workflows-legacy/nested-workflows/)\n- [Runtime/Dynamic Variables](/docs/workflows-legacy/runtime-variables/)\n\nWorkflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.\n\n## When to use workflows\n\nMost AI applications need more than a single call to a language model. You may want to run multiple steps, conditionally skip certain paths, or even pause execution altogether until you receive user input. Sometimes your agent tool calling is not accurate enough.\n\nMastra's workflow system provides:\n\n- A standardized way to define steps and link them together.\n- Support for both simple (linear) and advanced (branching, parallel) paths.\n- Debugging and observability features to track each workflow run.\n\n## Example\n\nTo create a workflow, you define one or more steps, link them, and then commit the workflow before starting it.\n\n### Breaking Down the Workflow (Legacy)\n\nLet's examine each part of the workflow creation process:\n\n#### 1. Creating the Workflow\n\nHere's how you define a workflow in Mastra. The `name` field determines the workflow's API endpoint (`/workflows/$NAME/`), while the `triggerSchema` defines the structure of the workflow's trigger data:\n\n```ts filename=\"src/mastra/workflow/index.ts\"\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\nconst myWorkflow = new LegacyWorkflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n```\n\n#### 2. Defining Steps\n\nNow, we'll define the workflow's steps. Each step can have its own input and output schemas. Here, `stepOne` doubles an input value, and `stepTwo` increments that result if `stepOne` was successful. (To keep things simple, we aren't making any LLM calls in this example):\n\n```ts filename=\"src/mastra/workflow/index.ts\"\nconst stepOne = new LegacyStep({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const doubledValue = context.triggerData.inputValue * 2;\n    return { doubledValue };\n  },\n});\n\nconst stepTwo = new LegacyStep({\n  id: \"stepTwo\",\n  execute: async ({ context }) => {\n    const doubledValue = context.getStepResult(stepOne)?.doubledValue;\n    if (!doubledValue) {\n      return { incrementedValue: 0 };\n    }\n    return {\n      incrementedValue: doubledValue + 1,\n    };\n  },\n});\n```\n\n#### 3. Linking Steps\n\nNow, let's create the control flow, and \"commit\" (finalize the workflow). In this case, `stepOne` runs first and is followed by `stepTwo`.\n\n```ts filename=\"src/mastra/workflow/index.ts\"\nmyWorkflow.step(stepOne).then(stepTwo).commit();\n```\n\n### Register the Workflow\n\nRegister your workflow with Mastra to enable logging and telemetry:\n\n```ts showLineNumbers filename=\"src/mastra/index.ts\"\nimport { Mastra } from \"@mastra/core\";\n\nexport const mastra = new Mastra({\n  legacy_workflows: { myWorkflow },\n});\n```\n\nThe workflow can also have the mastra instance injected into the context in the case where you need to create dynamic workflows:\n\n```ts filename=\"src/mastra/workflow/index.ts\"\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\nconst mastra = new Mastra();\n\nconst myWorkflow = new LegacyWorkflow({\n  name: \"my-workflow\",\n  mastra,\n});\n```\n\n### Executing the Workflow\n\nExecute your workflow programmatically or via API:\n\n```ts showLineNumbers filename=\"src/mastra/run-workflow.ts\" copy\nimport { mastra } from \"./index\";\n\n// Get the workflow\nconst myWorkflow = mastra.legacy_getWorkflow(\"myWorkflow\");\nconst { runId, start } = myWorkflow.createRun();\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 } });\n```\n\nOr use the API (requires running `mastra dev`):\n\n// Create workflow run\n\n```bash\ncurl --location 'http://localhost:5000/api/workflows/myWorkflow/start-async' \\\n     --header 'Content-Type: application/json' \\\n     --data '{\n       \"inputValue\": 45\n     }'\n```\n\nThis example shows the essentials: define your workflow, add steps, commit the workflow, then execute it.\n\n## Defining Steps\n\nThe basic building block of a workflow [is a step](./steps.mdx). Steps are defined using schemas for inputs and outputs, and can fetch prior step results.\n\n## Control Flow\n\nWorkflows let you define a [control flow](./control-flow.mdx) to chain steps together in with parallel steps, branching paths, and more.\n\n## Workflow Variables\n\nWhen you need to map data between steps or create dynamic data flows, [workflow variables](./variables.mdx) provide a powerful mechanism for passing information from one step to another and accessing nested properties within step outputs.\n\n## Suspend and Resume\n\nWhen you need to pause execution for external data, user input, or asynchronous events, Mastra [supports suspension at any step](./suspend-and-resume.mdx), persisting the state of the workflow so you can resume it later.\n\n## Observability and Debugging\n\nMastra workflows automatically [log the input and output of each step within a workflow run](../../reference/observability/otel-config.mdx), allowing you to send this data to your preferred logging, telemetry, or observability tools.\n\nYou can:\n\n- Track the status of each step (e.g., `success`, `error`, or `suspended`).\n- Store run-specific metadata for analysis.\n- Integrate with third-party observability platforms like Datadog or New Relic by forwarding logs.\n\n## More Resources\n\n- [Sequential Steps workflow example](../../examples/workflows_legacy/sequential-steps.mdx)\n- [Parallel Steps workflow example](../../examples/workflows_legacy/parallel-steps.mdx)\n- [Branching Paths workflow example](../../examples/workflows_legacy/branching-paths.mdx)\n- [Workflow Variables example](../../examples/workflows_legacy/workflow-variables.mdx)\n- [Cyclical Dependencies workflow example](../../examples/workflows_legacy/cyclical-dependencies.mdx)\n- [Suspend and Resume workflow example](../../examples/workflows_legacy/suspend-and-resume.mdx)\n\n\n---\ntitle: \"Runtime variables - dependency injection | Workflows (Legacy) | Mastra Docs\"\ndescription: Learn how to use Mastra's dependency injection system to provide runtime configuration to workflows and steps.\n---\n\n# Workflow Runtime Variables (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/runtime-variables\n\nMastra provides a powerful dependency injection system that enables you to configure your workflows and steps with runtime variables. This feature is essential for creating flexible and reusable workflows that can adapt their behavior based on runtime configuration.\n\n## Overview\n\nThe dependency injection system allows you to:\n\n1. Pass runtime configuration variables to workflows through a type-safe runtimeContext\n2. Access these variables within step execution contexts\n3. Modify workflow behavior without changing the underlying code\n4. Share configuration across multiple steps within the same workflow\n\n## Basic Usage\n\n```typescript\nconst myWorkflow = mastra.legacy_getWorkflow(\"myWorkflow\");\nconst { runId, start, resume } = myWorkflow.createRun();\n\n// Define your runtimeContext's type structure\ntype WorkflowRuntimeContext = {\n  multiplier: number;\n};\n\nconst runtimeContext = new RuntimeContext<WorkflowRuntimeContext>();\nruntimeContext.set(\"multiplier\", 5);\n\n// Start the workflow execution with runtimeContext\nawait start({\n  triggerData: { inputValue: 45 },\n  runtimeContext,\n});\n```\n\n## Using with REST API\n\nHere's how to dynamically set a multiplier value from an HTTP header:\n\n```typescript filename=\"src/index.ts\"\nimport { Mastra } from \"@mastra/core\";\nimport { RuntimeContext } from \"@mastra/core/di\";\nimport { workflow as myWorkflow } from \"./workflows\";\n\n// Define runtimeContext type with clear, descriptive types\ntype WorkflowRuntimeContext = {\n  multiplier: number;\n};\n\nexport const mastra = new Mastra({\n  legacy_workflows: {\n    myWorkflow,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const multiplier = c.req.header(\"x-multiplier\");\n        const runtimeContext = c.get<WorkflowRuntimeContext>(\"runtimeContext\");\n\n        // Parse and validate the multiplier value\n        const multiplierValue = parseInt(multiplier || \"1\", 10);\n        if (isNaN(multiplierValue)) {\n          throw new Error(\"Invalid multiplier value\");\n        }\n\n        runtimeContext.set(\"multiplier\", multiplierValue);\n\n        await next(); // Don't forget to call next()\n      },\n    ],\n  },\n});\n```\n\n## Creating Steps with Variables\n\nSteps can access runtimeContext variables and must conform to the workflow's runtimeContext type:\n\n```typescript\nimport { LegacyStep } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define step input/output types\ninterface StepInput {\n  inputValue: number;\n}\n\ninterface StepOutput {\n  incrementedValue: number;\n}\n\nconst stepOne = new LegacyStep({\n  id: \"stepOne\",\n  description: \"Multiply the input value by the configured multiplier\",\n  execute: async ({ context, runtimeContext }) => {\n    try {\n      // Type-safe access to runtimeContext variables\n      const multiplier = runtimeContext.get(\"multiplier\");\n      if (multiplier === undefined) {\n        throw new Error(\"Multiplier not configured in runtimeContext\");\n      }\n\n      // Get and validate input\n      const inputValue =\n        context.getStepResult<StepInput>(\"trigger\")?.inputValue;\n      if (inputValue === undefined) {\n        throw new Error(\"Input value not provided\");\n      }\n\n      const result: StepOutput = {\n        incrementedValue: inputValue * multiplier,\n      };\n\n      return result;\n    } catch (error) {\n      console.error(`Error in stepOne: ${error.message}`);\n      throw error;\n    }\n  },\n});\n```\n\n## Error Handling\n\nWhen working with runtime variables in workflows, it's important to handle potential errors:\n\n1. **Missing Variables**: Always check if required variables exist in the runtimeContext\n2. **Type Mismatches**: Use TypeScript's type system to catch type errors at compile time\n3. **Invalid Values**: Validate variable values before using them in your steps\n\n```typescript\n// Example of defensive programming with runtimeContext variables\nconst multiplier = runtimeContext.get(\"multiplier\");\nif (multiplier === undefined) {\n  throw new Error(\"Multiplier not configured in runtimeContext\");\n}\n\n// Type and value validation\nif (typeof multiplier !== \"number\" || multiplier <= 0) {\n  throw new Error(`Invalid multiplier value: ${multiplier}`);\n}\n```\n\n## Best Practices\n\n1. **Type Safety**: Always define proper types for your runtimeContext and step inputs/outputs\n2. **Validation**: Validate all inputs and runtimeContext variables before using them\n3. **Error Handling**: Implement proper error handling in your steps\n4. **Documentation**: Document the expected runtimeContext variables for each workflow\n5. **Default Values**: Provide sensible defaults when possible\n\n\n---\ntitle: \"Creating Steps and Adding to Workflows (Legacy) | Mastra Docs\"\ndescription: \"Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.\"\n---\n\n# Defining Steps in a Workflow (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/steps\n\nWhen you build a workflow, you typically break down operations into smaller tasks that can be linked and reused. Steps provide a structured way to manage these tasks by defining inputs, outputs, and execution logic.\n\nThe code below shows how to define these steps inline or separately.\n\n## Inline Step Creation\n\nYou can create steps directly within your workflow using `.step()` and `.then()`. This code shows how to define, link, and execute two steps in sequence.\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/index.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\nexport const myWorkflow = new LegacyWorkflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow\n  .step(\n    new LegacyStep({\n      id: \"stepOne\",\n      outputSchema: z.object({\n        doubledValue: z.number(),\n      }),\n      execute: async ({ context }) => ({\n        doubledValue: context.triggerData.inputValue * 2,\n      }),\n    }),\n  )\n  .then(\n    new LegacyStep({\n      id: \"stepTwo\",\n      outputSchema: z.object({\n        incrementedValue: z.number(),\n      }),\n      execute: async ({ context }) => {\n        if (context.steps.stepOne.status !== \"success\") {\n          return { incrementedValue: 0 };\n        }\n\n        return {\n          incrementedValue: context.steps.stepOne.output.doubledValue + 1,\n        };\n      },\n    }),\n  )\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { myWorkflow },\n});\n```\n\n## Creating Steps Separately\n\nIf you prefer to manage your step logic in separate entities, you can define steps outside and then add them to your workflow. This code shows how to define steps independently and link them afterward.\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/index.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define steps separately\nconst stepOne = new LegacyStep({\n  id: \"stepOne\",\n  outputSchema: z.object({\n    doubledValue: z.number(),\n  }),\n  execute: async ({ context }) => ({\n    doubledValue: context.triggerData.inputValue * 2,\n  }),\n});\n\nconst stepTwo = new LegacyStep({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: context.steps.stepOne.output.doubledValue + 1 };\n  },\n});\n\n// Build the workflow\nconst myWorkflow = new LegacyWorkflow({\n  name: \"my-workflow\",\n  triggerSchema: z.object({\n    inputValue: z.number(),\n  }),\n});\n\nmyWorkflow.step(stepOne).then(stepTwo);\nmyWorkflow.commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { myWorkflow },\n});\n```\n\n\n---\ntitle: \"Suspend & Resume Workflows (Legacy) | Human-in-the-Loop | Mastra Docs\"\ndescription: \"Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.\"\n---\n\n# Suspend and Resume in Workflows (Legacy)\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/suspend-and-resume\n\nComplex workflows often need to pause execution while waiting for external input or resources.\n\nMastra's suspend and resume features let you pause workflow execution at any step, persist the workflow snapshot to storage, and resume execution from the saved snapshot when ready.\nThis entire process is automatically managed by Mastra. No config needed, or manual step required from the user.\n\nStoring the workflow snapshot to storage (LibSQL by default) means that the workflow state is permanently preserved across sessions, deployments, and server restarts. This persistence is crucial for workflows that might remain suspended for minutes, hours, or even days while waiting for external input or resources.\n\n## When to Use Suspend/Resume\n\nCommon scenarios for suspending workflows include:\n\n- Waiting for human approval or input\n- Pausing until external API resources become available\n- Collecting additional data needed for later steps\n- Rate limiting or throttling expensive operations\n- Handling event-driven processes with external triggers\n\n## Basic Suspend Example\n\nHere's a simple workflow that suspends when a value is too low and resumes when given a higher value:\n\n```typescript\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\nconst stepTwo = new LegacyStep({\n  id: \"stepTwo\",\n  outputSchema: z.object({\n    incrementedValue: z.number(),\n  }),\n  execute: async ({ context, suspend }) => {\n    if (context.steps.stepOne.status !== \"success\") {\n      return { incrementedValue: 0 };\n    }\n\n    const currentValue = context.steps.stepOne.output.doubledValue;\n\n    if (currentValue < 100) {\n      await suspend();\n      return { incrementedValue: 0 };\n    }\n    return { incrementedValue: currentValue + 1 };\n  },\n});\n```\n\n## Async/Await Based Flow\n\nThe suspend and resume mechanism in Mastra uses an async/await pattern that makes it intuitive to implement complex workflows with suspension points. The code structure naturally reflects the execution flow.\n\n### How It Works\n\n1. A step's execution function receives a `suspend` function in its parameters\n2. When called with `await suspend()`, the workflow pauses at that point\n3. The workflow state is persisted\n4. Later, the workflow can be resumed by calling `workflow.resume()` with the appropriate parameters\n5. Execution continues from the point after the `suspend()` call\n\n### Example with Multiple Suspension Points\n\nHere's an example of a workflow with multiple steps that can suspend:\n\n```typescript\n// Define steps with suspend capability\nconst promptAgentStep = new LegacyStep({\n  id: \"promptAgent\",\n  execute: async ({ context, suspend }) => {\n    // Some condition that determines if we need to suspend\n    if (needHumanInput) {\n      // Optionally pass payload data that will be stored with suspended state\n      await suspend({ requestReason: \"Need human input for prompt\" });\n      // Code after suspend() will execute when the step is resumed\n      return { modelOutput: context.userInput };\n    }\n    return { modelOutput: \"AI generated output\" };\n  },\n  outputSchema: z.object({ modelOutput: z.string() }),\n});\n\nconst improveResponseStep = new LegacyStep({\n  id: \"improveResponse\",\n  execute: async ({ context, suspend }) => {\n    // Another condition for suspension\n    if (needFurtherRefinement) {\n      await suspend();\n      return { improvedOutput: context.refinedOutput };\n    }\n    return { improvedOutput: \"Improved output\" };\n  },\n  outputSchema: z.object({ improvedOutput: z.string() }),\n});\n\n// Build the workflow\nconst workflow = new LegacyWorkflow({\n  name: \"multi-suspend-workflow\",\n  triggerSchema: z.object({ input: z.string() }),\n});\n\nworkflow\n  .step(getUserInput)\n  .then(promptAgentStep)\n  .then(evaluateTone)\n  .then(improveResponseStep)\n  .then(evaluateImproved)\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { workflow },\n});\n```\n\n### Starting and Resuming the Workflow\n\n```typescript\n// Get the workflow and create a run\nconst wf = mastra.legacy_getWorkflow(\"multi-suspend-workflow\");\nconst run = wf.createRun();\n\n// Start the workflow\nconst initialResult = await run.start({\n  triggerData: { input: \"initial input\" },\n});\n\nlet promptAgentStepResult = initialResult.activePaths.get(\"promptAgent\");\nlet promptAgentResumeResult = undefined;\n\n// Check if a step is suspended\nif (promptAgentStepResult?.status === \"suspended\") {\n  console.log(\"Workflow suspended at promptAgent step\");\n\n  // Resume the workflow with new context\n  const resumeResult = await run.resume({\n    stepId: \"promptAgent\",\n    context: { userInput: \"Human provided input\" },\n  });\n\n  promptAgentResumeResult = resumeResult;\n}\n\nconst improveResponseStepResult =\n  promptAgentResumeResult?.activePaths.get(\"improveResponse\");\n\nif (improveResponseStepResult?.status === \"suspended\") {\n  console.log(\"Workflow suspended at improveResponse step\");\n\n  // Resume again with different context\n  const finalResult = await run.resume({\n    stepId: \"improveResponse\",\n    context: { refinedOutput: \"Human refined output\" },\n  });\n\n  console.log(\"Workflow completed:\", finalResult?.results);\n}\n```\n\n## Event-Based Suspension and Resumption\n\nIn addition to manually suspending steps, Mastra provides event-based suspension through the `afterEvent` method. This allows workflows to automatically suspend and wait for a specific event to occur before continuing.\n\n### Using afterEvent and resumeWithEvent\n\nThe `afterEvent` method automatically creates a suspension point in your workflow that waits for a specific event to occur. When the event happens, you can use `resumeWithEvent` to continue the workflow with the event data.\n\nHere's how it works:\n\n1. Define events in your workflow configuration\n2. Use `afterEvent` to create a suspension point waiting for that event\n3. When the event occurs, call `resumeWithEvent` with the event name and data\n\n### Example: Event-Based Workflow\n\n```typescript\n// Define steps\nconst getUserInput = new LegacyStep({\n  id: \"getUserInput\",\n  execute: async () => ({ userInput: \"initial input\" }),\n  outputSchema: z.object({ userInput: z.string() }),\n});\n\nconst processApproval = new LegacyStep({\n  id: \"processApproval\",\n  execute: async ({ context }) => {\n    // Access the event data from the context\n    const approvalData = context.inputData?.resumedEvent;\n    return {\n      approved: approvalData?.approved,\n      approvedBy: approvalData?.approverName,\n    };\n  },\n  outputSchema: z.object({\n    approved: z.boolean(),\n    approvedBy: z.string(),\n  }),\n});\n\n// Create workflow with event definition\nconst approvalWorkflow = new LegacyWorkflow({\n  name: \"approval-workflow\",\n  triggerSchema: z.object({ requestId: z.string() }),\n  events: {\n    approvalReceived: {\n      schema: z.object({\n        approved: z.boolean(),\n        approverName: z.string(),\n      }),\n    },\n  },\n});\n\n// Build workflow with event-based suspension\napprovalWorkflow\n  .step(getUserInput)\n  .afterEvent(\"approvalReceived\") // Workflow will automatically suspend here\n  .step(processApproval) // This step runs after the event is received\n  .commit();\n```\n\n### Running an Event-Based Workflow\n\n```typescript\n// Get the workflow\nconst workflow = mastra.legacy_getWorkflow(\"approval-workflow\");\nconst run = workflow.createRun();\n\n// Start the workflow\nconst initialResult = await run.start({\n  triggerData: { requestId: \"request-123\" },\n});\n\nconsole.log(\"Workflow started, waiting for approval event\");\nconsole.log(initialResult.results);\n// Output will show the workflow is suspended at the event step:\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'suspended' }\n// }\n\n// Later, when the approval event occurs:\nconst resumeResult = await run.resumeWithEvent(\"approvalReceived\", {\n  approved: true,\n  approverName: \"Jane Doe\",\n});\n\nconsole.log(\"Workflow resumed with event data:\", resumeResult.results);\n// Output will show the completed workflow:\n// {\n//   getUserInput: { status: 'success', output: { userInput: 'initial input' } },\n//   __approvalReceived_event: { status: 'success', output: { executed: true, resumedEvent: { approved: true, approverName: 'Jane Doe' } } },\n//   processApproval: { status: 'success', output: { approved: true, approvedBy: 'Jane Doe' } }\n// }\n```\n\n### Key Points About Event-Based Workflows\n\n- The `suspend()` function can optionally take a payload object that will be stored with the suspended state\n- Code after the `await suspend()` call will not execute until the step is resumed\n- When a step is suspended, its status becomes `'suspended'` in the workflow results\n- When resumed, the step's status changes from `'suspended'` to `'success'` once completed\n- The `resume()` method requires the `stepId` to identify which suspended step to resume\n- You can provide new context data when resuming that will be merged with existing step results\n\n- Events must be defined in the workflow configuration with a schema\n- The `afterEvent` method creates a special suspended step that waits for the event\n- The event step is automatically named `__eventName_event` (e.g., `__approvalReceived_event`)\n- Use `resumeWithEvent` to provide event data and continue the workflow\n- Event data is validated against the schema defined for that event\n- The event data is available in the context as `inputData.resumedEvent`\n\n## Storage for Suspend and Resume\n\nWhen a workflow is suspended using `await suspend()`, Mastra automatically persists the entire workflow state to storage. This is essential for workflows that might remain suspended for extended periods, as it ensures the state is preserved across application restarts or server instances.\n\n### Default Storage: LibSQL\n\nBy default, Mastra uses LibSQL as its storage engine:\n\n```typescript\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { LibSQLStore } from \"@mastra/libsql\";\n\nconst mastra = new Mastra({\n  storage: new LibSQLStore({\n    url: \"file:./storage.db\", // Local file-based database for development\n    // For production, use a persistent URL:\n    // url: process.env.DATABASE_URL,\n    // authToken: process.env.DATABASE_AUTH_TOKEN, // Optional for authenticated connections\n  }),\n});\n```\n\nThe LibSQL storage can be configured in different modes:\n\n- In-memory database (testing): `:memory:`\n- File-based database (development): `file:storage.db`\n- Remote database (production): URLs like `libsql://your-database.turso.io`\n\n### Alternative Storage Options\n\n#### Upstash (Redis-Compatible)\n\nFor serverless applications or environments where Redis is preferred:\n\n```bash copy\nnpm install @mastra/upstash@latest\n```\n\n```typescript\nimport { Mastra } from \"@mastra/core/mastra\";\nimport { UpstashStore } from \"@mastra/upstash\";\n\nconst mastra = new Mastra({\n  storage: new UpstashStore({\n    url: process.env.UPSTASH_URL,\n    token: process.env.UPSTASH_TOKEN,\n  }),\n});\n```\n\n### Storage Considerations\n\n- All storage options support suspend and resume functionality identically\n- The workflow state is automatically serialized and saved when suspended\n- No additional configuration is needed for suspend/resume to work with storage\n- Choose your storage option based on your infrastructure, scaling needs, and existing technology stack\n\n## Watching and Resuming\n\nTo handle suspended workflows, use the `watch` method to monitor workflow status per run and `resume` to continue execution:\n\n```typescript\nimport { mastra } from \"./index\";\n\n// Get the workflow\nconst myWorkflow = mastra.legacy_getWorkflow(\"myWorkflow\");\nconst { start, watch, resume } = myWorkflow.createRun();\n\n// Start watching the workflow before executing it\nwatch(async ({ activePaths }) => {\n  const isStepTwoSuspended = activePaths.get(\"stepTwo\")?.status === \"suspended\";\n  if (isStepTwoSuspended) {\n    console.log(\"Workflow suspended, resuming with new value\");\n\n    // Resume the workflow with new context\n    await resume({\n      stepId: \"stepTwo\",\n      context: { secondValue: 100 },\n    });\n  }\n});\n\n// Start the workflow execution\nawait start({ triggerData: { inputValue: 45 } });\n```\n\n### Watching and Resuming Event-Based Workflows\n\nYou can use the same watching pattern with event-based workflows:\n\n```typescript\nconst { start, watch, resumeWithEvent } = workflow.createRun();\n\n// Watch for suspended event steps\nwatch(async ({ activePaths }) => {\n  const isApprovalReceivedSuspended =\n    activePaths.get(\"__approvalReceived_event\")?.status === \"suspended\";\n  if (isApprovalReceivedSuspended) {\n    console.log(\"Workflow waiting for approval event\");\n\n    // In a real scenario, you would wait for the actual event to occur\n    // For example, this could be triggered by a webhook or user interaction\n    setTimeout(async () => {\n      await resumeWithEvent(\"approvalReceived\", {\n        approved: true,\n        approverName: \"Auto Approver\",\n      });\n    }, 5000); // Simulate event after 5 seconds\n  }\n});\n\n// Start the workflow\nawait start({ triggerData: { requestId: \"auto-123\" } });\n```\n\n## Further Reading\n\nFor a deeper understanding of how suspend and resume works under the hood:\n\n- [Understanding Snapshots in Mastra Workflows](../../reference/legacyWorkflows/snapshots.mdx) - Learn about the snapshot mechanism that powers suspend and resume functionality\n- [Step Configuration Guide](./steps.mdx) - Learn more about configuring steps in your workflows\n- [Control Flow Guide](./control-flow.mdx) - Advanced workflow control patterns\n- [Event-Driven Workflows](../../reference/legacyWorkflows/events.mdx) - Detailed reference for event-based workflows\n\n## Related Resources\n\n- See the [Suspend and Resume Example](../../examples/workflows_legacy/suspend-and-resume.mdx) for a complete working example\n- Check the [Step Class Reference](../../reference/legacyWorkflows/step-class.mdx) for suspend/resume API details\n- Review [Workflow Observability](../../reference/observability/otel-config.mdx) for monitoring suspended workflows\n\n\n---\ntitle: \"Data Mapping with Workflow (Legacy) Variables | Mastra Docs\"\ndescription: \"Learn how to use workflow variables to map data between steps and create dynamic data flows in your Mastra workflows.\"\n---\n\n# Data Mapping with Workflow Variables\n[EN] Source: https://mastra.ai/en/docs/workflows-legacy/variables\n\nWorkflow variables in Mastra provide a powerful mechanism for mapping data between steps, allowing you to create dynamic data flows and pass information from one step to another.\n\n## Understanding Workflow Variables\n\nIn Mastra workflows, variables serve as a way to:\n\n- Map data from trigger inputs to step inputs\n- Pass outputs from one step to inputs of another step\n- Access nested properties within step outputs\n- Create more flexible and reusable workflow steps\n\n## Using Variables for Data Mapping\n\n### Basic Variable Mapping\n\nYou can map data between steps using the `variables` property when adding a step to your workflow:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/index.ts\" copy\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\n\nconst workflow = new LegacyWorkflow({\n  name: \"data-mapping-workflow\",\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\nworkflow\n  .step(step1, {\n    variables: {\n      // Map trigger data to step input\n      inputData: { step: \"trigger\", path: \"inputData\" },\n    },\n  })\n  .then(step2, {\n    variables: {\n      // Map output from step1 to input for step2\n      previousValue: { step: step1, path: \"outputField\" },\n    },\n  })\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { workflow },\n});\n```\n\n### Accessing Nested Properties\n\nYou can access nested properties using dot notation in the `path` field:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/index.ts\" copy\nworkflow\n  .step(step1)\n  .then(step2, {\n    variables: {\n      // Access a nested property from step1's output\n      nestedValue: { step: step1, path: \"nested.deeply.value\" },\n    },\n  })\n  .commit();\n```\n\n### Mapping Entire Objects\n\nYou can map an entire object by using `.` as the path:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/index.ts\" copy\nworkflow\n  .step(step1, {\n    variables: {\n      // Map the entire trigger data object\n      triggerData: { step: \"trigger\", path: \".\" },\n    },\n  })\n  .commit();\n```\n\n### Variables in Loops\n\nVariables can also be passed to `while` and `until` loops. This is useful for passing data between iterations or from outside steps:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/loop-variables.ts\" copy\n// Step that increments a counter\nconst incrementStep = new LegacyStep({\n  id: \"increment\",\n  inputSchema: z.object({\n    // Previous value from last iteration\n    prevValue: z.number().optional(),\n  }),\n  outputSchema: z.object({\n    // Updated counter value\n    updatedCounter: z.number(),\n  }),\n  execute: async ({ context }) => {\n    const { prevValue = 0 } = context.inputData;\n    return { updatedCounter: prevValue + 1 };\n  },\n});\n\nconst workflow = new LegacyWorkflow({\n  name: \"counter\",\n});\n\nworkflow.step(incrementStep).while(\n  async ({ context }) => {\n    // Continue while counter is less than 10\n    const result = context.getStepResult(incrementStep);\n    return (result?.updatedCounter ?? 0) < 10;\n  },\n  incrementStep,\n  {\n    // Pass previous value to next iteration\n    prevValue: {\n      step: incrementStep,\n      path: \"updatedCounter\",\n    },\n  },\n);\n```\n\n## Variable Resolution\n\nWhen a workflow executes, Mastra resolves variables at runtime by:\n\n1. Identifying the source step specified in the `step` property\n2. Retrieving the output from that step\n3. Navigating to the specified property using the `path`\n4. Injecting the resolved value into the target step's context as the `inputData` property\n\n## Examples\n\n### Mapping from Trigger Data\n\nThis example shows how to map data from the workflow trigger to a step:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/trigger-mapping.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define a step that needs user input\nconst processUserInput = new LegacyStep({\n  id: \"processUserInput\",\n  execute: async ({ context }) => {\n    // The inputData will be available in context because of the variable mapping\n    const { inputData } = context.inputData;\n\n    return {\n      processedData: `Processed: ${inputData}`,\n    };\n  },\n});\n\n// Create the workflow\nconst workflow = new LegacyWorkflow({\n  name: \"trigger-mapping\",\n  triggerSchema: z.object({\n    inputData: z.string(),\n  }),\n});\n\n// Map the trigger data to the step\nworkflow\n  .step(processUserInput, {\n    variables: {\n      inputData: { step: \"trigger\", path: \"inputData\" },\n    },\n  })\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { workflow },\n});\n```\n\n### Mapping Between Steps\n\nThis example demonstrates mapping data from one step to another:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/step-mapping.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Step 1: Generate data\nconst generateData = new LegacyStep({\n  id: \"generateData\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async () => {\n    return {\n      nested: {\n        value: \"step1-data\",\n      },\n    };\n  },\n});\n\n// Step 2: Process the data from step 1\nconst processData = new LegacyStep({\n  id: \"processData\",\n  inputSchema: z.object({\n    previousValue: z.string(),\n  }),\n  execute: async ({ context }) => {\n    // previousValue will be available because of the variable mapping\n    const { previousValue } = context.inputData;\n\n    return {\n      result: `Processed: ${previousValue}`,\n    };\n  },\n});\n\n// Create the workflow\nconst workflow = new LegacyWorkflow({\n  name: \"step-mapping\",\n});\n\n// Map data from step1 to step2\nworkflow\n  .step(generateData)\n  .then(processData, {\n    variables: {\n      // Map the nested.value property from generateData's output\n      previousValue: { step: generateData, path: \"nested.value\" },\n    },\n  })\n  .commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { workflow },\n});\n```\n\n## Type Safety\n\nMastra provides type safety for variable mappings when using TypeScript:\n\n```typescript showLineNumbers filename=\"src/mastra/workflows/type-safe.ts\" copy\nimport { Mastra } from \"@mastra/core\";\nimport { LegacyStep, LegacyWorkflow } from \"@mastra/core/workflows/legacy\";\nimport { z } from \"zod\";\n\n// Define schemas for better type safety\nconst triggerSchema = z.object({\n  inputValue: z.string(),\n});\n\ntype TriggerType = z.infer<typeof triggerSchema>;\n\n// Step with typed context\nconst step1 = new LegacyStep({\n  id: \"step1\",\n  outputSchema: z.object({\n    nested: z.object({\n      value: z.string(),\n    }),\n  }),\n  execute: async ({ context }) => {\n    // TypeScript knows the shape of triggerData\n    const triggerData = context.getStepResult<TriggerType>(\"trigger\");\n\n    return {\n      nested: {\n        value: `processed-${triggerData?.inputValue}`,\n      },\n    };\n  },\n});\n\n// Create the workflow with the schema\nconst workflow = new LegacyWorkflow({\n  name: \"type-safe-workflow\",\n  triggerSchema,\n});\n\nworkflow.step(step1).commit();\n\n// Register the workflow with Mastra\nexport const mastra = new Mastra({\n  legacy_workflows: { workflow },\n});\n```\n\n## Best Practices\n\n1. **Validate Inputs and Outputs**: Use `inputSchema` and `outputSchema` to ensure data consistency.\n\n2. **Keep Mappings Simple**: Avoid overly complex nested paths when possible.\n\n3. **Consider Default Values**: Handle cases where mapped data might be undefined.\n\n## Comparison with Direct Context Access\n\nWhile you can access previous step results directly via `context.steps`, using variable mappings offers several advantages:\n\n| Feature     | Variable Mapping                            | Direct Context Access           |\n| ----------- | ------------------------------------------- | ------------------------------- |\n| Clarity     | Explicit data dependencies                  | Implicit dependencies           |\n| Reusability | Steps can be reused with different mappings | Steps are tightly coupled       |\n| Type Safety | Better TypeScript integration               | Requires manual type assertions |\n\n\n---\ntitle: \"Example: Categorizing Birds | Agents | Mastra Docs\"\ndescription: Example of using a Mastra AI Agent to determine if an image from Unsplash depicts a bird.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Example: Categorizing Birds with an AI Agent\n[EN] Source: https://mastra.ai/en/examples/agents/bird-checker\n\nWe will get a random image from [Unsplash](https://unsplash.com/) that matches a selected query and uses a [Mastra AI Agent](/docs/agents/overview.md) to determine if it is a bird or not.\n\n```ts showLineNumbers copy\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { z } from \"zod\";\n\nexport type Image = {\n  alt_description: string;\n  urls: {\n    regular: string;\n    raw: string;\n  };\n  user: {\n    first_name: string;\n    links: {\n      html: string;\n    };\n  };\n};\n\nexport type ImageResponse<T, K> =\n  | {\n      ok: true;\n      data: T;\n    }\n  | {\n      ok: false;\n      error: K;\n    };\n\nconst getRandomImage = async ({\n  query,\n}: {\n  query: string;\n}): Promise<ImageResponse<Image, string>> => {\n  const page = Math.floor(Math.random() * 20);\n  const order_by = Math.random() < 0.5 ? \"relevant\" : \"latest\";\n  try {\n    const res = await fetch(\n      `https://api.unsplash.com/search/photos?query=${query}&page=${page}&order_by=${order_by}`,\n      {\n        method: \"GET\",\n        headers: {\n          Authorization: `Client-ID ${process.env.UNSPLASH_ACCESS_KEY}`,\n          \"Accept-Version\": \"v1\",\n        },\n        cache: \"no-store\",\n      },\n    );\n\n    if (!res.ok) {\n      return {\n        ok: false,\n        error: \"Failed to fetch image\",\n      };\n    }\n\n    const data = (await res.json()) as {\n      results: Array<Image>;\n    };\n    const randomNo = Math.floor(Math.random() * data.results.length);\n\n    return {\n      ok: true,\n      data: data.results[randomNo] as Image,\n    };\n  } catch (err) {\n    return {\n      ok: false,\n      error: \"Error fetching image\",\n    };\n  }\n};\n\nconst instructions = `\n  You can view an image and figure out if it is a bird or not. \n  You can also figure out the species of the bird and where the picture was taken.\n`;\n\nexport const birdCheckerAgent = new Agent({\n  name: \"Bird checker\",\n  instructions,\n  model: anthropic(\"claude-3-haiku-20240307\"),\n});\n\nconst queries: string[] = [\"wildlife\", \"feathers\", \"flying\", \"birds\"];\nconst randomQuery = queries[Math.floor(Math.random() * queries.length)];\n\n// Get the image url from Unsplash with random type\nconst imageResponse = await getRandomImage({ query: randomQuery });\n\nif (!imageResponse.ok) {\n  console.log(\"Error fetching image\", imageResponse.error);\n  process.exit(1);\n}\n\nconsole.log(\"Image URL: \", imageResponse.data.urls.regular);\nconst response = await birdCheckerAgent.generate(\n  [\n    {\n      role: \"user\",\n      content: [\n        {\n          type: \"image\",\n          image: new URL(imageResponse.data.urls.regular),\n        },\n        {\n          type: \"text\",\n          text: \"view this image and let me know if it's a bird or not, and the scientific name of the bird without any explanation. Also summarize the location for this picture in one or two short sentences understandable by a high school student\",\n        },\n      ],\n    },\n  ],\n  {\n    output: z.object({\n      bird: z.boolean(),\n      species: z.string(),\n      location: z.string(),\n    }),\n  },\n);\n\nconsole.log(response.object);\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/bird-checker\"\n  }\n/>\n\n\n---\ntitle: \"Example: Deploying an MCPServer | Agents | Mastra Docs\"\ndescription: Example of setting up, building, and deploying a Mastra MCPServer using the stdio transport and publishing it to NPM.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Example: Deploying an MCPServer\n[EN] Source: https://mastra.ai/en/examples/agents/deploying-mcp-server\n\nThis example guides you through setting up a basic Mastra MCPServer using the stdio transport, building it, and preparing it for deployment, such as publishing to NPM.\n\n## Install Dependencies\n\nInstall the necessary packages:\n\n```bash\npnpm add @mastra/mcp @mastra/core tsup\n```\n\n## Set up MCP Server\n\n1.  Create a file for your stdio server, for example, `/src/mastra/stdio.ts`.\n\n2.  Add the following code to the file. Remember to import your actual Mastra tools and name the server appropriately.\n\n    ```typescript filename=\"src/mastra/stdio.ts\" copy\n    #!/usr/bin/env node\n    import { MCPServer } from \"@mastra/mcp\";\n    import { weatherTool } from \"./tools\";\n\n    const server = new MCPServer({\n      name: \"my-mcp-server\",\n      version: \"1.0.0\",\n      tools: { weatherTool },\n    });\n\n    server.startStdio().catch((error) => {\n      console.error(\"Error running MCP server:\", error);\n      process.exit(1);\n    });\n    ```\n\n3.  Update your `package.json` to include the `bin` entry pointing to your built server file and a script to build the server.\n\n```json filename=\"package.json\" copy\n{\n  \"bin\": \"dist/stdio.js\",\n  \"scripts\": {\n    \"build:mcp\": \"tsup src/mastra/stdio.ts --format esm --no-splitting --dts && chmod +x dist/stdio.js\"\n  }\n}\n```\n\n4.  Run the build command:\n\n    ```bash\n    pnpm run build:mcp\n    ```\n\n    This will compile your server code and make the output file executable.\n\n## Deploying to NPM\n\nTo make your MCP server available for others (or yourself) to use via `npx` or as a dependency, you can publish it to NPM.\n\n1.  Ensure you have an NPM account and are logged in (`npm login`).\n2.  Make sure your package name in `package.json` is unique and available.\n3.  Run the publish command from your project root after building:\n\n    ```bash\n    npm publish --access public\n    ```\n\n    For more details on publishing packages, refer to the [NPM documentation](https://docs.npmjs.com/creating-and-publishing-scoped-public-packages).\n\n## Use the Deployed MCP Server\n\nOnce published, your MCP server can be used by an `MCPClient` by specifying the command to run your package. You can also use any other MCP client like Claude desktop, Cursor, or Windsurf.\n\n```typescript\nimport { MCPClient } from \"@mastra/mcp\";\n\nconst mcp = new MCPClient({\n  servers: {\n    // Give this MCP server instance a name\n    yourServerName: {\n      command: \"npx\",\n      args: [\"-y\", \"@your-org-name/your-package-name@latest\"], // Replace with your package name\n    },\n  },\n});\n\n// You can then get tools or toolsets from this configuration to use in your agent\nconst tools = await mcp.getTools();\nconst toolsets = await mcp.getToolsets();\n```\n\nNote: If you published without an organization scope, the `args` might just be `[\"-y\", \"your-package-name@latest\"]`.\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n\n---\ntitle: Dynamic Agents Example | Agents | Mastra Docs\ndescription: Learn how to create and configure dynamic agents using runtime context in Mastra.\n---\n\n# Dynamic Agents Example\n[EN] Source: https://mastra.ai/en/examples/agents/dynamic-agents\n\nFirst, let's define our runtime context type:\n\n```typescript\nimport { Agent, RuntimeContext } from \"@mastra/core\";\nimport { z } from \"zod\";\n\ntype SupportRuntimeContext = {\n  \"user-tier\": \"free\" | \"pro\" | \"enterprise\";\n  language: \"en\" | \"es\" | \"fr\";\n  \"user-id\": string;\n};\n```\n\nNext, let's create our dynamic support agent with its configuration:\n\n```typescript\nconst supportAgent = new Agent({\n  name: \"Dynamic Support Agent\",\n\n  instructions: async ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    const language = runtimeContext.get(\"language\");\n\n    return `You are a customer support agent for our SaaS platform.\n    The current user is on the ${userTier} tier and prefers ${language} language.\n    \n    For ${userTier} tier users:\n    ${userTier === \"free\" ? \"- Provide basic support and documentation links\" : \"\"}\n    ${userTier === \"pro\" ? \"- Offer detailed technical support and best practices\" : \"\"}\n    ${userTier === \"enterprise\" ? \"- Provide priority support with custom solutions\" : \"\"}\n    \n    Always respond in ${language} language.`;\n  },\n\n  model: ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    return userTier === \"enterprise\"\n      ? openai(\"gpt-4\")\n      : openai(\"gpt-3.5-turbo\");\n  },\n\n  tools: ({ runtimeContext }) => {\n    const userTier = runtimeContext.get(\"user-tier\");\n    const baseTools = [knowledgeBase, ticketSystem];\n\n    if (userTier === \"pro\" || userTier === \"enterprise\") {\n      baseTools.push(advancedAnalytics);\n    }\n\n    if (userTier === \"enterprise\") {\n      baseTools.push(customIntegration);\n    }\n\n    return baseTools;\n  },\n});\n```\n\nRuntimeContext can be passed from the client/server directly to your agent generate and stream calls\n\n```typescript\nasync function handleSupportRequest(userId: string, message: string) {\n  const runtimeContext = new RuntimeContext<SupportRuntimeContext>();\n\n  runtimeContext.set(\"user-id\", userId);\n  runtimeContext.set(\"user-tier\", await getUserTier(userId));\n  runtimeContext.set(\"language\", await getUserLanguage(userId));\n\n  const response = await supportAgent.generate(message, {\n    runtimeContext,\n  });\n\n  return response.text;\n}\n```\n\nRuntimeContext can also be set from the server middleware layer\n\n```typescript\nimport { Mastra } from \"@mastra/core\";\nimport { registerApiRoute } from \"@mastra/core/server\";\n\nexport const mastra = new Mastra({\n  agents: {\n    support: supportAgent,\n  },\n  server: {\n    middleware: [\n      async (c, next) => {\n        const userId = c.req.header(\"X-User-ID\");\n        const runtimeContext = c.get<SupportRuntimeContext>(\"runtimeContext\");\n\n        // Set user tier based on subscription\n        const userTier = await getUserTier(userId);\n        runtimeContext.set(\"user-tier\", userTier);\n\n        // Set language based on user preferences\n        const language = await getUserLanguage(userId);\n        runtimeContext.set(\"language\", language);\n\n        // Set user ID\n        runtimeContext.set(\"user-id\", userId);\n\n        await next();\n      },\n    ],\n    apiRoutes: [\n      registerApiRoute(\"/support\", {\n        method: \"POST\",\n        handler: async (c) => {\n          const { userId, message } = await c.req.json();\n\n          try {\n            const response = await handleSupportRequest(userId, message);\n            return c.json({ response });\n          } catch (error) {\n            return c.json({ error: \"Failed to process support request\" }, 500);\n          }\n        },\n      }),\n    ],\n  },\n});\n```\n\n## Usage Example\n\nThis example shows how a single agent can handle different types of users and scenarios by leveraging runtime context, making it more flexible and maintainable than creating separate agents for each use case.\n\n\n---\ntitle: \"Example: Hierarchical Multi-Agent System | Agents | Mastra\"\ndescription: Example of creating a hierarchical multi-agent system using Mastra, where agents interact through tool functions.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Hierarchical Multi-Agent System\n[EN] Source: https://mastra.ai/en/examples/agents/hierarchical-multi-agent\n\nThis example demonstrates how to create a hierarchical multi-agent system where agents interact through tool functions, with one agent coordinating the work of others.\n\nThe system consists of three agents:\n\n1. A Publisher agent (supervisor) that orchestrates the process\n2. A Copywriter agent that writes the initial content\n3. An Editor agent that refines the content\n\nFirst, define the Copywriter agent and its tool:\n\n```ts showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\n\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n\nconst copywriterTool = createTool({\n  id: \"copywriter-agent\",\n  description: \"Calls the copywriter agent to write blog post copy.\",\n  inputSchema: z.object({\n    topic: z.string().describe(\"Blog post topic\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"Blog post copy\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${context.topic}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\nNext, define the Editor agent and its tool:\n\n```ts showLineNumbers copy\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n\nconst editorTool = createTool({\n  id: \"editor-agent\",\n  description: \"Calls the editor agent to edit blog post copy.\",\n  inputSchema: z.object({\n    copy: z.string().describe(\"Blog post copy\"),\n  }),\n  outputSchema: z.object({\n    copy: z.string().describe(\"Edited blog post copy\"),\n  }),\n  execute: async ({ context }) => {\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${context.copy}`,\n    );\n    return { copy: result.text };\n  },\n});\n```\n\nFinally, create the Publisher agent that coordinates the others:\n\n```ts showLineNumbers copy\nconst publisherAgent = new Agent({\n  name: \"publisherAgent\",\n  instructions:\n    \"You are a publisher agent that first calls the copywriter agent to write blog post copy about a specific topic and then calls the editor agent to edit the copy. Just return the final edited copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n  tools: { copywriterTool, editorTool },\n});\n\nconst mastra = new Mastra({\n  agents: { publisherAgent },\n});\n```\n\nTo use the entire system:\n\n```ts showLineNumbers copy\nasync function main() {\n  const agent = mastra.getAgent(\"publisherAgent\");\n  const result = await agent.generate(\n    \"Write a blog post about React JavaScript frameworks. Only return the final edited copy.\",\n  );\n  console.log(result.text);\n}\n\nmain();\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/hierarchical-multi-agent\"\n  }\n/>\n\n\n---\ntitle: \"Example: Multi-Agent Workflow | Agents | Mastra Docs\"\ndescription: Example of creating an agentic workflow in Mastra, where work product is passed between multiple agents.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Multi-Agent Workflow\n[EN] Source: https://mastra.ai/en/examples/agents/multi-agent-workflow\n\nThis example demonstrates how to create an agentic workflow with work product being passed between multiple agents with a worker agent and a supervisor agent.\n\nIn this example, we create a sequential workflow that calls two agents in order:\n\n1. A Copywriter agent that writes the initial blog post\n2. An Editor agent that refines the content\n\nFirst, import the required dependencies:\n\n```typescript\nimport { openai } from \"@ai-sdk/openai\";\nimport { anthropic } from \"@ai-sdk/anthropic\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createStep, createWorkflow } from \"@mastra/core/workflows\";\nimport { z } from \"zod\";\n```\n\nCreate the copywriter agent that will generate the initial blog post:\n\n```typescript\nconst copywriterAgent = new Agent({\n  name: \"Copywriter\",\n  instructions: \"You are a copywriter agent that writes blog post copy.\",\n  model: anthropic(\"claude-3-5-sonnet-20241022\"),\n});\n```\n\nDefine the copywriter step that executes the agent and handles the response:\n\n```typescript\nconst copywriterStep = createStep({\n  id: \"copywriterStep\",\n  inputSchema: z.object({\n    topic: z.string(),\n  }),\n  outputSchema: z.object({\n    copy: z.string(),\n  }),\n  execute: async ({ inputData }) => {\n    if (!inputData?.topic) {\n      throw new Error(\"Topic not found in trigger data\");\n    }\n    const result = await copywriterAgent.generate(\n      `Create a blog post about ${inputData.topic}`,\n    );\n    console.log(\"copywriter result\", result.text);\n    return {\n      copy: result.text,\n    };\n  },\n});\n```\n\nSet up the editor agent to refine the copywriter's content:\n\n```typescript\nconst editorAgent = new Agent({\n  name: \"Editor\",\n  instructions: \"You are an editor agent that edits blog post copy.\",\n  model: openai(\"gpt-4o-mini\"),\n});\n```\n\nCreate the editor step that processes the copywriter's output:\n\n```typescript\nconst editorStep = createStep({\n  id: \"editorStep\",\n  inputSchema: z.object({\n    copy: z.string(),\n  }),\n  outputSchema: z.object({\n    finalCopy: z.string(),\n  }),\n  execute: async ({ inputData }) => {\n    const copy = inputData?.copy;\n\n    const result = await editorAgent.generate(\n      `Edit the following blog post only returning the edited copy: ${copy}`,\n    );\n    console.log(\"editor result\", result.text);\n    return {\n      finalCopy: result.text,\n    };\n  },\n});\n```\n\nConfigure the workflow and execute the steps:\n\n```typescript\nconst myWorkflow = createWorkflow({\n  id: \"my-workflow\",\n  inputSchema: z.object({\n    topic: z.string(),\n  }),\n  outputSchema: z.object({\n    finalCopy: z.string(),\n  }),\n});\n\n// Run steps sequentially.\nmyWorkflow.then(copywriterStep).then(editorStep).commit();\n\nconst run = await myWorkflow.createRunAsync();\n\nconst res = await run.start({\n  inputData: { topic: \"React JavaScript frameworks\" },\n});\nconsole.log(\"Response: \", res);\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/multi-agent-workflow\"\n  }\n/>\n\n\n---\ntitle: \"Example: Agents with a System Prompt | Agents | Mastra Docs\"\ndescription: Example of creating an AI agent in Mastra with a system prompt to define its personality and capabilities.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Giving an Agent a System Prompt\n[EN] Source: https://mastra.ai/en/examples/agents/system-prompt\n\nWhen building AI agents, you often need to give them specific instructions and capabilities to handle specialized tasks effectively. System prompts allow you to define an agent's personality, knowledge domain, and behavioral guidelines. This example shows how to create an AI agent with custom instructions and integrate it with a dedicated tool for retrieving verified information.\n\n```ts showLineNumbers copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\n\nimport { z } from \"zod\";\n\nconst instructions = `You are a helpful cat expert assistant. When discussing cats, you should always include an interesting cat fact.\n\n  Your main responsibilities:\n  1. Answer questions about cats\n  2. Use the catFact tool to provide verified cat facts\n  3. Incorporate the cat facts naturally into your responses\n\n  Always use the catFact tool at least once in your responses to ensure accuracy.`;\n\nconst getCatFact = async () => {\n  const { fact } = (await fetch(\"https://catfact.ninja/fact\").then((res) =>\n    res.json(),\n  )) as {\n    fact: string;\n  };\n\n  return fact;\n};\n\nconst catFact = createTool({\n  id: \"Get cat facts\",\n  inputSchema: z.object({}),\n  description: \"Fetches cat facts\",\n  execute: async () => {\n    console.log(\"using tool to fetch cat fact\");\n    return {\n      catFact: await getCatFact(),\n    };\n  },\n});\n\nconst catOne = new Agent({\n  name: \"cat-one\",\n  instructions: instructions,\n  model: openai(\"gpt-4o-mini\"),\n  tools: {\n    catFact,\n  },\n});\n\nconst result = await catOne.generate(\"Tell me a cat fact\");\n\nconsole.log(result.text);\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/system-prompt\"\n  }\n/>\n\n\n---\ntitle: \"Example: Giving an Agent a Tool | Agents | Mastra Docs\"\ndescription: Example of creating an AI agent in Mastra that uses a dedicated tool to provide weather information.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Example: Giving an Agent a Tool\n[EN] Source: https://mastra.ai/en/examples/agents/using-a-tool\n\nWhen building AI agents, you often need to integrate external data sources or functionality to enhance their capabilities. This example shows how to create an AI agent that uses a dedicated weather tool to provide accurate weather information for specific locations.\n\n```ts showLineNumbers copy\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createTool } from \"@mastra/core/tools\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { z } from \"zod\";\n\ninterface WeatherResponse {\n  current: {\n    time: string;\n    temperature_2m: number;\n    apparent_temperature: number;\n    relative_humidity_2m: number;\n    wind_speed_10m: number;\n    wind_gusts_10m: number;\n    weather_code: number;\n  };\n}\n\nconst weatherTool = createTool({\n  id: \"get-weather\",\n  description: \"Get current weather for a location\",\n  inputSchema: z.object({\n    location: z.string().describe(\"City name\"),\n  }),\n  outputSchema: z.object({\n    temperature: z.number(),\n    feelsLike: z.number(),\n    humidity: z.number(),\n    windSpeed: z.number(),\n    windGust: z.number(),\n    conditions: z.string(),\n    location: z.string(),\n  }),\n  execute: async ({ context }) => {\n    return await getWeather(context.location);\n  },\n});\n\nconst getWeather = async (location: string) => {\n  const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(location)}&count=1`;\n  const geocodingResponse = await fetch(geocodingUrl);\n  const geocodingData = await geocodingResponse.json();\n\n  if (!geocodingData.results?.[0]) {\n    throw new Error(`Location '${location}' not found`);\n  }\n\n  const { latitude, longitude, name } = geocodingData.results[0];\n\n  const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,apparent_temperature,relative_humidity_2m,wind_speed_10m,wind_gusts_10m,weather_code`;\n\n  const response = await fetch(weatherUrl);\n  const data: WeatherResponse = await response.json();\n\n  return {\n    temperature: data.current.temperature_2m,\n    feelsLike: data.current.apparent_temperature,\n    humidity: data.current.relative_humidity_2m,\n    windSpeed: data.current.wind_speed_10m,\n    windGust: data.current.wind_gusts_10m,\n    conditions: getWeatherCondition(data.current.weather_code),\n    location: name,\n  };\n};\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: \"Clear sky\",\n    1: \"Mainly clear\",\n    2: \"Partly cloudy\",\n    3: \"Overcast\",\n    45: \"Foggy\",\n    48: \"Depositing rime fog\",\n    51: \"Light drizzle\",\n    53: \"Moderate drizzle\",\n    55: \"Dense drizzle\",\n    56: \"Light freezing drizzle\",\n    57: \"Dense freezing drizzle\",\n    61: \"Slight rain\",\n    63: \"Moderate rain\",\n    65: \"Heavy rain\",\n    66: \"Light freezing rain\",\n    67: \"Heavy freezing rain\",\n    71: \"Slight snow fall\",\n    73: \"Moderate snow fall\",\n    75: \"Heavy snow fall\",\n    77: \"Snow grains\",\n    80: \"Slight rain showers\",\n    81: \"Moderate rain showers\",\n    82: \"Violent rain showers\",\n    85: \"Slight snow showers\",\n    86: \"Heavy snow showers\",\n    95: \"Thunderstorm\",\n    96: \"Thunderstorm with slight hail\",\n    99: \"Thunderstorm with heavy hail\",\n  };\n  return conditions[code] || \"Unknown\";\n}\n\nconst weatherAgent = new Agent({\n  name: \"Weather Agent\",\n  instructions: `You are a helpful weather assistant that provides accurate weather information.\nYour primary function is to help users get weather details for specific locations. When responding:\n- Always ask for a location if none is provided\n- If the location name isnâ€™t in English, please translate it\n- Include relevant details like humidity, wind conditions, and precipitation\n- Keep responses concise but informative\nUse the weatherTool to fetch current weather data.`,\n  model: openai(\"gpt-4o-mini\"),\n  tools: { weatherTool },\n});\n\nconst mastra = new Mastra({\n  agents: { weatherAgent },\n});\n\nasync function main() {\n  const agent = await mastra.getAgent(\"weatherAgent\");\n  const result = await agent.generate(\"What is the weather in London?\");\n  console.log(result.text);\n}\n\nmain();\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/using-a-tool\"\n  }\n/>\n\n\n---\ntitle: \"Example: Workflow as Tools | Agents | Mastra Docs\"\ndescription: Example of creating Agents in Mastra, demonstrating how to use workflows as tools. It shows how to suspend and resume workflows from an agent.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Workflow as Tools\n[EN] Source: https://mastra.ai/en/examples/agents/workflow-as-tools\n\nWhen building AI applications, you often need to coordinate multiple steps that depend on each other's outputs. This example shows how to create an AI workflow that fetches weather data from a workflow. It also demonstrates how to handle suspend and resume of workflows from an agent.\n\n### Workflow Definition\n\n```ts showLineNumbers copy\nimport { Mastra } from \"@mastra/core\";\nimport { Agent } from \"@mastra/core/agent\";\nimport { createStep, createWorkflow } from \"@mastra/core/workflows\";\nimport { createTool } from '@mastra/core/tools';\nimport { z } from \"zod\";\nimport { openai } from \"@ai-sdk/openai\";\n\nconst forecastSchema = z.object({\n  date: z.string(),\n  maxTemp: z.number(),\n  minTemp: z.number(),\n  precipitationChance: z.number(),\n  condition: z.string(),\n  location: z.string(),\n});\n\nfunction getWeatherCondition(code: number): string {\n  const conditions: Record<number, string> = {\n    0: 'Clear sky',\n    1: 'Mainly clear',\n    2: 'Partly cloudy',\n    3: 'Overcast',\n    45: 'Foggy',\n    48: 'Depositing rime fog',\n    51: 'Light drizzle',\n    53: 'Moderate drizzle',\n    55: 'Dense drizzle',\n    61: 'Slight rain',\n    63: 'Moderate rain',\n    65: 'Heavy rain',\n    71: 'Slight snow fall',\n    73: 'Moderate snow fall',\n    75: 'Heavy snow fall',\n    95: 'Thunderstorm',\n  };\n  return conditions[code] || 'Unknown';\n}\n\nconst fetchWeatherWithSuspend = createStep({\n  id: 'fetch-weather',\n  description: 'Fetches weather forecast for a given city',\n  inputSchema: z.object({}),\n  resumeSchema: z.object({\n    city: z.string().describe('The city to get the weather for'),\n  }),\n  outputSchema: forecastSchema,\n  execute: async ({ resumeData, suspend }) => {\n    if (!resumeData) {\n      suspend({\n        message: 'Please enter the city to get the weather for',\n      });\n\n      return {};\n    }\n\n    const geocodingUrl = `https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(resumeData.city)}&count=1`;\n    const geocodingResponse = await fetch(geocodingUrl);\n    const geocodingData = (await geocodingResponse.json()) as {\n      results: { latitude: number; longitude: number; name: string }[];\n    };\n\n    if (!geocodingData.results?.[0]) {\n      throw new Error(`Location '${resumeData.city}' not found`);\n    }\n\n    const { latitude, longitude, name } = geocodingData.results[0];\n\n    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=precipitation,weathercode&timezone=auto,&hourly=precipitation_probability,temperature_2m`;\n    const response = await fetch(weatherUrl);\n    const data = (await response.json()) as {\n      current: {\n        time: string;\n        precipitation: number;\n        weathercode: number;\n      };\n      hourly: {\n        precipitation_probability: number[];\n        temperature_2m: number[];\n      };\n    };\n\n    const forecast = {\n      date: new Date().toISOString(),\n      maxTemp: Math.max(...data.hourly.temperature_2m),\n      minTemp: Math.min(...data.hourly.temperature_2m),\n      condition: getWeatherCondition(data.current.weathercode),\n      precipitationChance: data.hourly.precipitation_probability.reduce((acc, curr) => Math.max(acc, curr), 0),\n      location: resumeData.city,\n    };\n\n    return forecast;\n  },\n});\n\nconst weatherWorkflowWithSuspend = createWorkflow({\n  id: 'weather-workflow-with-suspend',\n  inputSchema: z.object({}),\n  outputSchema: forecastSchema,\n})\n  .then(fetchWeatherWithSuspend)\n  .commit();\n```\n\n### Tool Definitions\n\n```ts\nexport const startWeatherTool = createTool({\n  id: 'start-weather-tool',\n  description: 'Start the weather tool',\n  inputSchema: z.object({}),\n  outputSchema: z.object({\n    runId: z.string(),\n  }),\n  execute: async ({ context }) => {\n    const workflow = mastra.getWorkflow('weatherWorkflowWithSuspend');\n    const run = await workflow.createRunAsync();\n    await run.start({\n      inputData: {},\n    });\n\n    return {\n      runId: run.runId,\n    };\n  },\n});\n\nexport const resumeWeatherTool = createTool({\n  id: 'resume-weather-tool',\n  description: 'Resume the weather tool',\n  inputSchema: z.object({\n    runId: z.string(),\n    city: z.string().describe('City name'),\n  }),\n  outputSchema: forecastSchema,\n  execute: async ({ context }) => {\n    const workflow = mastra.getWorkflow('weatherWorkflowWithSuspend');\n    const run = await workflow.createRunAsync({\n      runId: context.runId,\n    });\n    const result = await run.resume({\n      step: 'fetch-weather',\n      resumeData: {\n        city: context.city,\n      },\n    });\n    return result.result;\n  },\n});\n```\n\n### Agent Definition\n\n```ts\nexport const weatherAgentWithWorkflow = new Agent({\n  name: 'Weather Agent with Workflow',\n  instructions: `You are a helpful weather assistant that provides accurate weather information.\n\nYour primary function is to help users get weather details for specific locations. When responding:\n- Always ask for a location if none is provided\n- If the location name isnâ€™t in English, please translate it\n- If giving a location with multiple parts (e.g. \"New York, NY\"), use the most relevant part (e.g. \"New York\")\n- Include relevant details like humidity, wind conditions, and precipitation\n- Keep responses concise but informative\n\nUse the startWeatherTool to start the weather workflow. This will start and then suspend the workflow and return a runId.\nUse the resumeWeatherTool to resume the weather workflow. This takes the runId returned from the startWeatherTool and the city entered by the user. It will resume the workflow and return the result.\nThe result will be the weather forecast for the city.`,\n  model: openai('gpt-4o'),\n  tools: { startWeatherTool, resumeWeatherTool },\n});\n```\n\n### Agent Execution\n```ts\nconst mastra = new Mastra({\n  agents: { weatherAgentWithWorkflow },\n  workflows: { weatherWorkflowWithSuspend },\n});\n\nconst agent = mastra.getAgent('weatherAgentWithWorkflow');\nconst result = await agent.generate([\n  {\n    role: 'user',\n    content: 'London',\n  },\n]);\n\nconsole.log(result);\n```\n\n<br/>\n\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/agents/workflow-as-tools\"\n  }\n/>\n\n\n---\ntitle: Deployment examples\n---\n\n# Deployment examples\n[EN] Source: https://mastra.ai/en/examples/deployment\n\nA few ways to extend your Mastra server during deployment. Each example assumes\n`Mastra` has already been initialised and focuses on server specific code.\n\n\n---\ntitle: \"Examples List: Workflows, Agents, RAG | Mastra Docs\"\ndescription: \"Explore practical examples of AI development with Mastra, including text generation, RAG implementations, structured outputs, and multi-modal interactions. Learn how to build AI applications using OpenAI, Anthropic, and Google Gemini.\"\n---\n\nimport { CardItems } from \"@/components/cards/card-items\";\nimport { Tabs } from \"nextra/components\";\n\n# Examples\n[EN] Source: https://mastra.ai/en/examples\n\nThe Examples section is a short list of example projects demonstrating basic AI engineering with Mastra, including text generation, structured output, streaming responses, retrievalâ€augmented generation (RAG), and voice.\n\n<CardItems titles={[\"Agent\", \"Workflow\", \"legacyWorkflow\", \"Memory\", \"RAG\", \"Evals\", \"Voice\"]} items={\n  {\n    Agent: [\n      {\n        title: \"Agent with System Prompt\",\n        href: \"/examples/agents/system-prompt\",\n      },\n      {\n        title: \"Workflow as Tools\",\n        href: \"/examples/agents/workflow-as-tools\",\n      },\n      {\n        title: \"Using a Tool\",\n        href: \"/examples/agents/using-a-tool\",\n      },\n      {\n        title: \"Hierarchical Multi-Agent System\",\n        href: \"/examples/agents/hierarchical-multi-agent\",\n      },\n      {\n        title: \"Multi-Agent Workflow\",\n        href: \"/examples/agents/multi-agent-workflow\",\n      },\n      {\n        title: \"Bird Checker\",\n        href: \"/examples/agents/bird-checker\",\n      },\n      {\n        title: \"Dynamic Agents\",\n        href: \"/examples/agents/dynamic-agents\"\n      }\n    ],\n    Workflow: [\n      {\n        title: \"Conditional Branching\",\n        href: \"/examples/workflows/conditional-branching\",\n      },\n      {\n        title: \"Parallel Steps\",\n        href: \"/examples/workflows/parallel-steps\",\n      },\n      {\n        title: \"Calling an Agent\",\n        href: \"/examples/workflows/calling-agent\",\n      },\n      {\n        title: \"Tool & Agent as a Step\",\n        href: \"/examples/workflows/agent-and-tool-interop\",\n      },\n      {\n        title: \"Human in the loop\",\n        href: \"/examples/workflows/human-in-the-loop\",\n      },\n      {\n        title: \"Control Flow\",\n        href: \"/examples/workflows/control-flow\",\n      },\n      {\n        title: \"Array as Input\",\n        href: \"/examples/workflows/array-as-input\",\n      }\n    ],\n    legacyWorkflow: [\n      {\n        title: \"Creating a Workflow\",\n        href: \"/examples/workflows_legacy/creating-a-workflow\",\n      },\n      {\n        title: \"Using a Tool as a Step\",\n        href: \"/examples/workflows_legacy/using-a-tool-as-a-step\",\n      },\n      { title: \"Parallel Steps\", href: \"/examples/workflows_legacy/parallel-steps\" },\n      {\n        title: \"Sequential Steps\",\n        href: \"/examples/workflows_legacy/sequential-steps\",\n      },\n      { title: \"Branching Paths\", href: \"/examples/workflows_legacy/branching-paths\" },\n      {\n        title: \"Cyclical Dependencies\",\n        href: \"/examples/workflows_legacy/cyclical-dependencies\",\n      },\n      {\n        title: \"Suspend and Resume\",\n        href: \"/examples/workflows_legacy/suspend-and-resume\",\n      },\n      { title: \"Calling an Agent\", href: \"/examples/workflows_legacy/calling-agent\" },\n    ],\n    Memory:[\n      {\n        title: \"Long-term Memory with LibSQL\",\n        href: \"/examples/memory/memory-with-libsql\",\n      },\n      {\n        title: \"Long-term Memory with Postgres\",\n        href: \"/examples/memory/memory-with-pg\",\n      },\n      {\n        title: \"Long-term Memory with Upstash\",\n        href: \"/examples/memory/memory-with-upstash\",\n      },\n      {\n        title: \"Long-term Memory with Mem0\",\n        href: \"/examples/memory/memory-with-mem0\"\n      },\n      {\n        title: \"Streaming Working Memory (quickstart)\",\n        href: \"/examples/memory/streaming-working-memory\",\n      },\n      {\n        title: \"Streaming Working Memory (advanced)\",\n        href: \"/examples/memory/streaming-working-memory-advanced\",\n      },\n    ],\n    RAG: [\n      { title: \"Chunk Text\", href: \"/examples/rag/chunking/chunk-text\" },\n      { title: \"Chunk Markdown\", href: \"/examples/rag/chunking/chunk-markdown\" },\n      { title: \"Chunk HTML\", href: \"/examples/rag/chunking/chunk-html\" },\n      { title: \"Chunk JSON\", href: \"/examples/rag/chunking/chunk-json\" },\n      { title: \"Embed Text Chunk\", href: \"/examples/rag/embedding/embed-text-chunk\" },\n      { title: \"Embed Chunk Array\", href: \"/examples/rag/embedding/embed-chunk-array\" },\n      { title: \"Adjust Chunk Size\", href: \"/examples/rag/chunking/adjust-chunk-size\" },\n      {\n        title: \"Adjust Chunk Delimiters\",\n        href: \"/examples/rag/chunking/adjust-chunk-delimiters\",\n      },\n      {\n        title: \"Metadata Extraction\",\n        href: \"/examples/rag/embedding/metadata-extraction\",\n      },\n      {\n        title: \"Hybrid Vector Search\",\n        href: \"/examples/rag/query/hybrid-vector-search\",\n      },\n      {\n        title: \"Embed Text with Cohere\",\n        href: \"/examples/rag/embedding/embed-text-with-cohere\",\n      },\n      {\n        title: \"Upsert Embeddings\",\n        href: \"/examples/rag/upsert/upsert-embeddings\",\n      },\n      { title: \"Retrieve Results\", href: \"/examples/rag/query/retrieve-results\" },\n      { title: \"Using the Vector Query Tool\", href: \"/examples/rag/usage/basic-rag\" },\n      {\n        title: \"Optimizing Information Density\",\n        href: \"/examples/rag/usage/cleanup-rag\",\n      },\n      { title: \"Metadata Filtering\", href: \"/examples/rag/usage/filter-rag\" },\n      {\n        title: \"Re-ranking Results\",\n        href: \"/examples/rag/rerank/rerank\",\n      },\n      {\n        title: \"Re-ranking Results with Tools\",\n        href: \"/examples/rag/rerank/rerank-rag\",\n      },\n      { title: \"Chain of Thought Prompting\", href: \"/examples/rag/usage/cot-rag\" },\n      {\n        title: \"Structured Reasoning with Workflows\",\n        href: \"/examples/rag/usage/cot-workflow-rag\",\n      },\n      { title: \"Graph RAG\", href: \"/examples/rag/usage/graph-rag\" },\n    ],\n    Evals: [\n      {\n        title: \"Answer Relevancy\",\n        href: \"/examples/evals/answer-relevancy\",\n      },\n      {\n        title: \"Bias\",\n        href: \"/examples/evals/bias\",\n      },\n      {\n        title: \"Completeness\",\n        href: \"/examples/evals/completeness\",\n      },\n      {\n        title: \"Content Similarity\",\n        href: \"/examples/evals/content-similarity\",\n      },\n      {\n        title: \"Context Position\",\n        href: \"/examples/evals/context-position\",\n      },\n      {\n        title: \"Context Precision\",\n        href: \"/examples/evals/context-precision\",\n      },\n      {\n        title: \"Context Relevancy\",\n        href: \"/examples/evals/context-relevancy\",\n      },\n      {\n        title: \"Contextual Recall\",\n        href: \"/examples/evals/contextual-recall\",\n      },\n      {\n        title: \"Custom Eval with LLM as a Judge\",\n        href: \"/examples/evals/custom-eval\",\n      },\n      {\n        title: \"Faithfulness\",\n        href: \"/examples/evals/faithfulness\",\n      },\n      {\n        title: \"Hallucination\",\n        href: \"/examples/evals/hallucination\",\n      },\n      {\n        title: \"Keyword Coverage\",\n        href: \"/examples/evals/keyword-coverage\",\n      },\n      {\n        title: \"Prompt Alignment\",\n        href: \"/examples/evals/prompt-alignment\",\n      },\n      {\n        title: \"Summarization\",\n        href: \"/examples/evals/summarization\",\n      },\n      {\n        title: \"Textual Difference\",\n        href: \"/examples/evals/textual-difference\",\n      },\n      {\n        title: \"Tone Consistency\", \n        href: \"/examples/evals/tone-consistency\",\n      },\n      {\n        title: \"Toxicity\",\n        href: \"/examples/evals/toxicity\",\n      },\n      {\n        title: \"Word Inclusion\",\n        href: \"/examples/evals/word-inclusion\",\n      },\n    ],\n    Voice: [\n    {\n      title: \"Text to Speech\",\n      href: \"/examples/voice/text-to-speech\",\n    },\n    {\n      title: \"Speech to Text\",\n      href: \"/examples/voice/speech-to-text\",\n    },\n    {\n      title: \"Turn Taking\",\n      href: \"/examples/voice/turn-taking\",\n    },\n    {\n      title: \"Speech to Speech\",\n      href: \"/examples/voice/speech-to-speech\",\n    },\n    ],\n}}>\n\n</CardItems>\n\n\n---\ntitle: \"Example: Adjusting Chunk Delimiters | RAG | Mastra Docs\"\ndescription: Adjust chunk delimiters in Mastra to better match your content structure.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Adjust Chunk Delimiters\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/adjust-chunk-delimiters\n\nWhen processing large documents, you may want to control how the text is split into smaller chunks. By default, documents are split on newlines, but you can customize this behavior to better match your content structure. This example shows how to specify a custom delimiter for chunking documents.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  separator: \"\\n\",\n});\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-delimiters\"\n  }\n/>\n\n\n---\ntitle: \"Example: Adjusting The Chunk Size | RAG | Mastra Docs\"\ndescription: Adjust chunk size in Mastra to better match your content and memory requirements.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Adjust Chunk Size\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/adjust-chunk-size\n\nWhen processing large documents, you might need to adjust how much text is included in each chunk. By default, chunks are 1024 characters long, but you can customize this size to better match your content and memory requirements. This example shows how to set a custom chunk size when splitting documents.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk({\n  size: 512,\n});\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/adjust-chunk-size\"\n  }\n/>\n\n\n---\ntitle: \"Example: Semantically Chunking HTML | RAG | Mastra Docs\"\ndescription: Chunk HTML content in Mastra to semantically chunk the document.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Semantically Chunking HTML\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/chunk-html\n\nWhen working with HTML content, you often need to break it down into smaller, manageable pieces while preserving the document structure. The chunk method splits HTML content intelligently, maintaining the integrity of HTML tags and elements. This example shows how to chunk HTML documents for search or retrieval purposes.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst html = `\n<div>\n    <h1>h1 content...</h1>\n    <p>p content...</p>\n</div>\n`;\n\nconst doc = MDocument.fromHTML(html);\n\nconst chunks = await doc.chunk({\n  headers: [\n    [\"h1\", \"Header 1\"],\n    [\"p\", \"Paragraph\"],\n  ],\n});\n\nconsole.log(chunks);\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-html\"\n  }\n/>\n\n\n---\ntitle: \"Example: Semantically Chunking JSON | RAG | Mastra Docs\"\ndescription: Chunk JSON data in Mastra to semantically chunk the document.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Semantically Chunking JSON\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/chunk-json\n\nWhen working with JSON data, you need to split it into smaller pieces while preserving the object structure. The chunk method breaks down JSON content intelligently, maintaining the relationships between keys and values. This example shows how to chunk JSON documents for search or retrieval purposes.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst testJson = {\n  name: \"John Doe\",\n  age: 30,\n  email: \"john.doe@example.com\",\n};\n\nconst doc = MDocument.fromJSON(JSON.stringify(testJson));\n\nconst chunks = await doc.chunk({\n  maxSize: 100,\n});\n\nconsole.log(chunks);\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-json\"\n  }\n/>\n\n\n---\ntitle: \"Example: Semantically Chunking Markdown | RAG | Mastra Docs\"\ndescription: Example of using Mastra to chunk markdown documents for search or retrieval purposes.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Chunk Markdown\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/chunk-markdown\n\nMarkdown is more information-dense than raw HTML, making it easier to work with for RAG pipelines. When working with markdown, you need to split it into smaller pieces while preserving headers and formatting. The `chunk` method handles Markdown-specific elements like headers, lists, and code blocks intelligently. This example shows how to chunk markdown documents for search or retrieval purposes.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromMarkdown(\"# Your markdown content...\");\n\nconst chunks = await doc.chunk();\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-markdown\"\n  }\n/>\n\n\n---\ntitle: \"Example: Semantically Chunking Text | RAG | Mastra Docs\"\ndescription: Example of using Mastra to split large text documents into smaller chunks for processing.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Chunk Text\n[EN] Source: https://mastra.ai/en/examples/rag/chunking/chunk-text\n\nWhen working with large text documents, you need to break them down into smaller, manageable pieces for processing. The chunk method splits text content into segments that can be used for search, analysis, or retrieval. This example shows how to split plain text into chunks using default settings.\n\n```tsx copy\nimport { MDocument } from \"@mastra/rag\";\n\nconst doc = MDocument.fromText(\"Your plain text content...\");\n\nconst chunks = await doc.chunk();\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/chunk-text\"\n  }\n/>\n\n\n---\ntitle: \"Example: Embedding Chunk Arrays | RAG | Mastra Docs\"\ndescription: Example of using Mastra to generate embeddings for an array of text chunks for similarity search.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Embed Chunk Array\n[EN] Source: https://mastra.ai/en/examples/rag/embedding/embed-chunk-array\n\nAfter chunking documents, you need to convert the text chunks into numerical vectors that can be used for similarity search. The `embed` method transforms text chunks into embeddings using your chosen provider and model. This example shows how to generate embeddings for an array of text chunks.\n\n```tsx copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embed } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-chunk-array\"\n  }\n/>\n\n\n---\ntitle: \"Example: Embedding Text Chunks | RAG | Mastra Docs\"\ndescription: Example of using Mastra to generate an embedding for a single text chunk for similarity search.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Embed Text Chunk\n[EN] Source: https://mastra.ai/en/examples/rag/embedding/embed-text-chunk\n\nWhen working with individual text chunks, you need to convert them into numerical vectors for similarity search. The `embed` method transforms a single text chunk into an embedding using your chosen provider and model.\n\n```tsx copy\nimport { openai } from \"@ai-sdk/openai\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embed } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embedding } = await embed({\n  model: openai.embedding(\"text-embedding-3-small\"),\n  value: chunks[0].text,\n});\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-chunk\"\n  }\n/>\n\n\n---\ntitle: \"Example: Embedding Text with Cohere | RAG | Mastra Docs\"\ndescription: Example of using Mastra to generate embeddings using Cohere's embedding model.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Embed Text with Cohere\n[EN] Source: https://mastra.ai/en/examples/rag/embedding/embed-text-with-cohere\n\nWhen working with alternative embedding providers, you need a way to generate vectors that match your chosen model's specifications. The `embed` method supports multiple providers, allowing you to switch between different embedding services. This example shows how to generate embeddings using Cohere's embedding model.\n\n```tsx copy\nimport { cohere } from \"@ai-sdk/cohere\";\nimport { MDocument } from \"@mastra/rag\";\nimport { embedMany } from \"ai\";\n\nconst doc = MDocument.fromText(\"Your text content...\");\n\nconst chunks = await doc.chunk();\n\nconst { embeddings } = await embedMany({\n  model: cohere.embedding(\"embed-english-v3.0\"),\n  values: chunks.map((chunk) => chunk.text),\n});\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/embed-text-with-cohere\"\n  }\n/>\n\n\n---\ntitle: \"Example: Metadata Extraction | Retrieval | RAG | Mastra Docs\"\ndescription: Example of extracting and utilizing metadata from documents in Mastra for enhanced document processing and retrieval.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Metadata Extraction\n[EN] Source: https://mastra.ai/en/examples/rag/embedding/metadata-extraction\n\nThis example demonstrates how to extract and utilize metadata from documents using Mastra's document processing capabilities.\nThe extracted metadata can be used for document organization, filtering, and enhanced retrieval in RAG systems.\n\n## Overview\n\nThe system demonstrates metadata extraction in two ways:\n\n1. Direct metadata extraction from a document\n2. Chunking with metadata extraction\n\n## Setup\n\n### Dependencies\n\nImport the necessary dependencies:\n\n```typescript copy showLineNumbers filename=\"src/index.ts\"\nimport { MDocument } from \"@mastra/rag\";\n```\n\n## Document Creation\n\nCreate a document from text content:\n\n```typescript copy showLineNumbers{3} filename=\"src/index.ts\"\nconst doc = MDocument.fromText(`Title: The Benefits of Regular Exercise\n\nRegular exercise has numerous health benefits. It improves cardiovascular health, \nstrengthens muscles, and boosts mental wellbeing.\n\nKey Benefits:\nâ€¢ Reduces stress and anxiety\nâ€¢ Improves sleep quality\nâ€¢ Helps maintain healthy weight\nâ€¢ Increases energy levels\n\nFor optimal results, experts recommend at least 150 minutes of moderate exercise \nper week.`);\n```\n\n## 1. Direct Metadata Extraction\n\nExtract metadata directly from the document:\n\n```typescript copy showLineNumbers{17} filename=\"src/index.ts\"\n// Configure metadata extraction options\nawait doc.extractMetadata({\n  keywords: true, // Extract important keywords\n  summary: true, // Generate a concise summary\n});\n\n// Retrieve the extracted metadata\nconst meta = doc.getMetadata();\nconsole.log(\"Extracted Metadata:\", meta);\n\n// Example Output:\n// Extracted Metadata: {\n//   keywords: [\n//     'exercise',\n//     'health benefits',\n//     'cardiovascular health',\n//     'mental wellbeing',\n//     'stress reduction',\n//     'sleep quality'\n//   ],\n//   summary: 'Regular exercise provides multiple health benefits including improved cardiovascular health, muscle strength, and mental wellbeing. Key benefits include stress reduction, better sleep, weight management, and increased energy. Recommended exercise duration is 150 minutes per week.'\n// }\n```\n\n## 2. Chunking with Metadata\n\nCombine document chunking with metadata extraction:\n\n```typescript copy showLineNumbers{40} filename=\"src/index.ts\"\n// Configure chunking with metadata extraction\nawait doc.chunk({\n  strategy: \"recursive\", // Use recursive chunking strategy\n  size: 200, // Maximum chunk size\n  extract: {\n    keywords: true, // Extract keywords per chunk\n    summary: true, // Generate summary per chunk\n  },\n});\n\n// Get metadata from chunks\nconst metaTwo = doc.getMetadata();\nconsole.log(\"Chunk Metadata:\", metaTwo);\n\n// Example Output:\n// Chunk Metadata: {\n//   keywords: [\n//     'exercise',\n//     'health benefits',\n//     'cardiovascular health',\n//     'mental wellbeing',\n//     'stress reduction',\n//     'sleep quality'\n//   ],\n//   summary: 'Regular exercise provides multiple health benefits including improved cardiovascular health, muscle strength, and mental wellbeing. Key benefits include stress reduction, better sleep, weight management, and increased energy. Recommended exercise duration is 150 minutes per week.'\n// }\n```\n\n<br />\n<br />\n<hr className=\"dark:border-[#404040] border-gray-300\" />\n<br />\n<br />\n<GithubLink\n  link={\n    \"https://github.com/mastra-ai/mastra/blob/main/examples/basics/rag/metadata-extraction\"\n  }\n/>\n\n\n---\ntitle: \"Example: Hybrid Vector Search | RAG | Mastra Docs\"\ndescription: Example of using metadata filters with PGVector to enhance vector search results in Mastra.\n---\n\nimport { GithubLink } from \"@/components/github-link\";\n\n# Hybrid Vector Search\n[EN] Source: https://mastra.ai/en/examples/rag/query/hybrid-vector-search\n\nWhen you combine vector similarity search with metadata filters, you can create a hybrid search that is more precise and efficient.\nThis approach combines:\n\n- Vector similarity search to find the most relevant documents\n- Metadata filters to refine the search results based on additional criteria\n\nThis example demonstrates how to use hybrid vector search with Mastra and PGVector.\n\n## Overview\n\nThe system implements filtered vector search using Mastra and PGVector. Here's what it does:\n\n1. Queries existing embeddings in PGVector with metadata filters\n2. Shows how to filter by different metadata fields\n3. Demonstrates combining vector similarity with metadata filtering\n\n> **Note**: For examples of how to extract metadata from your documents, see the [Metadata Extraction](../embedding/metadata-extraction.mdx) guide.\n>\n> To learn how to create and store embeddings, see the [Upsert Embeddings](/examples/rag/upsert/upsert-embeddings) guide.\n\n## Setup\n\n### Environment Setup\n\nMake sure to set up your environment variables:\n\n```bash filename=\".env\"\nOPENAI_API_KEY=your_openai_api_key_here\nPOSTGRES_CONNECTION_STRING=your_connection_string_here\n```\n\n### Dependencies\n\nImport the necessary dependencies:\n\n```typescript copy showLineNumbers filename=\"src/index.ts\"\nimport { embed } from \"ai\";\nimport { PgVector } from \"@mastra/pg\";\nimport { openai } from \"@ai-sdk/openai\";\n```\n\n## Vector Store Initialization\n\nInitialize PgVector with your connection string:\n\n```typescript copy showLineNumbers{4} filename=\"src/index.ts\"\nconst pgVector =","size_bytes":360000},"bot_project/__init__.py":{"content":"","size_bytes":0},"scripts/build.sh":{"content":"#!/usr/bin/env bash\n\nset -e\n\nexec mastra build\n","size_bytes":47},"scripts/inngest.sh":{"content":"#!/usr/bin/env bash\n\nset -e\n\nINNGEST_CONFIG=\".config/inngest/inngest.yaml\"\n\n# Try to store Inngest data in Postgres if it's available. Otherwise, put it in SQLite.\nif [[ ! -f  \"${INNGEST_CONFIG}\" ]]; then\n    mkdir -p \"$(dirname \"${INNGEST_CONFIG}\")\"\n    if [[ -n \"${DATABASE_URL}\" ]]; then\n        printf 'postgres-uri: \"%s\"' \"${DATABASE_URL}\" > \"${INNGEST_CONFIG}\"\n    else\n        printf 'sqlite-dir: \"/home/runner/workspace/.local/share/inngest\"' > \"${INNGEST_CONFIG}\"\n    fi\nfi\nexec inngest-cli dev -u http://localhost:5000/api/inngest --host 0.0.0.0 --port 3000 --config \"${INNGEST_CONFIG}\"\n","size_bytes":597},"src/global.d.ts":{"content":"declare module \"mastra\";\n","size_bytes":25},"bot_project/db/__init__.py":{"content":"","size_bytes":0},"bot_project/db/db.py":{"content":"\"\"\"\nDatabase module for Telegram bot reporting system.\nProvides CRUD operations for SQLite database with user events tracking.\n\"\"\"\n\nimport sqlite3\nimport logging\nfrom typing import Optional, List, Dict, Any, Tuple\nfrom datetime import datetime, date, timezone\nimport os\nfrom contextlib import contextmanager\n\n# Setup logging\nlogger = logging.getLogger(__name__)\n\n\nclass DatabaseManager:\n    \"\"\"\n    SQLite database manager for Telegram bot reporting system.\n    Handles all database operations with proper error handling and transactions.\n    \"\"\"\n    \n    def __init__(self, db_path: str):\n        \"\"\"\n        Initialize database manager.\n        \n        Args:\n            db_path: Path to SQLite database file\n        \"\"\"\n        self.db_path = db_path\n        self.init_database()\n    \n    @contextmanager\n    def get_connection(self):\n        \"\"\"\n        Context manager for database connections with automatic cleanup.\n        \n        Yields:\n            sqlite3.Connection: Database connection\n        \"\"\"\n        conn = None\n        try:\n            conn = sqlite3.connect(self.db_path)\n            conn.row_factory = sqlite3.Row  # Enable dict-like access to rows\n            conn.execute(\"PRAGMA foreign_keys=ON\")  # Enable foreign key constraints\n            yield conn\n        except Exception as e:\n            if conn:\n                conn.rollback()\n            logger.error(f\"Database error: {e}\")\n            raise\n        finally:\n            if conn:\n                conn.close()\n    \n    def init_database(self) -> None:\n        \"\"\"\n        Initialize database by running migrations.\n        Creates all necessary tables and indexes.\n        \"\"\"\n        migrations_path = os.path.join(os.path.dirname(__file__), 'migrations.sql')\n        \n        try:\n            with open(migrations_path, 'r', encoding='utf-8') as f:\n                migrations_sql = f.read()\n            \n            with self.get_connection() as conn:\n                conn.executescript(migrations_sql)\n                \n                # Add username column to inviters if it doesn't exist\n                try:\n                    conn.execute(\"ALTER TABLE inviters ADD COLUMN username TEXT\")\n                    logger.info(\"Added username column to inviters table\")\n                except Exception:\n                    # Column already exists\n                    pass\n                \n                conn.commit()\n                logger.info(\"Database initialized successfully\")\n                \n        except FileNotFoundError:\n            logger.error(f\"Migrations file not found: {migrations_path}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Failed to initialize database: {e}\")\n            raise\n    \n    def insert_user_if_not_exists(self, tg_user_id: int, username: Optional[str] = None, \n                                   name: Optional[str] = None) -> int:\n        \"\"\"\n        Insert user if not exists, return user ID. Uses atomic UPSERT operation.\n        \n        Args:\n            tg_user_id: Telegram user ID\n            username: Telegram username (optional)\n            name: User display name (optional)\n            \n        Returns:\n            int: User ID in database\n        \"\"\"\n        with self.get_connection() as conn:\n            # Atomic UPSERT operation\n            cursor = conn.execute(\n                \"\"\"INSERT INTO users (tg_user_id, username, name) VALUES (?, ?, ?)\n                   ON CONFLICT(tg_user_id) DO UPDATE SET \n                   username = COALESCE(excluded.username, username),\n                   name = COALESCE(excluded.name, name)\"\"\",\n                (tg_user_id, username, name)\n            )\n            \n            # Get the user ID (either newly inserted or existing)\n            cursor = conn.execute(\n                \"SELECT id FROM users WHERE tg_user_id = ?\",\n                (tg_user_id,)\n            )\n            row = cursor.fetchone()\n            conn.commit()\n            \n            if row is None:\n                raise RuntimeError(f\"Failed to insert/get user with tg_user_id={tg_user_id}\")\n            \n            logger.info(f\"User upserted: tg_user_id={tg_user_id}, username={username}\")\n            return row[0]\n    \n    def get_inviter_by_link(self, invite_link: str) -> Optional[int]:\n        \"\"\"\n        Get inviter ID by invite link.\n        \n        Args:\n            invite_link: Telegram invite link\n            \n        Returns:\n            Optional[int]: Inviter ID if found, None otherwise\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"SELECT id FROM inviters WHERE invite_link = ?\",\n                (invite_link,)\n            )\n            row = cursor.fetchone()\n            return row[0] if row else None\n\n    def upsert_inviter(self, name: str, username: Optional[str] = None, \n                       invite_link: Optional[str] = None, channel_id: Optional[str] = None) -> int:\n        \"\"\"\n        Insert or update inviter with username support.\n        \n        Args:\n            name: Inviter name\n            username: Inviter username (with or without @)\n            invite_link: Invite link (optional)\n            channel_id: Channel ID (optional)\n            \n        Returns:\n            int: Inviter ID\n        \"\"\"\n        # Clean username (remove @ if present, add if missing for storage)\n        if username and not username.startswith('@'):\n            username = f'@{username}'\n        \n        with self.get_connection() as conn:\n            # Try to find existing inviter by username or name\n            cursor = conn.execute(\n                \"SELECT id FROM inviters WHERE username = ? OR name = ?\",\n                (username, name)\n            )\n            existing = cursor.fetchone()\n            \n            if existing:\n                # Update existing\n                conn.execute(\n                    \"\"\"UPDATE inviters SET name = ?, username = ?, invite_link = ?, channel_id = ?\n                       WHERE id = ?\"\"\",\n                    (name, username, invite_link, channel_id, existing[0])\n                )\n                conn.commit()\n                return existing[0]\n            else:\n                # Insert new\n                cursor = conn.execute(\n                    \"INSERT INTO inviters (name, username, invite_link, channel_id) VALUES (?, ?, ?, ?)\",\n                    (name, username, invite_link, channel_id)\n                )\n                conn.commit()\n                return cursor.lastrowid\n    \n    def insert_journal_event(self, event_type: str, tg_user_id: int, \n                           username: Optional[str] = None, name: Optional[str] = None,\n                           inviter_id: Optional[int] = None, status: str = 'subscribed',\n                           note: Optional[str] = None, telegram_update_id: Optional[int] = None) -> int:\n        \"\"\"\n        Insert journal event with proper validation and duplicate detection.\n        \n        Args:\n            event_type: Type of event ('subscribe', 'unsubscribe', 'manual_add', etc.)\n            tg_user_id: Telegram user ID\n            username: Telegram username (optional)\n            name: User display name (optional)\n            inviter_id: ID of inviter (optional)\n            status: User status ('subscribed', 'left', etc.)\n            note: Additional notes (e.g., 'repeat' for duplicate invites)\n            telegram_update_id: Telegram update ID for idempotency (optional)\n            \n        Returns:\n            int: Journal entry ID\n        \"\"\"\n        # Use UTC timezone for consistency\n        event_time = datetime.now(timezone.utc).isoformat()\n        \n        with self.get_connection() as conn:\n            # Check if this is a repeat invitation\n            if event_type == 'subscribe' and inviter_id:\n                cursor = conn.execute(\n                    \"SELECT COUNT(*) FROM journal WHERE tg_user_id = ? AND event_type = 'subscribe' AND inviter_id IS NOT NULL AND inviter_id != ?\",\n                    (tg_user_id, inviter_id)\n                )\n                previous_invites = cursor.fetchone()[0]\n                if previous_invites > 0:\n                    note = 'repeat' if note is None else f\"{note},repeat\"\n            \n            # Insert journal event with idempotency via telegram_update_id\n            if telegram_update_id:\n                # For better idempotency, use INSERT OR IGNORE then SELECT\n                cursor = conn.execute(\n                    \"\"\"INSERT OR IGNORE INTO journal (event_time, event_type, tg_user_id, username, name, inviter_id, status, note, telegram_update_id) \n                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n                    (event_time, event_type, tg_user_id, username, name, inviter_id, status, note, telegram_update_id)\n                )\n                \n                if cursor.rowcount == 0:\n                    # Duplicate - find existing record\n                    cursor = conn.execute(\n                        \"SELECT id FROM journal WHERE telegram_update_id = ?\",\n                        (telegram_update_id,)\n                    )\n                    existing = cursor.fetchone()\n                    if existing:\n                        logger.info(f\"Duplicate event skipped: update_id={telegram_update_id}\")\n                        conn.commit()\n                        return existing[0]\n                    else:\n                        raise RuntimeError(f\"Insert ignored but no existing record found for update_id={telegram_update_id}\")\n                \n                journal_id = cursor.lastrowid\n                if journal_id is None:\n                    raise RuntimeError(f\"Failed to insert journal event for tg_user_id={tg_user_id}\")\n                \n                conn.commit()\n                logger.info(f\"Journal event inserted: {event_type} for tg_user_id={tg_user_id}, journal_id={journal_id}\")\n                return journal_id\n            else:\n                # No telegram_update_id - regular insert\n                cursor = conn.execute(\n                    \"\"\"INSERT INTO journal (event_time, event_type, tg_user_id, username, name, inviter_id, status, note, telegram_update_id) \n                       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n                    (event_time, event_type, tg_user_id, username, name, inviter_id, status, note, None)\n                )\n                conn.commit()\n                \n                journal_id = cursor.lastrowid\n                if journal_id is None:\n                    raise RuntimeError(f\"Failed to insert journal event for tg_user_id={tg_user_id}\")\n                \n                logger.info(f\"Journal event inserted: {event_type} for tg_user_id={tg_user_id}, journal_id={journal_id}\")\n                return journal_id\n    \n    def get_subscriptions_for_retention_check(self, retention_days: int, check_date: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get subscriptions that need retention check. Only selects subscriptions \n        that happened exactly N days ago and haven't been checked yet.\n        \n        Args:\n            retention_days: Number of days to check retention after subscription\n            check_date: Date of the check (ISO format)\n            \n        Returns:\n            List of journal entries that need retention check\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT j.* FROM journal j \n                   WHERE j.event_type = 'subscribe' \n                   AND date(j.event_time) = date(?, ? || ' days')\n                   AND NOT EXISTS (\n                       SELECT 1 FROM retention_checks rc \n                       WHERE rc.journal_id = j.id\n                   )\"\"\",\n                (check_date, f'-{retention_days}')\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def check_user_retention(self, journal_id: int, tg_user_id: int, \n                           subscription_time: str) -> str:\n        \"\"\"\n        Check if user is retained (no unsubscribe event after subscription).\n        \n        Args:\n            journal_id: Journal entry ID of the subscription\n            tg_user_id: Telegram user ID\n            subscription_time: Time of subscription (ISO format)\n            \n        Returns:\n            str: 'retained' or 'not_retained'\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(*) FROM journal \n                   WHERE tg_user_id = ? AND event_type = 'unsubscribe' \n                   AND event_time > ?\"\"\",\n                (tg_user_id, subscription_time)\n            )\n            unsubscribe_count = cursor.fetchone()[0]\n            \n            return 'not_retained' if unsubscribe_count > 0 else 'retained'\n    \n    def insert_retention_check(self, journal_id: int, check_date: str, result: str) -> None:\n        \"\"\"\n        Insert retention check result to avoid duplicate processing.\n        Uses UNIQUE constraint for idempotency.\n        \n        Args:\n            journal_id: Journal entry ID\n            check_date: Date of the check (ISO format)\n            result: Result of the check ('retained', 'not_retained', 'pending')\n        \"\"\"\n        with self.get_connection() as conn:\n            try:\n                conn.execute(\n                    \"INSERT INTO retention_checks (journal_id, check_date, result) VALUES (?, ?, ?)\",\n                    (journal_id, check_date, result)\n                )\n                conn.commit()\n            except sqlite3.IntegrityError:\n                # Duplicate (journal_id, check_date) - ignore silently\n                logger.debug(f\"Retention check already exists: journal_id={journal_id}, check_date={check_date}\")\n                pass\n    \n    def get_journal_for_excel(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get all journal entries for Excel export.\n        \n        Returns:\n            List of journal entries with inviter names and usernames\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT j.id, j.event_time, j.event_type, j.tg_user_id, \n                          j.username, j.name, \n                          COALESCE(i.username, i.name, 'Unknown') as inviter_name, \n                          j.status, j.note\n                   FROM journal j\n                   LEFT JOIN inviters i ON j.inviter_id = i.id\n                   ORDER BY j.event_time DESC\"\"\"\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def get_statistics_data(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get aggregated statistics for all inviters.\n        \n        Returns:\n            List of statistics per inviter\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                    COALESCE(i.username, i.name, 'Unknown') as inviter_name,\n                    COUNT(CASE WHEN j.event_type = 'subscribe' THEN 1 END) as total_invited,\n                    COUNT(CASE WHEN j.event_type = 'subscribe' AND j.tg_user_id NOT IN (\n                        SELECT j2.tg_user_id FROM journal j2 \n                        WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j.event_time\n                    ) THEN 1 END) as currently_subscribed,\n                    COUNT(CASE WHEN j.event_type = 'subscribe' AND j.tg_user_id IN (\n                        SELECT j2.tg_user_id FROM journal j2 \n                        WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j.event_time\n                    ) THEN 1 END) as unsubscribed,\n                    ROUND(\n                        CAST(COUNT(CASE WHEN j.event_type = 'subscribe' AND j.tg_user_id NOT IN (\n                            SELECT j2.tg_user_id FROM journal j2 \n                            WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j.event_time\n                        ) THEN 1 END) AS FLOAT) * 100.0 / \n                        NULLIF(COUNT(CASE WHEN j.event_type = 'subscribe' THEN 1 END), 0), 2\n                    ) as retention_percentage\n                FROM inviters i\n                LEFT JOIN journal j ON i.id = j.inviter_id\n                GROUP BY i.id, i.name, i.username\n                HAVING total_invited > 0\n                ORDER BY total_invited DESC\"\"\"\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def get_daily_stats(self, report_date: str) -> Dict[str, Any]:\n        \"\"\"\n        Get daily statistics for a specific date.\n        \n        Args:\n            report_date: Date in YYYY-MM-DD format\n            \n        Returns:\n            Dict with daily statistics\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                   COUNT(CASE WHEN event_type = 'subscribe' THEN 1 END) as total_subscriptions,\n                   COUNT(CASE WHEN event_type = 'unsubscribe' THEN 1 END) as total_unsubscriptions,\n                   COUNT(DISTINCT CASE WHEN event_type = 'subscribe' THEN tg_user_id END) as unique_subscribers,\n                   COUNT(CASE WHEN event_type = 'subscribe' AND note LIKE '%repeat%' THEN 1 END) as repeat_subscribers\n                   FROM journal \n                   WHERE date(event_time) = ?\"\"\",\n                (report_date,)\n            )\n            row = cursor.fetchone()\n            \n            stats = dict(row) if row else {}\n            stats['net_growth'] = stats.get('total_subscriptions', 0) - stats.get('total_unsubscriptions', 0)\n            return stats\n    \n    def get_weekly_stats(self, week_start: str) -> Dict[str, Any]:\n        \"\"\"\n        Get weekly statistics starting from given date.\n        \n        Args:\n            week_start: Start date of week in YYYY-MM-DD format\n            \n        Returns:\n            Dict with weekly statistics\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                   COUNT(CASE WHEN event_type = 'subscribe' THEN 1 END) as total_subscriptions,\n                   COUNT(CASE WHEN event_type = 'unsubscribe' THEN 1 END) as total_unsubscriptions,\n                   COUNT(DISTINCT CASE WHEN event_type = 'subscribe' THEN tg_user_id END) as unique_subscribers,\n                   COUNT(CASE WHEN event_type = 'subscribe' AND note LIKE '%repeat%' THEN 1 END) as repeat_subscribers\n                   FROM journal \n                   WHERE date(event_time) >= date(?) \n                   AND date(event_time) < date(?, '+7 days')\"\"\",\n                (week_start, week_start)\n            )\n            row = cursor.fetchone()\n            \n            stats = dict(row) if row else {}\n            stats['net_growth'] = stats.get('total_subscriptions', 0) - stats.get('total_unsubscriptions', 0)\n            return stats\n    \n    def get_monthly_stats(self, month_start: str) -> Dict[str, Any]:\n        \"\"\"\n        Get monthly statistics starting from given date.\n        \n        Args:\n            month_start: Start date of month in YYYY-MM-DD format\n            \n        Returns:\n            Dict with monthly statistics\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                   COUNT(CASE WHEN event_type = 'subscribe' THEN 1 END) as total_subscriptions,\n                   COUNT(CASE WHEN event_type = 'unsubscribe' THEN 1 END) as total_unsubscriptions,\n                   COUNT(DISTINCT CASE WHEN event_type = 'subscribe' THEN tg_user_id END) as unique_subscribers,\n                   COUNT(CASE WHEN event_type = 'subscribe' AND note LIKE '%repeat%' THEN 1 END) as repeat_subscribers\n                   FROM journal \n                   WHERE date(event_time) >= date(?) \n                   AND date(event_time) < date(?, '+1 month')\"\"\",\n                (month_start, month_start)\n            )\n            row = cursor.fetchone()\n            \n            stats = dict(row) if row else {}\n            stats['net_growth'] = stats.get('total_subscriptions', 0) - stats.get('total_unsubscriptions', 0)\n            return stats\n    \n    def get_events_for_period(self, start_date: str, end_date: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get all events for a specific period.\n        \n        Args:\n            start_date: Start date in YYYY-MM-DD format\n            end_date: End date in YYYY-MM-DD format\n            \n        Returns:\n            List of events\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT * FROM journal \n                   WHERE date(event_time) >= ? AND date(event_time) <= ?\n                   ORDER BY event_time DESC\"\"\",\n                (start_date, end_date)\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def get_retention_stats(self, retention_days: int, check_date: str) -> Dict[str, Any]:\n        \"\"\"\n        Get retention statistics for a specific period.\n        \n        Args:\n            retention_days: Number of days for retention check\n            check_date: Date to check from\n            \n        Returns:\n            Dict with retention statistics\n        \"\"\"\n        # Get subscriptions that happened N days ago\n        subscriptions_to_check = self.get_subscriptions_for_retention_check(retention_days, check_date)\n        \n        if not subscriptions_to_check:\n            return {\n                'total_subscriptions': 0,\n                'retained': 0,\n                'not_retained': 0,\n                'retention_rate': 0.0\n            }\n        \n        retained_count = 0\n        not_retained_count = 0\n        \n        for subscription in subscriptions_to_check:\n            retention_result = self.check_user_retention(\n                subscription['id'], \n                subscription['tg_user_id'], \n                subscription['event_time']\n            )\n            \n            if retention_result == 'retained':\n                retained_count += 1\n            elif retention_result == 'not_retained':\n                not_retained_count += 1\n        \n        total_subscriptions = len(subscriptions_to_check)\n        retention_rate = retained_count / total_subscriptions if total_subscriptions > 0 else 0.0\n        \n        return {\n            'total_subscriptions': total_subscriptions,\n            'retained': retained_count,\n            'not_retained': not_retained_count,\n            'retention_rate': retention_rate\n        }\n    \n    def get_retention_checks_for_excel(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get all retention checks for Excel export.\n        \n        Returns:\n            List of retention check records\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT rc.*, j.tg_user_id, j.username, j.event_time as subscription_time\n                   FROM retention_checks rc\n                   JOIN journal j ON rc.journal_id = j.id\n                   ORDER BY rc.check_date DESC, j.event_time DESC\"\"\"\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def get_user_stats_summary(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get summary statistics for all users.\n        \n        Returns:\n            List of user statistics\n        \"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                   j.tg_user_id,\n                   j.username,\n                   j.name,\n                   COUNT(CASE WHEN j.event_type = 'subscribe' THEN 1 END) as total_subscriptions,\n                   COUNT(CASE WHEN j.event_type = 'unsubscribe' THEN 1 END) as total_unsubscriptions,\n                   MIN(CASE WHEN j.event_type = 'subscribe' THEN j.event_time END) as first_subscription,\n                   MAX(j.event_time) as last_activity,\n                   CASE WHEN EXISTS (\n                       SELECT 1 FROM journal j2 \n                       WHERE j2.tg_user_id = j.tg_user_id \n                       AND j2.event_type = 'subscribe'\n                       AND j2.tg_user_id NOT IN (\n                           SELECT j3.tg_user_id FROM journal j3 \n                           WHERE j3.event_type = 'unsubscribe' AND j3.event_time > j2.event_time\n                       )\n                   ) THEN 'active' ELSE 'inactive' END as status\n                   FROM journal j\n                   GROUP BY j.tg_user_id, j.username, j.name\n                   ORDER BY last_activity DESC\"\"\"\n            )\n            return [dict(row) for row in cursor.fetchall()]\n\n    def get_daily_report_data(self, report_date: str) -> Dict[str, Any]:\n        \"\"\"\n        Generate daily report data for specific date.\n        \n        Args:\n            report_date: Date for the report (ISO format)\n            \n        Returns:\n            Dictionary with report data\n        \"\"\"\n        with self.get_connection() as conn:\n            # New subscriptions today\n            cursor = conn.execute(\n                \"SELECT COUNT(*) FROM journal WHERE event_type = 'subscribe' AND date(event_time) = ?\",\n                (report_date,)\n            )\n            new_subscriptions = cursor.fetchone()[0]\n            \n            # Unsubscriptions today\n            cursor = conn.execute(\n                \"SELECT COUNT(*) FROM journal WHERE event_type = 'unsubscribe' AND date(event_time) = ?\",\n                (report_date,)\n            )\n            unsubscriptions = cursor.fetchone()[0]\n            \n            # Total active subscribers\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(DISTINCT j1.tg_user_id) FROM journal j1\n                   WHERE j1.event_type = 'subscribe' \n                   AND j1.tg_user_id NOT IN (\n                       SELECT j2.tg_user_id FROM journal j2 \n                       WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j1.event_time\n                   )\"\"\"\n            )\n            total_active = cursor.fetchone()[0]\n            \n            # Top inviters today\n            cursor = conn.execute(\n                \"\"\"SELECT i.name, COUNT(*) as new_invites\n                   FROM journal j\n                   JOIN inviters i ON j.inviter_id = i.id\n                   WHERE j.event_type = 'subscribe' AND date(j.event_time) = ?\n                   GROUP BY i.id, i.name\n                   ORDER BY new_invites DESC\n                   LIMIT 5\"\"\",\n                (report_date,)\n            )\n            top_inviters = [dict(row) for row in cursor.fetchall()]\n            \n            return {\n                'date': report_date,\n                'new_subscriptions': new_subscriptions,\n                'unsubscriptions': unsubscriptions,\n                'total_active': total_active,\n                'top_inviters': top_inviters\n            }\n    \n    def get_all_inviters(self) -> List[Dict[str, Any]]:\n        \"\"\"Get all inviters from database.\"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\"SELECT id, name, invite_link FROM inviters\")\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def count_users_by_inviter(self, inviter_name: str) -> int:\n        \"\"\"Count total users invited by specific inviter.\"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(*) FROM journal j\n                   JOIN inviters i ON j.inviter_id = i.id\n                   WHERE i.name = ? AND j.event_type = 'subscribe'\"\"\",\n                (inviter_name,)\n            )\n            return cursor.fetchone()[0]\n    \n    def count_active_users_by_inviter(self, inviter_name: str) -> int:\n        \"\"\"Count currently active users invited by specific inviter.\"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(DISTINCT j1.tg_user_id) FROM journal j1\n                   JOIN inviters i ON j1.inviter_id = i.id\n                   WHERE i.name = ? AND j1.event_type = 'subscribe'\n                   AND j1.tg_user_id NOT IN (\n                       SELECT j2.tg_user_id FROM journal j2 \n                       WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j1.event_time\n                   )\"\"\",\n                (inviter_name,)\n            )\n            return cursor.fetchone()[0]\n    \n    def get_top_inviters_for_date(self, target_date: str, limit: int = 3) -> List[Dict[str, Any]]:\n        \"\"\"Get top inviters for specific date with retention data.\"\"\"\n        with self.get_connection() as conn:\n            cursor = conn.execute(\n                \"\"\"SELECT \n                    i.name as inviter_name,\n                    COUNT(*) as invited_count,\n                    COUNT(CASE WHEN j1.tg_user_id NOT IN (\n                        SELECT j2.tg_user_id FROM journal j2 \n                        WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j1.event_time\n                    ) THEN 1 END) as retained_count\n                   FROM journal j1\n                   JOIN inviters i ON j1.inviter_id = i.id\n                   WHERE j1.event_type = 'subscribe' AND date(j1.event_time) = ?\n                   GROUP BY i.id, i.name\n                   ORDER BY invited_count DESC\n                   LIMIT ?\"\"\",\n                (target_date, limit)\n            )\n            return [dict(row) for row in cursor.fetchall()]\n    \n    def get_retention_for_date(self, target_date: str, retention_days: int) -> Dict[str, Any]:\n        \"\"\"Get retention statistics for users who subscribed on specific date.\"\"\"\n        with self.get_connection() as conn:\n            # Get users who subscribed on target date\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(*) FROM journal \n                   WHERE event_type = 'subscribe' AND date(event_time) = ?\"\"\",\n                (target_date,)\n            )\n            total_subscriptions = cursor.fetchone()[0]\n            \n            if total_subscriptions == 0:\n                return {'total_subscriptions': 0, 'retained': 0, 'retention_rate': 0}\n            \n            # Get users who subscribed on target date and are still active after retention_days\n            from datetime import datetime, timedelta\n            check_date = datetime.strptime(target_date, \"%Y-%m-%d\") + timedelta(days=retention_days)\n            check_date_str = check_date.strftime(\"%Y-%m-%d\")\n            \n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(DISTINCT j1.tg_user_id) FROM journal j1\n                   WHERE j1.event_type = 'subscribe' AND date(j1.event_time) = ?\n                   AND j1.tg_user_id NOT IN (\n                       SELECT j2.tg_user_id FROM journal j2 \n                       WHERE j2.event_type = 'unsubscribe' \n                       AND j2.event_time > j1.event_time\n                       AND date(j2.event_time) <= ?\n                   )\"\"\",\n                (target_date, check_date_str)\n            )\n            retained = cursor.fetchone()[0]\n            \n            retention_rate = (retained / total_subscriptions) * 100 if total_subscriptions > 0 else 0\n            \n            return {\n                'total_subscriptions': total_subscriptions,\n                'retained': retained,\n                'retention_rate': retention_rate\n            }\n\n\n# Global database instance\ndb_manager: Optional[DatabaseManager] = None\n\n\ndef init_db(db_path: str) -> None:\n    \"\"\"\n    Initialize global database manager.\n    \n    Args:\n        db_path: Path to SQLite database file\n    \"\"\"\n    global db_manager\n    db_manager = DatabaseManager(db_path)\n\n\ndef get_db() -> DatabaseManager:\n    \"\"\"\n    Get global database manager instance.\n    \n    Returns:\n        DatabaseManager: Database manager instance\n        \n    Raises:\n        RuntimeError: If database not initialized\n    \"\"\"\n    if db_manager is None:\n        raise RuntimeError(\"Database not initialized. Call init_db() first.\")\n    return db_manager\n\n\nasync def init_database() -> None:\n    \"\"\"\n    Initialize database for startup scripts.\n    Async wrapper for init_db function.\n    \"\"\"\n    db_path = os.getenv('DB_PATH', 'data/bot.sqlite3')\n    \n    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð‘Ð” ÐµÑÐ»Ð¸ Ð¿ÑƒÑ‚ÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¿Ð°Ð¿ÐºÐ¸\n    db_dir = os.path.dirname(db_path)\n    if db_dir:  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð¿ÑƒÑ‚ÑŒ Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð¹\n        os.makedirs(db_dir, exist_ok=True)\n    \n    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n    init_db(db_path)\n    logger.info(f\"Database initialized: {db_path}\")","size_bytes":32639},"bot_project/handlers/__init__.py":{"content":"# Handlers package","size_bytes":18},"bot_project/handlers/commands.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´ Telegram Ð±Ð¾Ñ‚Ð° Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°Ð¼Ð¸.\n\nÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°:\n- /start, /help - ÑÐ¿Ñ€Ð°Ð²ÐºÐ°\n- /stats - ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´  \n- /report - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ\n- /export - Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n- /schedule - ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼\n- /status - ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\n\"\"\"\n\nimport logging\nimport os\nfrom datetime import datetime, timedelta\nfrom typing import Optional, List\nimport json\n\nfrom aiogram import Router, F\nfrom aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery, FSInputFile\nfrom aiogram.filters import Command, CommandStart\nfrom aiogram.fsm.context import FSMContext\nfrom aiogram.fsm.state import State, StatesGroup\nfrom pathlib import Path\n\nfrom db.db import get_db\nfrom reports.report_manager import ReportManager\nfrom reports.scheduler import ReportScheduler\nfrom utils.time_utils import get_almaty_now, format_datetime_for_report\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n# Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ€Ð¾ÑƒÑ‚ÐµÑ€ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´\ncommands_router = Router(name=\"commands\")\n\n# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\nreport_scheduler: Optional[ReportScheduler] = None\n\n\ndef initialize_scheduler(bot) -> None:\n    \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ° Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n    global report_scheduler\n    \n    try:\n        db = get_db()\n        report_scheduler = ReportScheduler(bot, db)\n        logger.info(\"ðŸ•’ [Commands] ReportScheduler initialized successfully\")\n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Failed to initialize ReportScheduler: {e}\")\n\n\ndef get_scheduler() -> Optional[ReportScheduler]:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.\"\"\"\n    return report_scheduler\n\n# Ð¡Ð¿Ð¸ÑÐ¾Ðº ID Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð² (Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°Ñ‚ÑŒÑÑ Ñ‡ÐµÑ€ÐµÐ· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ)\nADMIN_IDS: List[int] = []  # Ð‘ÑƒÐ´ÐµÑ‚ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½ Ð¿Ñ€Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸\n\n\ndef initialize_admin_ids() -> None:\n    \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¿Ð¸ÑÐºÐ° Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð² Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ.\"\"\"\n    global ADMIN_IDS\n    \n    admin_ids_str = os.environ.get('ADMIN_IDS', '')\n    if not admin_ids_str:\n        logger.warning(\"âš ï¸ [Commands] ADMIN_IDS environment variable not set - no administrators configured\")\n        return\n    \n    try:\n        # ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚: \"123456789,987654321\" Ð¸Ð»Ð¸ \"123456789, 987654321\"\n        admin_ids = [int(id_str.strip()) for id_str in admin_ids_str.split(',') if id_str.strip()]\n        ADMIN_IDS.clear()\n        ADMIN_IDS.extend(admin_ids)\n        \n        logger.info(f\"âœ… [Commands] Initialized {len(ADMIN_IDS)} administrators: {ADMIN_IDS}\")\n        \n    except ValueError as e:\n        logger.error(f\"âŒ [Commands] Invalid ADMIN_IDS format in environment variable: {admin_ids_str} - {e}\")\n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error initializing admin IDs: {e}\")\n\n\n# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ admin IDs Ð¿Ñ€Ð¸ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ðµ Ð¼Ð¾Ð´ÑƒÐ»Ñ\ninitialize_admin_ids()\n\n# FSM ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²\nclass ReportStates(StatesGroup):\n    waiting_for_period = State()\n    waiting_for_date_range = State()\n    waiting_for_schedule_time = State()\n    waiting_for_chat_id = State()\n\n\ndef is_admin(user_id: int) -> bool:\n    \"\"\"ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð¼.\"\"\"\n    return user_id in ADMIN_IDS\n\n\ndef admin_only(handler):\n    \"\"\"Ð”ÐµÐºÐ¾Ñ€Ð°Ñ‚Ð¾Ñ€ Ð´Ð»Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð².\"\"\"\n    async def wrapper(message: Message, *args, **kwargs):\n        if not is_admin(message.from_user.id):\n            await message.reply(\n                \"âŒ Ð£ Ð²Ð°Ñ Ð½ÐµÑ‚ Ð¿Ñ€Ð°Ð² Ð´Ð»Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹.\\n\"\n                \"Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ñ€Ð°Ð·Ñ€ÐµÑˆÑ‘Ð½ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°Ð¼.\"\n            )\n            return\n        return await handler(message, *args, **kwargs)\n    return wrapper\n\n\n@commands_router.message(CommandStart())\nasync def handle_start(message: Message):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /start.\"\"\"\n    user = message.from_user\n    \n    welcome_text = f\"\"\"\nðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚, {user.first_name}!\n\nðŸ¤– Ð¯ Ð±Ð¾Ñ‚ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð² Telegram Ñ‡Ð°Ñ‚Ð°Ñ… Ð¸ ÐºÐ°Ð½Ð°Ð»Ð°Ñ….\n\nðŸ“Š **Ð§Ñ‚Ð¾ Ñ ÑƒÐ¼ÐµÑŽ:**\nâ€¢ ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸/Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ¸ Ð¾Ñ‚ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²\nâ€¢ ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ‚ÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð² Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ñ…\nâ€¢ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð² Excel\nâ€¢ ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÑŽ\n\nðŸ“‹ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:**\n/help - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð²ÑÐµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹\n/stats - Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ\n/status - ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\n\nðŸ”’ **Ð”Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð²:**\n/report - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n/export - ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n/schedule - ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼\n\nÐ”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð¼ÐµÐ½Ñ Ð² Ð²Ð°ÑˆÐ¸ Ñ‡Ð°Ñ‚Ñ‹ Ð¸ ÐºÐ°Ð½Ð°Ð»Ñ‹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ñ Ð¼Ð¾Ð³ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ñ‚ÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ!\n    \"\"\"\n    \n    await message.reply(welcome_text, parse_mode=\"Markdown\")\n    \n    logger.info(f\"ðŸ‘‹ [Commands] Start command from user {user.id} (@{user.username})\")\n\n\n@commands_router.message(Command(\"help\"))\nasync def handle_help(message: Message):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /help.\"\"\"\n    help_text = \"\"\"\nðŸ“‹ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:**\n\nðŸ‘¤ **Ð”Ð»Ñ Ð²ÑÐµÑ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹:**\n/start - Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð±Ð¾Ñ‚Ðµ\n/help - ÑÑ‚Ð° ÑÐ¿Ñ€Ð°Ð²ÐºÐ°\n/stats [Ð¿ÐµÑ€Ð¸Ð¾Ð´] - ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸\n/status - ÑÑ‚Ð°Ñ‚ÑƒÑ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\n\nðŸ”§ **Ð”Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð²:**\n/report [Ñ‚Ð¸Ð¿] [Ð´Ð°Ñ‚Ð°] - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n  â€¢ daily YYYY-MM-DD - ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n  â€¢ weekly YYYY-MM-DD - ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚  \n  â€¢ monthly YYYY-MM-DD - Ð¼ÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n  â€¢ retention [Ð´Ð½Ð¸] [Ð´Ð°Ñ‚Ð°] - Ð°Ð½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\n\n/export - Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Excel\n\n/schedule - ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸:\n  â€¢ config - Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼Ñ Ð¸ Ñ‡Ð°Ñ‚Ñ‹\n  â€¢ status - ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n  â€¢ test [Ñ‚Ð¸Ð¿] - Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n  â€¢ enable/disable - Ð²ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ/Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ\n\n**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\n`/stats today` - ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° ÑÐµÐ³Ð¾Ð´Ð½Ñ\n`/report daily 2024-01-15` - Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° 15 ÑÐ½Ð²Ð°Ñ€Ñ\n`/schedule config 09:00` - Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð½Ð° 9:00\n    \"\"\"\n    \n    await message.reply(help_text, parse_mode=\"Markdown\")\n\n\n@commands_router.message(Command(\"stats\"))\nasync def handle_stats(message: Message):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /stats Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸.\"\"\"\n    try:\n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹\n        args = message.text.split()[1:] if len(message.text.split()) > 1 else [\"today\"]\n        period = args[0].lower()\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¿ÐµÑ€Ð¸Ð¾Ð´ Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸\n        now = get_almaty_now()\n        \n        if period == \"today\":\n            start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)\n            end_date = now\n            period_name = \"ÑÐµÐ³Ð¾Ð´Ð½Ñ\"\n        elif period == \"yesterday\":\n            yesterday = now - timedelta(days=1)\n            start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)\n            end_date = yesterday.replace(hour=23, minute=59, second=59, microsecond=999999)\n            period_name = \"Ð²Ñ‡ÐµÑ€Ð°\"\n        elif period == \"week\":\n            week_start = now - timedelta(days=now.weekday())\n            start_date = week_start.replace(hour=0, minute=0, second=0, microsecond=0)\n            end_date = now\n            period_name = \"Ð·Ð° ÑÑ‚Ñƒ Ð½ÐµÐ´ÐµÐ»ÑŽ\"\n        elif period == \"month\":\n            month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n            start_date = month_start\n            end_date = now\n            period_name = \"Ð·Ð° ÑÑ‚Ð¾Ñ‚ Ð¼ÐµÑÑÑ†\"\n        else:\n            await message.reply(\n                \"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ: today, yesterday, week, month\"\n            )\n            return\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n        db = get_db()\n        events = db.get_events_for_period(\n            start_date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n            end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n        )\n        \n        if not events:\n            await message.reply(f\"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° {period_name}: Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\")\n            return\n        \n        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n        stats = _analyze_events(events)\n        \n        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚\n        stats_text = f\"\"\"\nðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° {period_name}:**\n\nðŸ“ˆ **ÐžÐ±Ñ‰Ð¸Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸:**\nâ€¢ Ð’ÑÐµÐ³Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹: {stats['total_events']}\nâ€¢ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: {stats['unique_users']}\nâ€¢ Ð—Ð°Ñ‚Ñ€Ð¾Ð½ÑƒÑ‚Ð¾ Ñ‡Ð°Ñ‚Ð¾Ð²: {stats['unique_chats']}\n\nðŸ“¢ **ÐšÐ°Ð½Ð°Ð»Ñ‹:**\nâ€¢ ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ¸: {stats['channel_subscribes']}\nâ€¢ ÐžÑ‚Ð¿Ð¸ÑÐºÐ¸: {stats['channel_unsubscribes']}\nâ€¢ Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚: {stats['channel_net_growth']}\n\nðŸ‘¥ **Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹:**  \nâ€¢ ÐŸÑ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ: {stats['group_joins']}\nâ€¢ Ð’Ñ‹Ñ…Ð¾Ð´Ñ‹: {stats['group_leaves']}\nâ€¢ Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚: {stats['group_net_growth']}\n\nðŸ¤– **Ð‘Ð¾Ñ‚:**\nâ€¢ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ Ð² Ñ‡Ð°Ñ‚Ð¾Ð²: {stats['bot_added']}\nâ€¢ Ð£Ð´Ð°Ð»Ñ‘Ð½ Ð¸Ð· Ñ‡Ð°Ñ‚Ð¾Ð²: {stats['bot_removed']}\n\nâ° **ÐŸÐµÑ€Ð¸Ð¾Ð´:** {format_datetime_for_report(start_date)} - {format_datetime_for_report(end_date)}\n        \"\"\"\n        \n        await message.reply(stats_text, parse_mode=\"Markdown\")\n        \n        logger.info(f\"ðŸ“Š [Commands] Stats request from user {message.from_user.id} for period {period}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling stats command: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.\")\n\n\n@commands_router.message(Command(\"status\"))\nasync def handle_status(message: Message):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /status Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹.\"\"\"\n    try:\n        db = get_db()\n        \n        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº Ð‘Ð”\n        try:\n            db.get_user_stats_summary()\n            db_status = \"âœ… ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°\"\n        except Exception as e:\n            db_status = f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)[:50]}...\"\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾Ð±Ñ‰ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ\n        now = get_almaty_now()\n        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)\n        \n        try:\n            today_events = db.get_events_for_period(\n                today_start.strftime(\"%Y-%m-%d %H:%M:%S\"),\n                now.strftime(\"%Y-%m-%d %H:%M:%S\")\n            )\n            events_today = len(today_events) if today_events else 0\n        except:\n            events_today = \"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾\"\n        \n        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n        scheduler = get_scheduler()\n        if scheduler:\n            config = scheduler.config\n            if scheduler.running and config.enabled:\n                scheduler_status = f\"âœ… Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ (Ð²Ñ€ÐµÐ¼Ñ: {config.report_time.strftime('%H:%M')}, Ñ‡Ð°Ñ‚Ð¾Ð²: {len(config.target_chats)})\"\n            elif config.enabled:\n                scheduler_status = \"âš ï¸ Ð’ÐºÐ»ÑŽÑ‡Ñ‘Ð½, Ð½Ð¾ Ð½Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½\"\n            else:\n                scheduler_status = \"âŒ Ð’Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½\"\n        else:\n            scheduler_status = \"âŒ ÐÐµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\"\n        \n        status_text = f\"\"\"\nðŸ”§ **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹:**\n\nðŸ’¾ **Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…:** {db_status}\nðŸ“Š **Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ ÑÐµÐ³Ð¾Ð´Ð½Ñ:** {events_today}\nâ° **ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº:** {scheduler_status}\n\nâ° **Ð’Ñ€ÐµÐ¼Ñ ÑÐµÑ€Ð²ÐµÑ€Ð°:** {format_datetime_for_report(now)}\nðŸŒ **Ð§Ð°ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ð¾ÑÑ:** ÐœÐ¾ÑÐºÐ²Ð° (UTC+3)\n\nðŸ’¡ **Ð’ÐµÑ€ÑÐ¸Ñ:** 1.0.0\nðŸ¤– **Ð‘Ð¾Ñ‚ ID:** {message.bot.id}\n        \"\"\"\n        \n        await message.reply(status_text, parse_mode=\"Markdown\")\n        \n        logger.info(f\"ðŸ”§ [Commands] Status request from user {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling status command: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹.\")\n\n\n@commands_router.message(Command(\"report\"))\n@admin_only\nasync def handle_report(message: Message, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /report Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n    try:\n        args = message.text.split()[1:]\n        \n        if not args:\n            # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\n            keyboard = InlineKeyboardMarkup(inline_keyboard=[\n                [\n                    InlineKeyboardButton(text=\"ðŸ“… Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹\", callback_data=\"report_daily\"),\n                    InlineKeyboardButton(text=\"ðŸ“Š Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹\", callback_data=\"report_weekly\")\n                ],\n                [\n                    InlineKeyboardButton(text=\"ðŸ“ˆ ÐœÐµÑÑÑ‡Ð½Ñ‹Ð¹\", callback_data=\"report_monthly\"),\n                    InlineKeyboardButton(text=\"ðŸ”„ Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ\", callback_data=\"report_retention\")\n                ]\n            ])\n            \n            await message.reply(\n                \"ðŸ“‹ **Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²**\\n\\n\"\n                \"Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° Ð¸Ð»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ:\\n\"\n                \"`/report [Ñ‚Ð¸Ð¿] [Ð´Ð°Ñ‚Ð°]`\\n\\n\"\n                \"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:\\n\"\n                \"â€¢ `/report daily 2024-01-15`\\n\"\n                \"â€¢ `/report weekly 2024-01-08`\\n\"\n                \"â€¢ `/report monthly 2024-01-01`\\n\"\n                \"â€¢ `/report retention 7 2024-01-15`\",\n                reply_markup=keyboard,\n                parse_mode=\"Markdown\"\n            )\n            return\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹\n        report_type = args[0].lower()\n        \n        if report_type not in [\"daily\", \"weekly\", \"monthly\", \"retention\"]:\n            await message.reply(\n                \"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°. Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹: daily, weekly, monthly, retention\"\n            )\n            return\n        \n        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ñƒ\n        target_date = None\n        retention_days = 7\n        \n        if len(args) > 1:\n            if report_type == \"retention\" and len(args) > 2:\n                try:\n                    retention_days = int(args[1])\n                    target_date = args[2]\n                except ValueError:\n                    await message.reply(\"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ: /report retention [Ð´Ð½Ð¸] [Ð´Ð°Ñ‚Ð°]\")\n                    return\n            else:\n                target_date = args[1]\n        \n        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n        await _generate_and_send_report(message, report_type, target_date, retention_days)\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling report command: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.\")\n\n\n@commands_router.message(Command(\"export\"))\n@admin_only\nasync def handle_export(message: Message, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /export Ð´Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð‘Ð”.\"\"\"\n    try:\n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ðµ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°\n        status_msg = await message.reply(\"â³ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…...\")\n        \n        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚\n        db = get_db()\n        report_manager = ReportManager(db)\n        file_path = report_manager.export_full_database()\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»\n        file_path_obj = Path(file_path)\n        if not file_path_obj.exists():\n            await message.reply(\"âŒ Ð¤Ð°Ð¹Ð» ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\")\n            return\n            \n        document = FSInputFile(file_path_obj, filename=file_path_obj.name)\n        await message.bot.send_document(\n            chat_id=message.chat.id,\n            document=document,\n            caption=f\"ðŸ“ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\\n\"\n                   f\"ðŸ• Ð¡Ð¾Ð·Ð´Ð°Ð½: {format_datetime_for_report(get_almaty_now())}\"\n        )\n        \n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐµ\n        await status_msg.delete()\n        \n        logger.info(f\"ðŸ“ [Commands] Database export sent to user {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling export command: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.\")\n\n\n@commands_router.message(Command(\"schedule\"))\n@admin_only  \nasync def handle_schedule(message: Message, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /schedule Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼.\"\"\"\n    try:\n        args = message.text.split()[1:] if len(message.text.split()) > 1 else []\n        \n        if not args:\n            # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ Ð¿Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ\n            help_text = \"\"\"\nâ° **Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²**\n\nðŸ“‹ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:**\nâ€¢ `/schedule status` - ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\nâ€¢ `/schedule config [Ð²Ñ€ÐµÐ¼Ñ] [Ñ‡Ð°Ñ‚Ñ‹]` - Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ\nâ€¢ `/schedule enable` - Ð²ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\nâ€¢ `/schedule disable` - Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\nâ€¢ `/schedule test [Ñ‚Ð¸Ð¿]` - Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n\n**ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹:**\nâ€¢ `/schedule config 09:00` - Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð½Ð° 9:00\nâ€¢ `/schedule test daily` - Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n            \"\"\"\n            await message.reply(help_text, parse_mode=\"Markdown\")\n            return\n        \n        command = args[0].lower()\n        \n        if command == \"status\":\n            await _handle_schedule_status(message)\n        elif command == \"config\":\n            await _handle_schedule_config(message, args[1:] if len(args) > 1 else [])\n        elif command == \"enable\":\n            await _handle_schedule_enable(message)\n        elif command == \"disable\":\n            await _handle_schedule_disable(message)\n        elif command == \"test\":\n            report_type = args[1] if len(args) > 1 else \"daily\"\n            await _handle_schedule_test(message, report_type)\n        else:\n            await message.reply(\n                \"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ `/schedule` Ð´Ð»Ñ ÑÐ¿Ñ€Ð°Ð²ÐºÐ¸.\",\n                parse_mode=\"Markdown\"\n            )\n            \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling schedule command: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.\")\n\n\n@commands_router.callback_query(F.data.startswith(\"report_\"))\nasync def handle_report_callback(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð½Ð°Ð¶Ð°Ñ‚Ð¸Ð¹ Ð½Ð° ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        report_type = callback.data.split(\"_\")[1]\n        \n        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ Ð´Ð°Ñ‚Ð¾Ð¹ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ\n        await _generate_and_send_report(callback.message, report_type)\n        \n        await callback.answer(\"âœ… Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚...\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error handling report callback: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\", show_alert=True)\n\n\nasync def _generate_and_send_report(message: Message, report_type: str, \n                                  target_date: Optional[str] = None,\n                                  retention_days: int = 7):\n    \"\"\"\n    Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ.\n    \n    Args:\n        message: Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°\n        report_type: Ð¢Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° (daily, weekly, monthly, retention)\n        target_date: Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð´Ð°Ñ‚Ð° (YYYY-MM-DD)\n        retention_days: Ð”Ð½Ð¸ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\n    \"\"\"\n    status_msg = None\n    try:\n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ðµ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸\n        status_msg = await message.reply(f\"â³ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚...\")\n        \n        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n        db = get_db()\n        report_manager = ReportManager(db)\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð°Ñ‚Ñƒ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð°\n        if not target_date:\n            now = get_almaty_now()\n            if report_type == \"daily\":\n                yesterday = now - timedelta(days=1)\n                target_date = yesterday.strftime(\"%Y-%m-%d\")\n            elif report_type == \"weekly\":\n                days_since_monday = now.weekday()\n                last_monday = now - timedelta(days=days_since_monday + 7)\n                target_date = last_monday.strftime(\"%Y-%m-%d\")\n            elif report_type == \"monthly\":\n                if now.month == 1:\n                    last_month = now.replace(year=now.year - 1, month=12, day=1)\n                else:\n                    last_month = now.replace(month=now.month - 1, day=1)\n                target_date = last_month.strftime(\"%Y-%m-%d\")\n            else:  # retention\n                yesterday = now - timedelta(days=1)\n                target_date = yesterday.strftime(\"%Y-%m-%d\")\n        \n        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\n        file_path = None\n        caption = None\n        \n        if report_type == \"daily\":\n            result = report_manager.generate_daily_report(target_date)\n            file_path = result.get('excel_file')\n            caption = f\"ðŸ“… Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {target_date}\"\n        elif report_type == \"weekly\":\n            result = report_manager.generate_weekly_report(target_date)\n            file_path = result.get('excel_file')\n            caption = f\"ðŸ“Š Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {target_date}\"\n        elif report_type == \"monthly\":\n            result = report_manager.generate_monthly_report(target_date)\n            file_path = result.get('excel_file')\n            caption = f\"ðŸ“ˆ ÐœÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {target_date}\"\n        elif report_type == \"retention\":\n            result = report_manager.generate_retention_report(retention_days, target_date)\n            file_path = result.get('excel_file')\n            caption = f\"ðŸ”„ ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ ({retention_days} Ð´Ð½ÐµÐ¹) Ð·Ð° {target_date}\"\n        else:\n            await status_msg.edit_text(\"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n            return\n        \n        if not file_path:\n            await status_msg.edit_text(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ\")\n            return\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»\n        file_path_obj = Path(str(file_path))\n        if not file_path_obj.exists():\n            await status_msg.edit_text(\"âŒ Ð¤Ð°Ð¹Ð» Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\")\n            return\n            \n        document = FSInputFile(file_path_obj, filename=file_path_obj.name)\n        await message.bot.send_document(\n            chat_id=message.chat.id,\n            document=document,\n            caption=f\"{caption}\\nðŸ• Ð¡Ð¾Ð·Ð´Ð°Ð½: {format_datetime_for_report(get_almaty_now())}\"\n        )\n        \n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÐµ\n        await status_msg.delete()\n        \n        logger.info(f\"ðŸ“‹ [Commands] {report_type.title()} report sent to user {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error generating {report_type} report: {e}\")\n        if status_msg:\n            try:\n                await status_msg.edit_text(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n            except Exception:\n                await message.reply(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n        else:\n            await message.reply(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n\n\ndef _analyze_events(events: List[dict]) -> dict:\n    \"\"\"\n    ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð¸ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ.\n    \n    Args:\n        events: Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð¸Ð· Ð‘Ð”\n        \n    Returns:\n        dict: Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¾ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¾Ð¹\n    \"\"\"\n    stats = {\n        'total_events': len(events),\n        'unique_users': len(set(event['user_id'] for event in events)),\n        'unique_chats': len(set(event['chat_id'] for event in events)),\n        'channel_subscribes': 0,\n        'channel_unsubscribes': 0,\n        'group_joins': 0,\n        'group_leaves': 0,\n        'bot_added': 0,\n        'bot_removed': 0,\n    }\n    \n    for event in events:\n        event_type = event['event_type']\n        \n        if event_type == 'channel_subscribe':\n            stats['channel_subscribes'] += 1\n        elif event_type == 'channel_unsubscribe':\n            stats['channel_unsubscribes'] += 1\n        elif event_type == 'group_join':\n            stats['group_joins'] += 1\n        elif event_type == 'group_leave':\n            stats['group_leaves'] += 1\n        elif event_type == 'bot_added':\n            stats['bot_added'] += 1\n        elif event_type == 'bot_removed':\n            stats['bot_removed'] += 1\n    \n    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚\n    stats['channel_net_growth'] = stats['channel_subscribes'] - stats['channel_unsubscribes']\n    stats['group_net_growth'] = stats['group_joins'] - stats['group_leaves']\n    \n    return stats\n\n\ndef configure_admin_ids(admin_ids: List[int]):\n    \"\"\"ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº ID Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð².\"\"\"\n    global ADMIN_IDS\n    ADMIN_IDS = admin_ids\n    logger.info(f\"ðŸ”§ [Commands] Configured {len(admin_ids)} admin IDs\")\n\n\nasync def _handle_schedule_status(message: Message) -> None:\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /schedule status.\"\"\"\n    scheduler = get_scheduler()\n    \n    if not scheduler:\n        await message.reply(\"âŒ ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\")\n        return\n    \n    config = scheduler.config\n    status_text = f\"\"\"\nðŸ•’ **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ° Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²:**\n\nðŸ“Š **Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ:** {'âœ… Ð’ÐºÐ»ÑŽÑ‡Ñ‘Ð½' if config.enabled else 'âŒ Ð’Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½'}\nâ° **Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸:** {config.report_time.strftime('%H:%M')} (ÐœÐ¡Ðš)\nðŸ“¨ **Ð¦ÐµÐ»ÐµÐ²Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹:** {len(config.target_chats)} ÑˆÑ‚.\nðŸ“‹ **Ð¢Ð¸Ð¿Ñ‹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²:** {', '.join(config.report_types)}\nðŸ”„ **Ð—Ð°Ð¿ÑƒÑ‰ÐµÐ½:** {'âœ… Ð”Ð°' if scheduler.running else 'âŒ ÐÐµÑ‚'}\n\nðŸ’¡ **Ð§Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸:**\n{chr(10).join([f'â€¢ {chat_id}' for chat_id in config.target_chats]) if config.target_chats else 'â€¢ ÐÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹'}\n    \"\"\"\n    \n    await message.reply(status_text, parse_mode=\"Markdown\")\n\n\nasync def _handle_schedule_config(message: Message, args: List[str]) -> None:\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /schedule config.\"\"\"\n    scheduler = get_scheduler()\n    \n    if not scheduler:\n        await message.reply(\"âŒ ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\")\n        return\n    \n    try:\n        if not args:\n            # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ\n            config = scheduler.config\n            config_text = f\"\"\"\nâš™ï¸ **Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ:**\n\nâ° **Ð’Ñ€ÐµÐ¼Ñ:** {config.report_time.strftime('%H:%M')} (ÐœÐ¡Ðš)\nðŸ“¨ **Ð§Ð°Ñ‚Ñ‹:** {', '.join(map(str, config.target_chats)) if config.target_chats else 'ÐÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹'}\nðŸ“‹ **Ð¢Ð¸Ð¿Ñ‹:** {', '.join(config.report_types)}\n\n**Ð”Ð»Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ:**\n`/schedule config [Ð²Ñ€ÐµÐ¼Ñ] [chat_id1,chat_id2,...]`\n            \"\"\"\n            await message.reply(config_text, parse_mode=\"Markdown\")\n            return\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð²Ñ€ÐµÐ¼Ñ\n        time_str = args[0]\n        try:\n            from datetime import time\n            hour, minute = map(int, time_str.split(':'))\n            report_time = time(hour, minute)\n        except ValueError:\n            await message.reply(\"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ HH:MM (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 09:00)\")\n            return\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ‡Ð°Ñ‚Ñ‹ ÐµÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹\n        target_chats = []\n        if len(args) > 1:\n            try:\n                chat_ids_str = args[1]\n                target_chats = [int(chat_id.strip()) for chat_id in chat_ids_str.split(',') if chat_id.strip()]\n            except ValueError:\n                await message.reply(\"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ID Ñ‡Ð°Ñ‚Ð¾Ð². Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð° Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ\")\n                return\n        else:\n            # Ð•ÑÐ»Ð¸ Ñ‡Ð°Ñ‚Ñ‹ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ñ‡Ð°Ñ‚\n            target_chats = [message.chat.id]\n        \n        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ\n        await scheduler.configure(\n            report_time=report_time,\n            target_chats=target_chats\n        )\n        \n        await message.reply(\n            f\"âœ… ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½:\\n\"\n            f\"â° Ð’Ñ€ÐµÐ¼Ñ: {report_time.strftime('%H:%M')} (ÐœÐ¡Ðš)\\n\"\n            f\"ðŸ“¨ Ð§Ð°Ñ‚Ñ‹: {', '.join(map(str, target_chats))}\",\n            parse_mode=\"Markdown\"\n        )\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error configuring scheduler: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\")\n\n\nasync def _handle_schedule_enable(message: Message) -> None:\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /schedule enable.\"\"\"\n    scheduler = get_scheduler()\n    \n    if not scheduler:\n        await message.reply(\"âŒ ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\")\n        return\n    \n    try:\n        await scheduler.configure(enabled=True)\n        await scheduler.start()\n        await message.reply(\"âœ… ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð²ÐºÐ»ÑŽÑ‡Ñ‘Ð½\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error enabling scheduler: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\")\n\n\nasync def _handle_schedule_disable(message: Message) -> None:\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /schedule disable.\"\"\"\n    scheduler = get_scheduler()\n    \n    if not scheduler:\n        await message.reply(\"âŒ ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\")\n        return\n    \n    try:\n        await scheduler.configure(enabled=False)\n        await scheduler.stop()\n        await message.reply(\"âœ… ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð²Ñ‹ÐºÐ»ÑŽÑ‡Ñ‘Ð½\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error disabling scheduler: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\")\n\n\nasync def _handle_schedule_test(message: Message, report_type: str) -> None:\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /schedule test.\"\"\"\n    scheduler = get_scheduler()\n    \n    if not scheduler:\n        await message.reply(\"âŒ ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½\")\n        return\n    \n    if report_type not in [\"daily\", \"weekly\", \"monthly\"]:\n        await message.reply(\"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ: daily, weekly, monthly\")\n        return\n    \n    try:\n        status_msg = await message.reply(f\"â³ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚...\")\n        \n        success = await scheduler.send_test_report(message.chat.id, report_type)\n        \n        if success:\n            await status_msg.edit_text(f\"âœ… Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½\")\n        else:\n            await status_msg.edit_text(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n            \n    except Exception as e:\n        logger.exception(f\"âŒ [Commands] Error sending test report: {e}\")\n        await message.reply(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ {report_type} Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\")\n\n\n@commands_router.message(Command(\"create_test_data\"))\n@admin_only\nasync def handle_create_test_data(message: Message):\n    \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Excel Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°.\"\"\"\n    try:\n        db = get_db()\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹ Ñ username ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n        vadim_id = db.upsert_inviter(name=\"Vadim\", username=\"@vadim\")\n        anel_id = db.upsert_inviter(name=\"Anel\", username=\"@anel\") \n        petr_id = db.upsert_inviter(name=\"Petr\", username=\"@petr\")\n        \n        # Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n        test_events = [\n            # Alex Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð»ÑÑ Ñ‡ÐµÑ€ÐµÐ· Vadim, Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¾Ñ‚Ð¿Ð¸ÑÐ°Ð»ÑÑ\n            {'event_type': 'subscribe', 'tg_user_id': 1234567, 'username': '@alex', 'name': 'Alex Ivanov', 'inviter_id': vadim_id, 'status': 'subscribed'},\n            {'event_type': 'unsubscribe', 'tg_user_id': 1234567, 'username': '@alex', 'name': 'Alex Ivanov', 'inviter_id': vadim_id, 'status': 'left'},\n            \n            # Maria Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð»Ð°ÑÑŒ Ñ‡ÐµÑ€ÐµÐ· Anel Ð¸ Ð¾ÑÑ‚Ð°Ð»Ð°ÑÑŒ  \n            {'event_type': 'subscribe', 'tg_user_id': 7654321, 'username': '@masha', 'name': 'Maria Petrova', 'inviter_id': anel_id, 'status': 'subscribed'},\n            \n            # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸\n            {'event_type': 'subscribe', 'tg_user_id': 1111111, 'username': '@ivan', 'name': 'Ivan Petrov', 'inviter_id': vadim_id, 'status': 'subscribed'},\n            {'event_type': 'subscribe', 'tg_user_id': 2222222, 'username': '@elena', 'name': 'Elena Sidorova', 'inviter_id': petr_id, 'status': 'subscribed'},\n            {'event_type': 'subscribe', 'tg_user_id': 3333333, 'username': '@dmitry', 'name': 'Dmitry Volkov', 'inviter_id': anel_id, 'status': 'subscribed'},\n        ]\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð² Ð¶ÑƒÑ€Ð½Ð°Ð»\n        for event in test_events:\n            db.insert_journal_event(\n                event_type=event['event_type'],\n                tg_user_id=event['tg_user_id'],\n                username=event['username'],\n                name=event['name'],\n                inviter_id=event['inviter_id'],\n                status=event['status']\n            )\n        \n        await message.answer(\n            f\"âœ… Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹!\\n\\n\"\n            f\"ðŸ“Š Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾:\\n\"\n            f\"â€¢ 3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ñ username (@vadim, @anel, @petr)\\n\" \n            f\"â€¢ {len(test_events)} ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\\n\\n\"\n            f\"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ /unified_report Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Excel Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°\"\n        )\n        \n    except Exception as e:\n        logger.exception(f\"Error creating test data: {e}\")\n        await message.answer(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {str(e)}\")\n\n\n@commands_router.message(Command(\"unified_report\"))\n@admin_only\nasync def handle_unified_report(message: Message):\n    \"\"\"Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ unified Excel Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\"\"\"\n    try:\n        from reports.unified_report_manager import UnifiedReportManager\n        db = get_db()\n        unified_manager = UnifiedReportManager(db)\n        \n        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Excel Ñ„Ð°Ð¹Ð»Ðµ\n        stats = unified_manager.get_stats_summary()\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ\n        stats_text = f\"ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑÐ¼:**\\n\\n\"\n        \n        if stats['inviters_data']:\n            for inviter_data in stats['inviters_data']:\n                stats_text += f\"**{inviter_data['inviter_name']}:**\\n\"\n                stats_text += f\"  â€¢ Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾: {inviter_data['total_invited']}\\n\"\n                stats_text += f\"  â€¢ ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ°Ð½Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ: {inviter_data['currently_subscribed']}\\n\" \n                stats_text += f\"  â€¢ ÐžÑ‚Ð¿Ð¸ÑÐ°Ð»Ð¸ÑÑŒ: {inviter_data['unsubscribed']}\\n\"\n                retention = 0\n                if inviter_data['total_invited'] > 0:\n                    retention = round((inviter_data['currently_subscribed'] / inviter_data['total_invited']) * 100)\n                stats_text += f\"  â€¢ % ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ: {retention}%\\n\\n\"\n        else:\n            stats_text += \"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.\"\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Excel Ñ„Ð°Ð¹Ð»\n        excel_path = unified_manager.export_excel_file()\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÑƒ Ð´Ð»Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ\n        keyboard = InlineKeyboardMarkup(inline_keyboard=[\n            [InlineKeyboardButton(text=\"ðŸ“¤ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel-Ñ„Ð°Ð¹Ð»\", callback_data=\"download_unified_excel\")]\n        ])\n        \n        await message.answer(stats_text, parse_mode=\"Markdown\")\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»\n        if Path(excel_path).exists():\n            document = FSInputFile(excel_path, filename=\"subscribers_report.xlsx\")\n            await message.answer_document(\n                document=document,\n                caption=\"ðŸ“‚ **subscribers_report.xlsx** - Unified Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\\n\\n\"\n                       \"**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**\\n\"\n                       \"â€¢ Ð›Ð¸ÑÑ‚ **Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ** - Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¶ÑƒÑ€Ð½Ð°Ð» ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\\n\" \n                       \"â€¢ Ð›Ð¸ÑÑ‚ **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°** - ÑÐ²Ð¾Ð´ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑÐ¼\\n\"\n                       \"â€¢ Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð»Ð¸ÑÑ‚Ñ‹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ Ð”Ð”-ÐœÐœ-Ð“Ð“Ð“Ð“\",\n                parse_mode=\"Markdown\"\n            )\n        else:\n            await message.answer(\"âŒ Excel Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\")\n            \n    except Exception as e:\n        logger.exception(f\"Error generating unified report: {e}\")\n        await message.answer(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ unified Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°: {str(e)}\")\n\n\n# ===== ÐšÐžÐœÐÐÐ”Ð« Ð£ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð¯ Ð¡Ð¡Ð«Ð›ÐšÐÐœÐ˜ =====\n\n@commands_router.message(Command(\"create_link\"))\n@admin_only\nasync def handle_create_link(message: Message):\n    \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    try:\n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð· Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹\n        args = message.text.split()[1:] if message.text else []\n        if not args:\n            await message.answer(\n                \"âŒ Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ¸.\\n\\n\"\n                \"ðŸ“ **Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:** `/create_link username`\\n\"\n                \"ðŸ“ **ÐŸÑ€Ð¸Ð¼ÐµÑ€:** `/create_link @vadim`\\n\\n\"\n                \"â„¹ï¸ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ TARGET_CHATS Ð´Ð»Ñ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²\",\n                parse_mode=\"Markdown\"\n            )\n            return\n        \n        username = args[0].strip()\n        if not username.startswith('@'):\n            username = f'@{username}'\n        \n        # Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€\n        from utils.adapter import get_invite_manager\n        \n        invite_manager = get_invite_manager()\n        if not invite_manager:\n            await message.answer(\"âŒ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°\")\n            return\n        \n        # Ð£Ð±ÐµÐ¶Ð´Ð°ÐµÐ¼ÑÑ Ñ‡Ñ‚Ð¾ bot instance Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½\n        if not invite_manager.bot:\n            invite_manager.bot = message.bot\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÑÑ‹Ð»ÐºÑƒ\n        invite_link = await invite_manager.create_invite_for(username)\n        \n        await message.answer(\n            f\"âœ… Ð¡ÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð° Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {username}!\\n\\n\"\n            f\"ðŸ”— **Ð¡ÑÑ‹Ð»ÐºÐ°:** `{invite_link}`\\n\\n\"\n            f\"ðŸ“Š Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ /list_links Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð²ÑÐµ ÑÑÑ‹Ð»ÐºÐ¸\",\n            parse_mode=\"Markdown\"\n        )\n        \n    except Exception as e:\n        logger.exception(f\"Error creating invite link: {e}\")\n        await message.answer(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÑÑÑ‹Ð»ÐºÐ¸: {str(e)}\")\n\n\n@commands_router.message(Command(\"delete_link\"))\n@admin_only\nasync def handle_delete_link(message: Message):\n    \"\"\"Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ.\"\"\"\n    try:\n        args = message.text.split()[1:] if message.text else []\n        if not args:\n            await message.answer(\n                \"âŒ Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ ID ÑÑÑ‹Ð»ÐºÐ¸ Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ.\\n\\n\"\n                \"ðŸ“ **Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ:** `/delete_link ID`\\n\"\n                \"ðŸ“ **ÐŸÑ€Ð¸Ð¼ÐµÑ€:** `/delete_link 1`\\n\\n\"\n                \"ðŸ“‹ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ `/list_links` Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð²ÑÐµ ID ÑÑÑ‹Ð»Ð¾Ðº\",\n                parse_mode=\"Markdown\"\n            )\n            return\n        \n        try:\n            link_id = int(args[0])\n        except ValueError:\n            await message.answer(\"âŒ ID Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾Ð¼\")\n            return\n        \n        from utils.adapter import get_invite_manager\n        \n        invite_manager = get_invite_manager()\n        if not invite_manager:\n            await message.answer(\"âŒ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°\")\n            return\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÑÑ‹Ð»ÐºÐµ Ð¿ÐµÑ€ÐµÐ´ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸ÐµÐ¼\n        link_info = invite_manager.get_invite_info(link_id)\n        if not link_info:\n            await message.answer(\"âŒ Ð¡ÑÑ‹Ð»ÐºÐ° Ñ Ñ‚Ð°ÐºÐ¸Ð¼ ID Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°\")\n            return\n        \n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑÑ‹Ð»ÐºÑƒ\n        success = invite_manager.delete_invite(link_id)\n        \n        if success:\n            await message.answer(\n                f\"âœ… Ð¡ÑÑ‹Ð»ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð°!\\n\\n\"\n                f\"ðŸ‘¤ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ: {link_info['name']}\\n\"\n                f\"ðŸ”— Ð¡ÑÑ‹Ð»ÐºÐ°: `{link_info['invite_link']}`\",\n                parse_mode=\"Markdown\"\n            )\n        else:\n            await message.answer(\"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ\")\n            \n    except Exception as e:\n        logger.exception(f\"Error deleting invite link: {e}\")\n        await message.answer(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸ ÑÑÑ‹Ð»ÐºÐ¸: {str(e)}\")\n\n\n@commands_router.message(Command(\"list_links\"))\n@admin_only\nasync def handle_list_links(message: Message):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑÑ‹Ð»ÐºÐ¸.\"\"\"\n    try:\n        from utils.adapter import get_invite_manager\n        \n        invite_manager = get_invite_manager()\n        if not invite_manager:\n            await message.answer(\"âŒ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°\")\n            return\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ ÑÑÑ‹Ð»ÐºÐ¸\n        invites = invite_manager.get_invites()\n        \n        if not invites:\n            await message.answer(\n                \"ðŸ“ **Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº Ð¿ÑƒÑÑ‚**\\n\\n\"\n                \"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ `/create_link username` Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ¸\",\n                parse_mode=\"Markdown\"\n            )\n            return\n        \n        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ\n        response = \"ðŸ“‹ **Ð’ÑÐµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑÑ‹Ð»ÐºÐ¸:**\\n\\n\"\n        \n        for invite in invites:\n            response += f\"**ID {invite['id']}** - {invite['name']}\\n\"\n            response += f\"ðŸ”— `{invite['invite_link']}`\\n\"\n            response += f\"ðŸ“Š ÐŸÑ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾: {invite.get('total_invited', 0)}, \"\n            response += f\"ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ…: {invite.get('active_now', 0)}\\n\\n\"\n        \n        response += \"ðŸ’¡ **ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸:**\\n\"\n        response += \"â€¢ `/create_link @username` - ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\\n\"\n        response += \"â€¢ `/delete_link ID` - ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ Ð¿Ð¾ ID\\n\" \n        response += \"â€¢ `/list_links` - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð²ÑÐµ ÑÑÑ‹Ð»ÐºÐ¸ Ñ ID Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¾Ð¹\"\n        \n        await message.answer(response, parse_mode=\"Markdown\")\n        \n    except Exception as e:\n        logger.exception(f\"Error listing invite links: {e}\")\n        await message.answer(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ ÑÐ¿Ð¸ÑÐºÐ° ÑÑÑ‹Ð»Ð¾Ðº: {str(e)}\")\n\n\n# Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð° Ð´Ð»Ñ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸\n__all__ = ['commands_router', 'configure_admin_ids', 'initialize_scheduler']","size_bytes":46246},"bot_project/handlers/events.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Telegram Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ Ð² Ñ‡Ð°Ñ‚Ð°Ñ….\n\nÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚:\n- ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ¸/Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ¸ Ð¾Ñ‚ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²\n- Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð²Ð°Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ñ‡Ð°Ñ‚Ð¾Ð²  \n- Ð’Ñ…Ð¾Ð´/Ð²Ñ‹Ñ…Ð¾Ð´ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð² Ð¸Ð· Ð³Ñ€ÑƒÐ¿Ð¿\n- Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ/ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ñ‡Ð°Ñ‚Ð¾Ð²\n\"\"\"\n\nimport logging\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, Any\n\nfrom aiogram import Router, F\nfrom aiogram.types import (\n    ChatMemberUpdated, \n    ChatMemberOwner, \n    ChatMemberAdministrator,\n    ChatMemberMember, \n    ChatMemberRestricted,\n    ChatMemberLeft, \n    ChatMemberBanned\n)\nfrom aiogram.enums import ChatType, ChatMemberStatus\n\nfrom db.db import get_db\nfrom utils.time_utils import get_almaty_now\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n# Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ€Ð¾ÑƒÑ‚ÐµÑ€ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¾Ð² ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\nevents_router = Router(name=\"events\")\n\n\n@events_router.chat_member()\nasync def handle_chat_member_update(chat_member: ChatMemberUpdated):\n    \"\"\"\n    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð² Ñ‡Ð°Ñ‚Ð°.\n    \n    ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚:\n    - ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ¸/Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ¸ Ð¾Ñ‚ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²\n    - Ð’Ñ…Ð¾Ð´/Ð²Ñ‹Ñ…Ð¾Ð´ Ð¸Ð· Ð³Ñ€ÑƒÐ¿Ð¿\n    - Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð°Ð² ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²\n    - Ð‘Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¸/Ñ€Ð°Ð·Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¸\n    \"\"\"\n    try:\n        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ\n        chat = chat_member.chat\n        user = chat_member.new_chat_member.user\n        old_status = chat_member.old_chat_member.status\n        new_status = chat_member.new_chat_member.status\n        \n        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ñ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹\n        chat_type_str = chat.type.value if hasattr(chat.type, 'value') else str(chat.type)\n        logger.info(f\"ðŸ“ [Events] Chat member update: chat_id={chat.id}, chat_type={chat_type_str}, \"\n                   f\"user_id={user.id}, old_status={old_status}, new_status={new_status}\")\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ invite_link ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°\n        invite_link = getattr(chat_member, 'invite_link', None)\n        if invite_link:\n            logger.info(f\"ðŸ”— [Events] Invite link detected: {invite_link}\")\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ update_id Ð´Ð»Ñ Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ (Ð±ÐµÐ· fallback Ð½Ð° timestamp)\n        update_id = None\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n        event_type = _determine_event_type(chat.type, old_status, new_status)\n        \n        if not event_type:\n            logger.debug(f\"â­ï¸ [Events] Skipping non-tracked status change: {old_status} â†’ {new_status}\")\n            return\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸Ð· invite_link\n        inviter_id = None\n        if invite_link:\n            try:\n                db = get_db()\n                inviter_id = db.get_inviter_by_link(invite_link)\n                if inviter_id:\n                    logger.info(f\"ðŸ‘¤ [Events] Found inviter_id={inviter_id} for link: {invite_link}\")\n                else:\n                    logger.warning(f\"âš ï¸ [Events] No inviter found for link: {invite_link}\")\n            except Exception as e:\n                logger.error(f\"âŒ [Events] Error finding inviter for link {invite_link}: {e}\")\n\n        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² Ð‘Ð”\n        event_data = {\n            'telegram_update_id': update_id,\n            'chat_id': chat.id,\n            'chat_title': chat.title or chat.username or f\"Chat_{chat.id}\",\n            'chat_type': chat_type_str,\n            'user_id': user.id,\n            'username': user.username,\n            'first_name': user.first_name,\n            'last_name': user.last_name,\n            'event_type': event_type,\n            'old_status': old_status.value if hasattr(old_status, 'value') else str(old_status),\n            'new_status': new_status.value if hasattr(new_status, 'value') else str(new_status),\n            'timestamp': get_almaty_now(),\n            'is_bot': user.is_bot,\n            'raw_data': {\n                'chat': {\n                    'id': chat.id,\n                    'type': chat_type_str,\n                    'title': chat.title,\n                    'username': chat.username,\n                    'description': getattr(chat, 'description', None),\n                },\n                'user': {\n                    'id': user.id,\n                    'username': user.username,\n                    'first_name': user.first_name,\n                    'last_name': user.last_name,\n                    'is_bot': user.is_bot,\n                    'language_code': getattr(user, 'language_code', None),\n                },\n                'status_change': {\n                    'old': old_status.value if hasattr(old_status, 'value') else str(old_status),\n                    'new': new_status.value if hasattr(new_status, 'value') else str(new_status),\n                    'date': chat_member.date.isoformat() if chat_member.date else None,\n                }\n            }\n        }\n        \n        # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n        if 'db' not in locals():\n            db = get_db()\n        db.insert_journal_event(\n            event_type=event_type,\n            tg_user_id=user.id,\n            username=user.username,\n            name=user.first_name,\n            status=new_status.value if hasattr(new_status, 'value') else str(new_status),\n            telegram_update_id=update_id,\n            inviter_id=inviter_id\n        )\n        \n        logger.info(f\"âœ… [Events] Recorded {event_type} event: \"\n                   f\"chat_id={chat.id}, user_id={user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Events] Error handling chat member update: {e}\")\n\n\n@events_router.my_chat_member()\nasync def handle_bot_chat_member_update(my_chat_member: ChatMemberUpdated):\n    \"\"\"\n    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð±Ð¾Ñ‚Ð° Ð² Ñ‡Ð°Ñ‚Ð°Ñ….\n    \n    ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚ ÐºÐ¾Ð³Ð´Ð° Ð±Ð¾Ñ‚Ð°:\n    - Ð”Ð¾Ð±Ð°Ð²Ð»ÑÑŽÑ‚ Ð² Ñ‡Ð°Ñ‚\n    - Ð£Ð´Ð°Ð»ÑÑŽÑ‚ Ð¸Ð· Ñ‡Ð°Ñ‚Ð°\n    - Ð˜Ð·Ð¼ÐµÐ½ÑÑŽÑ‚ ÐµÐ³Ð¾ Ð¿Ñ€Ð°Ð²Ð°\n    - Ð‘Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‚/Ñ€Ð°Ð·Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑŽÑ‚\n    \"\"\"\n    try:\n        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ\n        chat = my_chat_member.chat\n        bot_user = my_chat_member.new_chat_member.user\n        old_status = my_chat_member.old_chat_member.status\n        new_status = my_chat_member.new_chat_member.status\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ update_id Ð´Ð»Ñ Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ timestamp ÐºÐ°Ðº fallback)\n        update_id = getattr(my_chat_member, 'update_id', None) or int(get_almaty_now().timestamp())\n        \n        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ\n        logger.info(f\"ðŸ¤– [Events] Bot status update: chat_id={chat.id}, \"\n                   f\"old_status={old_status}, new_status={new_status}\")\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ Ð±Ð¾Ñ‚Ð°\n        event_type = _determine_bot_event_type(chat.type, old_status, new_status)\n        \n        if not event_type:\n            logger.debug(f\"â­ï¸ [Events] Skipping non-tracked bot status change: {old_status} â†’ {new_status}\")\n            return\n        \n        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² Ð‘Ð”\n        event_data = {\n            'telegram_update_id': update_id,\n            'chat_id': chat.id,\n            'chat_title': chat.title or chat.username or f\"Chat_{chat.id}\",\n            'chat_type': chat_type_str,\n            'user_id': bot_user.id,\n            'username': bot_user.username,\n            'first_name': bot_user.first_name,\n            'last_name': bot_user.last_name,\n            'event_type': event_type,\n            'old_status': old_status.value if hasattr(old_status, 'value') else str(old_status),\n            'new_status': new_status.value if hasattr(new_status, 'value') else str(new_status),\n            'timestamp': get_almaty_now(),\n            'is_bot': True,\n            'raw_data': {\n                'chat': {\n                    'id': chat.id,\n                    'type': chat_type_str,\n                    'title': chat.title,\n                    'username': chat.username,\n                    'description': getattr(chat, 'description', None),\n                },\n                'bot': {\n                    'id': bot_user.id,\n                    'username': bot_user.username,\n                    'first_name': bot_user.first_name,\n                    'last_name': bot_user.last_name,\n                    'is_bot': True,\n                },\n                'status_change': {\n                    'old': old_status.value if hasattr(old_status, 'value') else str(old_status),\n                    'new': new_status.value if hasattr(new_status, 'value') else str(new_status),\n                    'date': my_chat_member.date.isoformat() if my_chat_member.date else None,\n                }\n            }\n        }\n        \n        # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n        db = get_db()\n        db.insert_journal_event(\n            event_type=event_type,\n            tg_user_id=bot_user.id,\n            username=bot_user.username,\n            name=bot_user.first_name,\n            status=new_status.value if hasattr(new_status, 'value') else str(new_status),\n            telegram_update_id=update_id\n        )\n        \n        logger.info(f\"âœ… [Events] Recorded bot {event_type} event: chat_id={chat.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Events] Error handling bot chat member update: {e}\")\n\n\ndef _determine_event_type(chat_type: ChatType, old_status: ChatMemberStatus, \n                         new_status: ChatMemberStatus) -> Optional[str]:\n    \"\"\"\n    ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ñ‚Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚Ð¸Ð¿Ð° Ñ‡Ð°Ñ‚Ð° Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ°.\n    \n    Args:\n        chat_type: Ð¢Ð¸Ð¿ Ñ‡Ð°Ñ‚Ð° (channel, group, supergroup, private)\n        old_status: Ð¡Ñ‚Ð°Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°\n        new_status: ÐÐ¾Ð²Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°\n        \n    Returns:\n        str Ð¸Ð»Ð¸ None: Ð¢Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² Ð‘Ð”\n    \"\"\"\n    # Ð”Ð»Ñ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²\n    if chat_type == ChatType.CHANNEL:\n        if old_status == ChatMemberStatus.LEFT and new_status == ChatMemberStatus.MEMBER:\n            return \"subscribe\"\n        elif old_status == ChatMemberStatus.MEMBER and new_status == ChatMemberStatus.LEFT:\n            return \"unsubscribe\"\n        elif old_status == ChatMemberStatus.MEMBER and new_status == ChatMemberStatus.BANNED:\n            return \"channel_banned\"\n        elif old_status == ChatMemberStatus.BANNED and new_status == ChatMemberStatus.MEMBER:\n            return \"channel_unbanned\"\n    \n    # Ð”Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿ Ð¸ ÑÑƒÐ¿ÐµÑ€Ð³Ñ€ÑƒÐ¿Ð¿\n    elif chat_type in [ChatType.GROUP, ChatType.SUPERGROUP]:\n        if old_status == ChatMemberStatus.LEFT and new_status in [\n            ChatMemberStatus.MEMBER, ChatMemberStatus.RESTRICTED\n        ]:\n            return \"group_join\"\n        elif old_status in [\n            ChatMemberStatus.MEMBER, ChatMemberStatus.RESTRICTED\n        ] and new_status == ChatMemberStatus.LEFT:\n            return \"group_leave\"\n        elif old_status in [\n            ChatMemberStatus.MEMBER, ChatMemberStatus.RESTRICTED\n        ] and new_status == ChatMemberStatus.BANNED:\n            return \"group_banned\"\n        elif old_status == ChatMemberStatus.BANNED and new_status in [\n            ChatMemberStatus.MEMBER, ChatMemberStatus.RESTRICTED\n        ]:\n            return \"group_unbanned\"\n        elif old_status == ChatMemberStatus.MEMBER and new_status == ChatMemberStatus.ADMINISTRATOR:\n            return \"group_promoted\"\n        elif old_status == ChatMemberStatus.ADMINISTRATOR and new_status == ChatMemberStatus.MEMBER:\n            return \"group_demoted\"\n    \n    # ÐŸÑ€Ð¸Ð²Ð°Ñ‚Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹ (Ñ…Ð¾Ñ‚Ñ Ñ‚Ð°Ð¼ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ñ€ÐµÐ´ÐºÐ¸)\n    elif chat_type == ChatType.PRIVATE:\n        if old_status == ChatMemberStatus.LEFT and new_status == ChatMemberStatus.MEMBER:\n            return \"private_unblocked\"\n        elif old_status == ChatMemberStatus.MEMBER and new_status == ChatMemberStatus.BANNED:\n            return \"private_blocked\"\n    \n    return None\n\n\ndef _determine_bot_event_type(chat_type: ChatType, old_status: ChatMemberStatus, \n                             new_status: ChatMemberStatus) -> Optional[str]:\n    \"\"\"\n    ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ñ‚Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð±Ð¾Ñ‚Ð°.\n    \n    Args:\n        chat_type: Ð¢Ð¸Ð¿ Ñ‡Ð°Ñ‚Ð°\n        old_status: Ð¡Ñ‚Ð°Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð±Ð¾Ñ‚Ð°\n        new_status: ÐÐ¾Ð²Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð±Ð¾Ñ‚Ð°\n        \n    Returns:\n        str Ð¸Ð»Ð¸ None: Ð¢Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² Ð‘Ð”\n    \"\"\"\n    # Ð”Ð»Ñ Ð²ÑÐµÑ… Ñ‚Ð¸Ð¿Ð¾Ð² Ñ‡Ð°Ñ‚Ð¾Ð²\n    if old_status == ChatMemberStatus.LEFT and new_status in [\n        ChatMemberStatus.MEMBER, ChatMemberStatus.ADMINISTRATOR\n    ]:\n        return \"bot_added\"\n    elif old_status in [\n        ChatMemberStatus.MEMBER, ChatMemberStatus.ADMINISTRATOR\n    ] and new_status == ChatMemberStatus.LEFT:\n        return \"bot_removed\"\n    elif old_status in [\n        ChatMemberStatus.MEMBER, ChatMemberStatus.ADMINISTRATOR\n    ] and new_status == ChatMemberStatus.BANNED:\n        return \"bot_banned\"\n    elif old_status == ChatMemberStatus.BANNED and new_status in [\n        ChatMemberStatus.MEMBER, ChatMemberStatus.ADMINISTRATOR\n    ]:\n        return \"bot_unbanned\"\n    elif old_status == ChatMemberStatus.MEMBER and new_status == ChatMemberStatus.ADMINISTRATOR:\n        return \"bot_promoted\"\n    elif old_status == ChatMemberStatus.ADMINISTRATOR and new_status == ChatMemberStatus.MEMBER:\n        return \"bot_demoted\"\n    \n    return None\n\n\nasync def log_event_statistics():\n    \"\"\"Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹.\"\"\"\n    try:\n        db = get_db()\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ñ‡Ð°Ñ\n        now = get_almaty_now()\n        stats = db.get_events_for_period(\n            start_date=(now.replace(minute=0, second=0, microsecond=0) - \n                       timedelta(hours=1)).strftime(\"%Y-%m-%d %H:%M:%S\"),\n            end_date=now.strftime(\"%Y-%m-%d %H:%M:%S\")\n        )\n        \n        if stats:\n            logger.info(f\"ðŸ“Š [Events] Processed {len(stats)} events in the last hour\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ [Events] Error logging event statistics: {e}\")\n\n\n# Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð° Ð´Ð»Ñ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸\n__all__ = ['events_router', 'log_event_statistics']","size_bytes":14918},"bot_project/reports/__init__.py":{"content":"","size_bytes":0},"bot_project/reports/excel_templates.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nExcel Templates module for Telegram bot reporting system.\nProvides templates and utilities for generating formatted Excel reports\nwith proper styling, charts, and Russian localization.\n\"\"\"\n\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\nfrom datetime import datetime, date\n\nimport pandas as pd\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment, Border, Side, NamedStyle\nfrom openpyxl.utils.dataframe import dataframe_to_rows\nfrom openpyxl.utils import get_column_letter\nfrom openpyxl.chart import LineChart, BarChart, PieChart, Reference\n# from openpyxl.chart.series import DataPoint  # Not needed\n\nfrom utils.time_utils import format_datetime_for_report, format_time_period_ru\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseReportTemplate:\n    \"\"\"\n    Base class for Excel report templates with common styling and utilities.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize base template with common styles.\"\"\"\n        self.wb = None\n        self._init_styles()\n    \n    def _init_styles(self):\n        \"\"\"Initialize common Excel styles.\"\"\"\n        # Header style\n        self.header_style = NamedStyle(name=\"header\")\n        self.header_style.font = Font(bold=True, size=12, color=\"FFFFFF\")\n        self.header_style.fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n        self.header_style.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n        self.header_style.border = Border(\n            left=Side(style=\"thin\"),\n            right=Side(style=\"thin\"),\n            top=Side(style=\"thin\"),\n            bottom=Side(style=\"thin\")\n        )\n        \n        # Title style\n        self.title_style = NamedStyle(name=\"title\")\n        self.title_style.font = Font(bold=True, size=16, color=\"366092\")\n        self.title_style.alignment = Alignment(horizontal=\"center\")\n        \n        # Subtitle style\n        self.subtitle_style = NamedStyle(name=\"subtitle\")\n        self.subtitle_style.font = Font(bold=True, size=12, color=\"666666\")\n        self.subtitle_style.alignment = Alignment(horizontal=\"left\")\n        \n        # Data style\n        self.data_style = NamedStyle(name=\"data\")\n        self.data_style.font = Font(size=10)\n        self.data_style.alignment = Alignment(horizontal=\"center\")\n        self.data_style.border = Border(\n            left=Side(style=\"thin\"),\n            right=Side(style=\"thin\"),\n            top=Side(style=\"thin\"),\n            bottom=Side(style=\"thin\")\n        )\n        \n        # Number style\n        self.number_style = NamedStyle(name=\"number\")\n        self.number_style.font = Font(size=10)\n        self.number_style.alignment = Alignment(horizontal=\"right\")\n        self.number_style.number_format = \"#,##0\"\n        \n        # Percentage style\n        self.percentage_style = NamedStyle(name=\"percentage\")\n        self.percentage_style.font = Font(size=10)\n        self.percentage_style.alignment = Alignment(horizontal=\"right\")\n        self.percentage_style.number_format = \"0.00%\"\n    \n    def _add_title(self, ws, title: str, row: int = 1) -> int:\n        \"\"\"\n        Add title to worksheet.\n        \n        Args:\n            ws: Worksheet\n            title: Title text\n            row: Starting row\n            \n        Returns:\n            int: Next available row\n        \"\"\"\n        ws.cell(row=row, column=1, value=title)\n        ws.cell(row=row, column=1).style = self.title_style\n        ws.merge_cells(start_row=row, start_column=1, end_row=row, end_column=6)\n        return row + 2\n    \n    def _add_subtitle(self, ws, subtitle: str, row: int) -> int:\n        \"\"\"\n        Add subtitle to worksheet.\n        \n        Args:\n            ws: Worksheet\n            subtitle: Subtitle text\n            row: Starting row\n            \n        Returns:\n            int: Next available row\n        \"\"\"\n        ws.cell(row=row, column=1, value=subtitle)\n        ws.cell(row=row, column=1).style = self.subtitle_style\n        return row + 1\n    \n    def _add_dataframe_table(self, ws, df: pd.DataFrame, start_row: int, \n                            start_col: int = 1, add_headers: bool = True) -> int:\n        \"\"\"\n        Add DataFrame as formatted table to worksheet.\n        \n        Args:\n            ws: Worksheet\n            df: DataFrame to add\n            start_row: Starting row\n            start_col: Starting column\n            add_headers: Whether to add headers\n            \n        Returns:\n            int: Next available row\n        \"\"\"\n        current_row = start_row\n        \n        # Add headers if requested\n        if add_headers:\n            for col_idx, column in enumerate(df.columns):\n                cell = ws.cell(row=current_row, column=start_col + col_idx, value=column)\n                cell.style = self.header_style\n            current_row += 1\n        \n        # Add data rows\n        for _, row_data in df.iterrows():\n            for col_idx, value in enumerate(row_data):\n                cell = ws.cell(row=current_row, column=start_col + col_idx, value=value)\n                cell.style = self.data_style\n                \n                # Apply number formatting for numeric values\n                if isinstance(value, (int, float)) and not isinstance(value, bool):\n                    if 0 <= value <= 1 and '.' in str(value):\n                        cell.style = self.percentage_style\n                    else:\n                        cell.style = self.number_style\n            current_row += 1\n        \n        return current_row + 1\n    \n    def _add_summary_stats(self, ws, stats: Dict[str, Any], start_row: int) -> int:\n        \"\"\"\n        Add summary statistics section.\n        \n        Args:\n            ws: Worksheet\n            stats: Statistics dictionary\n            start_row: Starting row\n            \n        Returns:\n            int: Next available row\n        \"\"\"\n        current_row = start_row\n        \n        # Define stat mappings with Russian labels\n        stat_mappings = {\n            'total_subscriptions': 'Ð’ÑÐµÐ³Ð¾ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¾Ðº',\n            'total_unsubscriptions': 'Ð’ÑÐµÐ³Ð¾ Ð¾Ñ‚Ð¿Ð¸ÑÐ¾Ðº',\n            'net_growth': 'Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚',\n            'unique_subscribers': 'Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²',\n            'repeat_subscribers': 'ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð²',\n            'retention_rate': 'ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ',\n            'churn_rate': 'ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ Ð¾Ñ‚Ñ‚Ð¾ÐºÐ°'\n        }\n        \n        for key, label in stat_mappings.items():\n            if key in stats:\n                value = stats[key]\n                \n                # Format value appropriately\n                if isinstance(value, float) and 0 <= value <= 1:\n                    formatted_value = f\"{value:.2%}\"\n                elif isinstance(value, (int, float)):\n                    formatted_value = f\"{value:,}\"\n                else:\n                    formatted_value = str(value)\n                \n                ws.cell(row=current_row, column=1, value=label)\n                ws.cell(row=current_row, column=1).style = self.subtitle_style\n                ws.cell(row=current_row, column=2, value=formatted_value)\n                ws.cell(row=current_row, column=2).style = self.data_style\n                \n                current_row += 1\n        \n        return current_row + 1\n    \n    def _add_bar_chart(self, ws, data_range: str, categories_range: str, \n                       title: str, position: str) -> None:\n        \"\"\"\n        Add bar chart to worksheet.\n        \n        Args:\n            ws: Worksheet\n            data_range: Data range for chart\n            categories_range: Categories range\n            title: Chart title\n            position: Chart position (e.g., \"H5\")\n        \"\"\"\n        try:\n            chart = BarChart()\n            chart.title = title\n            chart.y_axis.title = \"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾\"\n            chart.x_axis.title = \"ÐŸÐµÑ€Ð¸Ð¾Ð´\"\n            \n            # Create Reference objects properly\n            data = Reference(worksheet=ws, range_string=data_range)\n            categories = Reference(worksheet=ws, range_string=categories_range)\n            \n            chart.add_data(data, titles_from_data=True)\n            chart.set_categories(categories)\n            \n            ws.add_chart(chart, position)\n        except Exception as e:\n            logger.warning(f\"Failed to create bar chart: {e}\")\n            # Chart creation failed, continue without chart\n    \n    def _add_line_chart(self, ws, data_range: str, categories_range: str,\n                        title: str, position: str) -> None:\n        \"\"\"\n        Add line chart to worksheet.\n        \n        Args:\n            ws: Worksheet\n            data_range: Data range for chart\n            categories_range: Categories range\n            title: Chart title\n            position: Chart position (e.g., \"H5\")\n        \"\"\"\n        try:\n            chart = LineChart()\n            chart.title = title\n            chart.y_axis.title = \"Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ\"\n            chart.x_axis.title = \"Ð”Ð°Ñ‚Ð°\"\n            \n            # Create Reference objects properly\n            data = Reference(worksheet=ws, range_string=data_range)\n            categories = Reference(worksheet=ws, range_string=categories_range)\n            \n            chart.add_data(data, titles_from_data=True)\n            chart.set_categories(categories)\n            \n            ws.add_chart(chart, position)\n        except Exception as e:\n            logger.warning(f\"Failed to create line chart: {e}\")\n            # Chart creation failed, continue without chart\n    \n    def _auto_adjust_columns(self, ws) -> None:\n        \"\"\"Auto-adjust column widths based on content.\"\"\"\n        for column in ws.columns:\n            max_length = 0\n            column_letter = get_column_letter(column[0].column)\n            \n            for cell in column:\n                try:\n                    if len(str(cell.value)) > max_length:\n                        max_length = len(str(cell.value))\n                except:\n                    pass\n            \n            adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters\n            ws.column_dimensions[column_letter].width = adjusted_width\n\n\nclass DailyReportTemplate(BaseReportTemplate):\n    \"\"\"Template for daily subscription/unsubscription reports.\"\"\"\n    \n    def generate(self, report_data: Dict[str, Any], file_path: Path) -> None:\n        \"\"\"\n        Generate daily report Excel file.\n        \n        Args:\n            report_data: Report data dictionary\n            file_path: Output file path\n        \"\"\"\n        logger.info(f\"Generating daily report: {file_path}\")\n        \n        self.wb = Workbook()\n        # Remove default sheet safely\n        active = self.wb.active\n        if active is not None:\n            self.wb.remove(active)\n        \n        # Add styles to workbook\n        for style in [self.header_style, self.title_style, self.subtitle_style, \n                     self.data_style, self.number_style, self.percentage_style]:\n            if style.name not in self.wb.named_styles:\n                self.wb.add_named_style(style)\n        \n        # Create main summary sheet\n        self._create_summary_sheet(report_data)\n        \n        # Create events detail sheet\n        self._create_events_sheet(report_data)\n        \n        # Create retention analysis sheet\n        self._create_retention_sheet(report_data)\n        \n        # Save workbook\n        self.wb.save(file_path)\n        logger.info(f\"Daily report saved: {file_path}\")\n    \n    def _create_summary_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create summary sheet with main statistics.\"\"\"\n        ws = self.wb.create_sheet(\"Ð¡Ð²Ð¾Ð´ÐºÐ°\")\n        \n        # Title\n        target_date = report_data['date']\n        formatted_date = format_datetime_for_report(\n            datetime.fromisoformat(target_date + \"T00:00:00\"), \n            include_time=False\n        )\n        current_row = self._add_title(ws, f\"Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {formatted_date}\")\n        \n        # Summary statistics\n        current_row = self._add_subtitle(ws, \"ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\", current_row)\n        current_row = self._add_summary_stats(ws, report_data['stats'], current_row)\n        \n        # Retention statistics\n        current_row = self._add_subtitle(ws, \"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\", current_row + 1)\n        \n        retention_data = []\n        for period, retention_stats in report_data['retention'].items():\n            period_days = period.replace('_', ' ')\n            retention_data.append({\n                'ÐŸÐµÑ€Ð¸Ð¾Ð´': format_time_period_ru(int(period.split('_')[0])),\n                'Ð’ÑÐµÐ³Ð¾ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¾Ðº': retention_stats.get('total_subscriptions', 0),\n                'Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¾': retention_stats.get('retained', 0),\n                'ÐÐµ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¾': retention_stats.get('not_retained', 0),\n                'ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ': retention_stats.get('retention_rate', 0)\n            })\n        \n        if retention_data:\n            df_retention = pd.DataFrame(retention_data)\n            current_row = self._add_dataframe_table(ws, df_retention, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_events_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create events detail sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð”ÐµÑ‚Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\")\n        \n        # Events table\n        events = report_data.get('events', [])\n        if events:\n            # Convert events to DataFrame\n            events_df = pd.DataFrame(events)\n            \n            # Rename columns to Russian\n            column_mapping = {\n                'event_time': 'Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ',\n                'event_type': 'Ð¢Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ',\n                'tg_user_id': 'ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'username': 'Ð˜Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'name': 'ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÐ¼Ð¾Ðµ Ð¸Ð¼Ñ',\n                'status': 'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ',\n                'note': 'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ'\n            }\n            \n            events_df = events_df.rename(columns=column_mapping)\n            \n            # Format datetime columns\n            if 'Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ' in events_df.columns:\n                events_df['Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ'] = events_df['Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ'].apply(\n                    lambda x: format_datetime_for_report(datetime.fromisoformat(x)) if x else ''\n                )\n            \n            current_row = self._add_dataframe_table(ws, events_df, current_row)\n        else:\n            ws.cell(row=current_row, column=1, value=\"ÐÐµÑ‚ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´\")\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_retention_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create retention analysis sheet.\"\"\"\n        ws = self.wb.create_sheet(\"ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n        \n        # Title\n        current_row = self._add_title(ws, \"ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹\")\n        \n        # Detailed retention analysis\n        for period, retention_stats in report_data['retention'].items():\n            if not retention_stats:\n                continue\n            \n            period_name = format_time_period_ru(int(period.split('_')[0]))\n            current_row = self._add_subtitle(ws, f\"Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð·Ð° {period_name}\", current_row)\n            \n            # Add retention statistics\n            retention_summary = {\n                'total_subscriptions': retention_stats.get('total_subscriptions', 0),\n                'retained': retention_stats.get('retained', 0),\n                'not_retained': retention_stats.get('not_retained', 0),\n                'retention_rate': retention_stats.get('retention_rate', 0)\n            }\n            \n            current_row = self._add_summary_stats(ws, retention_summary, current_row)\n            current_row += 1\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n\n\nclass WeeklyReportTemplate(BaseReportTemplate):\n    \"\"\"Template for weekly subscription/unsubscription reports.\"\"\"\n    \n    def generate(self, report_data: Dict[str, Any], file_path: Path) -> None:\n        \"\"\"Generate weekly report Excel file.\"\"\"\n        logger.info(f\"Generating weekly report: {file_path}\")\n        \n        self.wb = Workbook()\n        # Remove default sheet safely\n        active = self.wb.active\n        if active is not None:\n            self.wb.remove(active)\n        \n        # Add styles\n        for style in [self.header_style, self.title_style, self.subtitle_style, \n                     self.data_style, self.number_style, self.percentage_style]:\n            if style.name not in self.wb.named_styles:\n                self.wb.add_named_style(style)\n        \n        # Create sheets\n        self._create_weekly_summary_sheet(report_data)\n        self._create_daily_breakdown_sheet(report_data)\n        self._create_weekly_events_sheet(report_data)\n        \n        # Save workbook\n        self.wb.save(file_path)\n        logger.info(f\"Weekly report saved: {file_path}\")\n    \n    def _create_weekly_summary_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create weekly summary sheet.\"\"\"\n        ws = self.wb.create_sheet(\"ÐÐµÐ´ÐµÐ»ÑŒÐ½Ð°Ñ ÑÐ²Ð¾Ð´ÐºÐ°\")\n        \n        # Title\n        week_start = report_data['week_start']\n        week_end = report_data['week_end']\n        current_row = self._add_title(ws, f\"ÐÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {week_start} Ð¿Ð¾ {week_end}\")\n        \n        # Weekly statistics\n        current_row = self._add_subtitle(ws, \"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ\", current_row)\n        current_row = self._add_summary_stats(ws, report_data['stats'], current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_daily_breakdown_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create daily breakdown sheet.\"\"\"\n        ws = self.wb.create_sheet(\"ÐŸÐ¾ Ð´Ð½ÑÐ¼\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð Ð°Ð·Ð±Ð¸Ð²ÐºÐ° Ð¿Ð¾ Ð´Ð½ÑÐ¼ Ð½ÐµÐ´ÐµÐ»Ð¸\")\n        \n        # Daily breakdown table\n        daily_data = []\n        for day_data in report_data.get('daily_breakdown', []):\n            daily_data.append({\n                'Ð”Ð°Ñ‚Ð°': day_data['date'],\n                'Ð”ÐµÐ½ÑŒ Ð½ÐµÐ´ÐµÐ»Ð¸': day_data['weekday'],\n                'ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ¸': day_data['stats'].get('total_subscriptions', 0),\n                'ÐžÑ‚Ð¿Ð¸ÑÐºÐ¸': day_data['stats'].get('total_unsubscriptions', 0),\n                'Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚': day_data['stats'].get('net_growth', 0)\n            })\n        \n        if daily_data:\n            df_daily = pd.DataFrame(daily_data)\n            current_row = self._add_dataframe_table(ws, df_daily, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_weekly_events_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create weekly events sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð½ÐµÐ´ÐµÐ»Ð¸\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð’ÑÐµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð·Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ\")\n        \n        # Events table (similar to daily report)\n        events = report_data.get('events', [])\n        if events:\n            events_df = pd.DataFrame(events)\n            \n            column_mapping = {\n                'event_time': 'Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ',\n                'event_type': 'Ð¢Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ',\n                'tg_user_id': 'ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'username': 'Ð˜Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'status': 'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ'\n            }\n            \n            events_df = events_df.rename(columns=column_mapping)\n            \n            if 'Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ' in events_df.columns:\n                events_df['Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ'] = events_df['Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ'].apply(\n                    lambda x: format_datetime_for_report(datetime.fromisoformat(x)) if x else ''\n                )\n            \n            current_row = self._add_dataframe_table(ws, events_df, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n\n\nclass MonthlyReportTemplate(BaseReportTemplate):\n    \"\"\"Template for monthly subscription/unsubscription reports.\"\"\"\n    \n    def generate(self, report_data: Dict[str, Any], file_path: Path) -> None:\n        \"\"\"Generate monthly report Excel file.\"\"\"\n        logger.info(f\"Generating monthly report: {file_path}\")\n        \n        self.wb = Workbook()\n        # Remove default sheet safely\n        active = self.wb.active\n        if active is not None:\n            self.wb.remove(active)\n        \n        # Add styles\n        for style in [self.header_style, self.title_style, self.subtitle_style, \n                     self.data_style, self.number_style, self.percentage_style]:\n            if style.name not in self.wb.named_styles:\n                self.wb.add_named_style(style)\n        \n        # Create sheets\n        self._create_monthly_summary_sheet(report_data)\n        self._create_weekly_breakdown_sheet(report_data)\n        self._create_monthly_retention_sheet(report_data)\n        \n        # Save workbook\n        self.wb.save(file_path)\n        logger.info(f\"Monthly report saved: {file_path}\")\n    \n    def _create_monthly_summary_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create monthly summary sheet.\"\"\"\n        ws = self.wb.create_sheet(\"ÐœÐµÑÑÑ‡Ð½Ð°Ñ ÑÐ²Ð¾Ð´ÐºÐ°\")\n        \n        # Title\n        month_start = report_data['month_start']\n        month_end = report_data['month_end']\n        current_row = self._add_title(ws, f\"ÐœÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {month_start} Ð¿Ð¾ {month_end}\")\n        \n        # Monthly statistics\n        current_row = self._add_subtitle(ws, \"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð° Ð¼ÐµÑÑÑ†\", current_row)\n        current_row = self._add_summary_stats(ws, report_data['stats'], current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_weekly_breakdown_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create weekly breakdown sheet.\"\"\"\n        ws = self.wb.create_sheet(\"ÐŸÐ¾ Ð½ÐµÐ´ÐµÐ»ÑÐ¼\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð Ð°Ð·Ð±Ð¸Ð²ÐºÐ° Ð¿Ð¾ Ð½ÐµÐ´ÐµÐ»ÑÐ¼\")\n        \n        # Weekly breakdown table\n        weekly_data = []\n        for week_data in report_data.get('weekly_breakdown', []):\n            weekly_data.append({\n                'ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð½ÐµÐ´ÐµÐ»Ð¸': week_data['week_start'],\n                'ÐšÐ¾Ð½ÐµÑ† Ð½ÐµÐ´ÐµÐ»Ð¸': week_data['week_end'],\n                'ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ¸': week_data['stats'].get('total_subscriptions', 0),\n                'ÐžÑ‚Ð¿Ð¸ÑÐºÐ¸': week_data['stats'].get('total_unsubscriptions', 0),\n                'Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚': week_data['stats'].get('net_growth', 0)\n            })\n        \n        if weekly_data:\n            df_weekly = pd.DataFrame(weekly_data)\n            current_row = self._add_dataframe_table(ws, df_weekly, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_monthly_retention_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create monthly retention analysis sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ\")\n        \n        # Title\n        current_row = self._add_title(ws, \"ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð·Ð° Ð¼ÐµÑÑÑ†\")\n        \n        # Retention analysis\n        retention_analysis = report_data.get('retention_analysis', {})\n        for period, retention_stats in retention_analysis.items():\n            if not retention_stats:\n                continue\n            \n            period_name = format_time_period_ru(int(period.split('_')[0]))\n            current_row = self._add_subtitle(ws, f\"Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð·Ð° {period_name}\", current_row)\n            current_row = self._add_summary_stats(ws, retention_stats, current_row)\n            current_row += 1\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n\n\nclass RetentionReportTemplate(BaseReportTemplate):\n    \"\"\"Template for detailed retention analysis reports.\"\"\"\n    \n    def generate(self, report_data: Dict[str, Any], file_path: Path) -> None:\n        \"\"\"Generate retention report Excel file.\"\"\"\n        logger.info(f\"Generating retention report: {file_path}\")\n        \n        self.wb = Workbook()\n        # Remove default sheet safely\n        active = self.wb.active\n        if active is not None:\n            self.wb.remove(active)\n        \n        # Add styles\n        for style in [self.header_style, self.title_style, self.subtitle_style, \n                     self.data_style, self.number_style, self.percentage_style]:\n            if style.name not in self.wb.named_styles:\n                self.wb.add_named_style(style)\n        \n        # Create sheets\n        self._create_retention_summary_sheet(report_data)\n        self._create_retention_details_sheet(report_data)\n        self._create_retention_trends_sheet(report_data)\n        \n        # Save workbook\n        self.wb.save(file_path)\n        logger.info(f\"Retention report saved: {file_path}\")\n    \n    def _create_retention_summary_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create retention summary sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð¡Ð²Ð¾Ð´ÐºÐ° ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n        \n        # Title\n        retention_days = report_data['retention_days']\n        target_date = report_data['target_date']\n        period_name = format_time_period_ru(retention_days)\n        \n        current_row = self._add_title(ws, f\"ÐÐ½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð·Ð° {period_name} Ð½Ð° {target_date}\")\n        \n        # Summary statistics\n        current_row = self._add_subtitle(ws, \"ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\", current_row)\n        current_row = self._add_summary_stats(ws, report_data['stats'], current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_retention_details_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create retention details sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð”ÐµÑ‚Ð°Ð»Ð¸ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n        \n        # Details table\n        details = report_data.get('details', [])\n        if details:\n            details_df = pd.DataFrame(details)\n            \n            column_mapping = {\n                'journal_id': 'ID Ð·Ð°Ð¿Ð¸ÑÐ¸',\n                'tg_user_id': 'ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'username': 'Ð˜Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ',\n                'subscription_date': 'Ð”Ð°Ñ‚Ð° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸',\n                'retention_result': 'Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ',\n                'inviter_id': 'ID Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð²ÑˆÐµÐ³Ð¾'\n            }\n            \n            details_df = details_df.rename(columns=column_mapping)\n            \n            if 'Ð”Ð°Ñ‚Ð° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸' in details_df.columns:\n                details_df['Ð”Ð°Ñ‚Ð° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸'] = details_df['Ð”Ð°Ñ‚Ð° Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸'].apply(\n                    lambda x: format_datetime_for_report(datetime.fromisoformat(x)) if x else ''\n                )\n            \n            current_row = self._add_dataframe_table(ws, details_df, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n    \n    def _create_retention_trends_sheet(self, report_data: Dict[str, Any]) -> None:\n        \"\"\"Create retention trends sheet.\"\"\"\n        ws = self.wb.create_sheet(\"Ð¢Ñ€ÐµÐ½Ð´Ñ‹ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n        \n        # Title\n        current_row = self._add_title(ws, \"Ð¢Ñ€ÐµÐ½Ð´Ñ‹ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ð¿Ð¾ Ð´Ð½ÑÐ¼\")\n        \n        # Trends table\n        trends = report_data.get('trends', [])\n        if trends:\n            trends_data = []\n            for trend in trends:\n                trends_data.append({\n                    'Ð”Ð°Ñ‚Ð°': trend['date'],\n                    'Ð’ÑÐµÐ³Ð¾ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¾Ðº': trend['stats'].get('total_subscriptions', 0),\n                    'Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¾': trend['stats'].get('retained', 0),\n                    'ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ': trend['stats'].get('retention_rate', 0)\n                })\n            \n            if trends_data:\n                df_trends = pd.DataFrame(trends_data)\n                current_row = self._add_dataframe_table(ws, df_trends, current_row)\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)","size_bytes":28977},"bot_project/reports/report_manager.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nReport Manager module for Telegram bot reporting system.\nHandles generation of Excel reports with subscription/unsubscription statistics,\nretention analysis, and historical data export.\n\"\"\"\n\nimport os\nimport logging\nfrom datetime import datetime, date, timedelta\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom pathlib import Path\nimport tempfile\n\nimport pandas as pd\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment, Border, Side\nfrom openpyxl.utils.dataframe import dataframe_to_rows\n\nfrom db.db import DatabaseManager\nfrom utils.time_utils import (\n    get_almaty_now, get_today_date_str, get_date_n_days_ago,\n    format_datetime_for_report, get_week_start_date, get_month_start_date,\n    format_time_period_ru\n)\nfrom utils.logging_conf import log_report_generation\n\nlogger = logging.getLogger(__name__)\n\n\nclass ReportManager:\n    \"\"\"\n    Manages generation of various types of reports for the Telegram bot system.\n    \"\"\"\n    \n    def __init__(self, db_manager: DatabaseManager, reports_dir: str = \"reports_output\"):\n        \"\"\"\n        Initialize Report Manager.\n        \n        Args:\n            db_manager: Database manager instance\n            reports_dir: Directory to store generated reports\n        \"\"\"\n        self.db = db_manager\n        self.reports_dir = Path(reports_dir)\n        self.reports_dir.mkdir(exist_ok=True)\n        \n        logger.info(f\"ReportManager initialized with reports directory: {self.reports_dir}\")\n    \n    def generate_daily_report(self, target_date: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate daily subscription/unsubscription report.\n        \n        Args:\n            target_date: Target date in YYYY-MM-DD format (default: yesterday)\n            \n        Returns:\n            Dict with report data and file path\n        \"\"\"\n        if target_date is None:\n            target_date = get_date_n_days_ago(1)  # Yesterday by default\n        \n        log_report_generation(\"daily\", target_date, \"started\")\n        \n        try:\n            # Get daily statistics\n            daily_stats = self.db.get_daily_stats(target_date)\n            \n            # Get detailed events for the day\n            events = self.db.get_events_for_period(target_date, target_date)\n            \n            # Get retention data for recent periods\n            retention_7d = self._get_retention_for_date(target_date, 7)\n            retention_14d = self._get_retention_for_date(target_date, 14)\n            retention_30d = self._get_retention_for_date(target_date, 30)\n            \n            report_data = {\n                'date': target_date,\n                'stats': daily_stats,\n                'events': events,\n                'retention': {\n                    '7_days': retention_7d,\n                    '14_days': retention_14d,\n                    '30_days': retention_30d\n                },\n                'generated_at': get_almaty_now().isoformat()\n            }\n            \n            # Generate Excel file\n            excel_path = self._generate_daily_excel(report_data)\n            report_data['excel_file'] = str(excel_path)\n            \n            log_report_generation(\"daily\", target_date, \"completed\", \n                                  events_count=len(events), excel_file=excel_path)\n            \n            return report_data\n            \n        except Exception as e:\n            log_report_generation(\"daily\", target_date, \"failed\", error=str(e))\n            logger.error(f\"Failed to generate daily report: {e}\")\n            raise\n    \n    def generate_weekly_report(self, target_date: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate weekly subscription/unsubscription report.\n        \n        Args:\n            target_date: Target date in YYYY-MM-DD format (default: last Monday)\n            \n        Returns:\n            Dict with report data and file path\n        \"\"\"\n        if target_date is None:\n            # Get last Monday\n            today = date.fromisoformat(get_today_date_str())\n            days_since_monday = today.weekday()\n            target_date = (today - timedelta(days=days_since_monday + 7)).isoformat()\n        \n        week_start = get_week_start_date(target_date)\n        week_end = (date.fromisoformat(week_start) + timedelta(days=6)).isoformat()\n        \n        log_report_generation(\"weekly\", f\"{week_start} to {week_end}\", \"started\")\n        \n        try:\n            # Get weekly statistics\n            weekly_stats = self.db.get_weekly_stats(week_start)\n            \n            # Get events for the week\n            events = self.db.get_events_for_period(week_start, week_end)\n            \n            # Get daily breakdown\n            daily_breakdown = []\n            current_date = date.fromisoformat(week_start)\n            for i in range(7):\n                day_str = current_date.isoformat()\n                day_stats = self.db.get_daily_stats(day_str)\n                daily_breakdown.append({\n                    'date': day_str,\n                    'weekday': current_date.strftime('%A'),\n                    'stats': day_stats\n                })\n                current_date += timedelta(days=1)\n            \n            report_data = {\n                'week_start': week_start,\n                'week_end': week_end,\n                'stats': weekly_stats,\n                'daily_breakdown': daily_breakdown,\n                'events': events,\n                'generated_at': get_almaty_now().isoformat()\n            }\n            \n            # Generate Excel file\n            excel_path = self._generate_weekly_excel(report_data)\n            report_data['excel_file'] = str(excel_path)\n            \n            log_report_generation(\"weekly\", f\"{week_start} to {week_end}\", \"completed\",\n                                  events_count=len(events), excel_file=excel_path)\n            \n            return report_data\n            \n        except Exception as e:\n            log_report_generation(\"weekly\", f\"{week_start} to {week_end}\", \"failed\", error=str(e))\n            logger.error(f\"Failed to generate weekly report: {e}\")\n            raise\n    \n    def generate_monthly_report(self, target_date: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate monthly subscription/unsubscription report.\n        \n        Args:\n            target_date: Target date in YYYY-MM-DD format (default: last month)\n            \n        Returns:\n            Dict with report data and file path\n        \"\"\"\n        if target_date is None:\n            # Get first day of last month\n            today = date.fromisoformat(get_today_date_str())\n            if today.month == 1:\n                last_month = today.replace(year=today.year - 1, month=12, day=1)\n            else:\n                last_month = today.replace(month=today.month - 1, day=1)\n            target_date = last_month.isoformat()\n        \n        month_start = get_month_start_date(target_date)\n        # Get last day of month\n        next_month = date.fromisoformat(month_start) + timedelta(days=32)\n        month_end = (next_month.replace(day=1) - timedelta(days=1)).isoformat()\n        \n        log_report_generation(\"monthly\", f\"{month_start} to {month_end}\", \"started\")\n        \n        try:\n            # Get monthly statistics\n            monthly_stats = self.db.get_monthly_stats(month_start)\n            \n            # Get events for the month\n            events = self.db.get_events_for_period(month_start, month_end)\n            \n            # Get weekly breakdown\n            weekly_breakdown = self._get_weekly_breakdown_for_month(month_start, month_end)\n            \n            # Get retention analysis for the month\n            retention_analysis = self._get_monthly_retention_analysis(month_start, month_end)\n            \n            report_data = {\n                'month_start': month_start,\n                'month_end': month_end,\n                'stats': monthly_stats,\n                'weekly_breakdown': weekly_breakdown,\n                'retention_analysis': retention_analysis,\n                'events': events,\n                'generated_at': get_almaty_now().isoformat()\n            }\n            \n            # Generate Excel file\n            excel_path = self._generate_monthly_excel(report_data)\n            report_data['excel_file'] = str(excel_path)\n            \n            log_report_generation(\"monthly\", f\"{month_start} to {month_end}\", \"completed\",\n                                  events_count=len(events), excel_file=excel_path)\n            \n            return report_data\n            \n        except Exception as e:\n            log_report_generation(\"monthly\", f\"{month_start} to {month_end}\", \"failed\", error=str(e))\n            logger.error(f\"Failed to generate monthly report: {e}\")\n            raise\n    \n    def generate_retention_report(self, retention_days: int = 7, target_date: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate detailed retention analysis report.\n        \n        Args:\n            retention_days: Number of days for retention analysis\n            target_date: Target date for analysis (default: today)\n            \n        Returns:\n            Dict with retention analysis and file path\n        \"\"\"\n        if target_date is None:\n            target_date = get_today_date_str()\n        \n        log_report_generation(\"retention\", f\"{retention_days}d from {target_date}\", \"started\")\n        \n        try:\n            # Get retention statistics\n            retention_stats = self.db.get_retention_stats(retention_days, target_date)\n            \n            # Get detailed retention data\n            retention_details = self._get_detailed_retention_analysis(retention_days, target_date)\n            \n            # Get historical retention trends\n            retention_trends = self._get_retention_trends(retention_days, target_date, 30)  # Last 30 days\n            \n            report_data = {\n                'retention_days': retention_days,\n                'target_date': target_date,\n                'stats': retention_stats,\n                'details': retention_details,\n                'trends': retention_trends,\n                'generated_at': get_almaty_now().isoformat()\n            }\n            \n            # Generate Excel file\n            excel_path = self._generate_retention_excel(report_data)\n            report_data['excel_file'] = str(excel_path)\n            \n            log_report_generation(\"retention\", f\"{retention_days}d from {target_date}\", \"completed\",\n                                  excel_file=excel_path)\n            \n            return report_data\n            \n        except Exception as e:\n            log_report_generation(\"retention\", f\"{retention_days}d from {target_date}\", \"failed\", error=str(e))\n            logger.error(f\"Failed to generate retention report: {e}\")\n            raise\n    \n    def export_full_database(self) -> str:\n        \"\"\"\n        Export complete database to Excel file.\n        \n        Returns:\n            str: Path to generated Excel file\n        \"\"\"\n        log_report_generation(\"full_export\", \"all_data\", \"started\")\n        \n        try:\n            # Get all data from database\n            journal_data = self.db.get_journal_for_excel()\n            retention_data = self.db.get_retention_checks_for_excel()\n            user_stats = self.db.get_user_stats_summary()\n            \n            # Generate timestamp for filename\n            timestamp = get_almaty_now().strftime(\"%Y%m%d_%H%M%S\")\n            filename = f\"full_database_export_{timestamp}.xlsx\"\n            file_path = self.reports_dir / filename\n            \n            # Create Excel workbook\n            wb = Workbook()\n            \n            # Remove default sheet safely after adding at least one new sheet\n            active = wb.active\n            sheets_added = False\n            \n            # Add journal data\n            if journal_data:\n                self._add_dataframe_to_workbook(wb, pd.DataFrame(journal_data), \"Journal\")\n                sheets_added = True\n            \n            # Add retention data\n            if retention_data:\n                self._add_dataframe_to_workbook(wb, pd.DataFrame(retention_data), \"Retention_Checks\")\n                sheets_added = True\n            \n            # Add user statistics\n            if user_stats:\n                self._add_dataframe_to_workbook(wb, pd.DataFrame(user_stats), \"User_Statistics\")\n                sheets_added = True\n            \n            # If no data was added, create an empty sheet\n            if not sheets_added:\n                ws = wb.create_sheet(\"No_Data\")\n                ws['A1'] = \"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°\"\n                ws['A2'] = f\"Ð’Ñ€ÐµÐ¼Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ: {get_almaty_now().strftime('%Y-%m-%d %H:%M:%S')}\"\n            \n            # Remove default sheet only if we added other sheets\n            if active is not None and sheets_added:\n                wb.remove(active)\n            \n            # Save workbook\n            wb.save(file_path)\n            \n            log_report_generation(\"full_export\", \"all_data\", \"completed\",\n                                  journal_records=len(journal_data),\n                                  retention_records=len(retention_data),\n                                  excel_file=file_path)\n            \n            logger.info(f\"Full database export completed: {file_path}\")\n            return str(file_path)\n            \n        except Exception as e:\n            log_report_generation(\"full_export\", \"all_data\", \"failed\", error=str(e))\n            logger.error(f\"Failed to export full database: {e}\")\n            raise\n    \n    def _get_retention_for_date(self, target_date: str, retention_days: int) -> Dict[str, Any]:\n        \"\"\"\n        Get retention statistics for a specific date and period.\n        \n        Args:\n            target_date: Date to check retention for\n            retention_days: Retention period in days\n            \n        Returns:\n            Dict with retention statistics\n        \"\"\"\n        try:\n            retention_stats = self.db.get_retention_stats(retention_days, target_date)\n            return retention_stats\n        except Exception as e:\n            logger.warning(f\"Failed to get retention data for {target_date} ({retention_days}d): {e}\")\n            return {'total_subscriptions': 0, 'retained': 0, 'not_retained': 0, 'retention_rate': 0.0}\n    \n    def _get_weekly_breakdown_for_month(self, month_start: str, month_end: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get weekly breakdown for a month period.\n        \n        Args:\n            month_start: Start of month\n            month_end: End of month\n            \n        Returns:\n            List of weekly statistics\n        \"\"\"\n        weekly_breakdown = []\n        current_date = date.fromisoformat(month_start)\n        end_date = date.fromisoformat(month_end)\n        \n        while current_date <= end_date:\n            week_start = get_week_start_date(current_date.isoformat())\n            week_end_date = date.fromisoformat(week_start) + timedelta(days=6)\n            \n            # Don't go beyond month end\n            if week_end_date > end_date:\n                week_end_date = end_date\n            \n            week_end = week_end_date.isoformat()\n            \n            try:\n                week_stats = self.db.get_weekly_stats(week_start)\n                weekly_breakdown.append({\n                    'week_start': week_start,\n                    'week_end': week_end,\n                    'stats': week_stats\n                })\n            except Exception as e:\n                logger.warning(f\"Failed to get weekly stats for {week_start}: {e}\")\n            \n            # Move to next week\n            current_date = date.fromisoformat(week_start) + timedelta(days=7)\n        \n        return weekly_breakdown\n    \n    def _get_monthly_retention_analysis(self, month_start: str, month_end: str) -> Dict[str, Any]:\n        \"\"\"\n        Get retention analysis for a month.\n        \n        Args:\n            month_start: Start of month\n            month_end: End of month\n            \n        Returns:\n            Dict with retention analysis\n        \"\"\"\n        try:\n            # Analyze different retention periods\n            retention_7d = self.db.get_retention_stats(7, month_end)\n            retention_14d = self.db.get_retention_stats(14, month_end)\n            retention_30d = self.db.get_retention_stats(30, month_end)\n            \n            return {\n                '7_days': retention_7d,\n                '14_days': retention_14d,\n                '30_days': retention_30d\n            }\n        except Exception as e:\n            logger.warning(f\"Failed to get monthly retention analysis: {e}\")\n            return {'7_days': {}, '14_days': {}, '30_days': {}}\n    \n    def _get_detailed_retention_analysis(self, retention_days: int, target_date: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get detailed retention analysis with individual user data.\n        \n        Args:\n            retention_days: Retention period\n            target_date: Target date\n            \n        Returns:\n            List of detailed retention records\n        \"\"\"\n        try:\n            # Get subscriptions that need retention check\n            subscriptions = self.db.get_subscriptions_for_retention_check(retention_days, target_date)\n            \n            detailed_data = []\n            for subscription in subscriptions:\n                retention_result = self.db.check_user_retention(\n                    subscription['id'], \n                    subscription['tg_user_id'], \n                    subscription['event_time']\n                )\n                \n                detailed_data.append({\n                    'journal_id': subscription['id'],\n                    'tg_user_id': subscription['tg_user_id'],\n                    'username': subscription.get('username'),\n                    'subscription_date': subscription['event_time'],\n                    'retention_result': retention_result,\n                    'inviter_id': subscription.get('inviter_id')\n                })\n            \n            return detailed_data\n            \n        except Exception as e:\n            logger.warning(f\"Failed to get detailed retention analysis: {e}\")\n            return []\n    \n    def _get_retention_trends(self, retention_days: int, target_date: str, days_back: int) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get retention trends over a period.\n        \n        Args:\n            retention_days: Retention period\n            target_date: End date\n            days_back: Number of days to look back\n            \n        Returns:\n            List of daily retention statistics\n        \"\"\"\n        trends = []\n        end_date = date.fromisoformat(target_date)\n        \n        for i in range(days_back):\n            check_date = (end_date - timedelta(days=i)).isoformat()\n            try:\n                retention_stats = self.db.get_retention_stats(retention_days, check_date)\n                trends.append({\n                    'date': check_date,\n                    'stats': retention_stats\n                })\n            except Exception as e:\n                logger.warning(f\"Failed to get retention trends for {check_date}: {e}\")\n        \n        return list(reversed(trends))  # Oldest first\n    \n    def _generate_daily_excel(self, report_data: Dict[str, Any]) -> Path:\n        \"\"\"Generate Excel file for daily report.\"\"\"\n        from .excel_templates import DailyReportTemplate\n        \n        template = DailyReportTemplate()\n        timestamp = get_almaty_now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"daily_report_{report_data['date']}_{timestamp}.xlsx\"\n        file_path = self.reports_dir / filename\n        \n        template.generate(report_data, file_path)\n        return file_path\n    \n    def _generate_weekly_excel(self, report_data: Dict[str, Any]) -> Path:\n        \"\"\"Generate Excel file for weekly report.\"\"\"\n        from .excel_templates import WeeklyReportTemplate\n        \n        template = WeeklyReportTemplate()\n        timestamp = get_almaty_now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"weekly_report_{report_data['week_start']}_to_{report_data['week_end']}_{timestamp}.xlsx\"\n        file_path = self.reports_dir / filename\n        \n        template.generate(report_data, file_path)\n        return file_path\n    \n    def _generate_monthly_excel(self, report_data: Dict[str, Any]) -> Path:\n        \"\"\"Generate Excel file for monthly report.\"\"\"\n        from .excel_templates import MonthlyReportTemplate\n        \n        template = MonthlyReportTemplate()\n        timestamp = get_almaty_now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"monthly_report_{report_data['month_start']}_to_{report_data['month_end']}_{timestamp}.xlsx\"\n        file_path = self.reports_dir / filename\n        \n        template.generate(report_data, file_path)\n        return file_path\n    \n    def _generate_retention_excel(self, report_data: Dict[str, Any]) -> Path:\n        \"\"\"Generate Excel file for retention report.\"\"\"\n        from .excel_templates import RetentionReportTemplate\n        \n        template = RetentionReportTemplate()\n        timestamp = get_almaty_now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"retention_report_{report_data['retention_days']}d_{report_data['target_date']}_{timestamp}.xlsx\"\n        file_path = self.reports_dir / filename\n        \n        template.generate(report_data, file_path)\n        return file_path\n    \n    def _add_dataframe_to_workbook(self, wb: Workbook, df: pd.DataFrame, sheet_name: str) -> None:\n        \"\"\"\n        Add DataFrame to workbook as a new sheet.\n        \n        Args:\n            wb: Workbook to add sheet to\n            df: DataFrame to add\n            sheet_name: Name of the sheet\n        \"\"\"\n        ws = wb.create_sheet(title=sheet_name)\n        \n        # Add DataFrame to worksheet\n        for r in dataframe_to_rows(df, index=False, header=True):\n            ws.append(r)\n        \n        # Style the header row\n        if ws.max_row > 0:\n            for cell in ws[1]:\n                cell.font = Font(bold=True)\n                cell.fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n    \n    def get_report_summary(self, days_back: int = 30) -> Dict[str, Any]:\n        \"\"\"\n        Get summary of reports generated in the last N days.\n        \n        Args:\n            days_back: Number of days to look back\n            \n        Returns:\n            Dict with report summary\n        \"\"\"\n        try:\n            start_date = get_date_n_days_ago(days_back)\n            end_date = get_today_date_str()\n            \n            # Get basic statistics for the period\n            period_stats = []\n            current_date = date.fromisoformat(start_date)\n            end_date_obj = date.fromisoformat(end_date)\n            \n            total_subscriptions = 0\n            total_unsubscriptions = 0\n            \n            while current_date <= end_date_obj:\n                day_str = current_date.isoformat()\n                try:\n                    daily_stats = self.db.get_daily_stats(day_str)\n                    period_stats.append({\n                        'date': day_str,\n                        'stats': daily_stats\n                    })\n                    \n                    total_subscriptions += daily_stats.get('total_subscriptions', 0)\n                    total_unsubscriptions += daily_stats.get('total_unsubscriptions', 0)\n                    \n                except Exception as e:\n                    logger.warning(f\"Failed to get daily stats for {day_str}: {e}\")\n                \n                current_date += timedelta(days=1)\n            \n            return {\n                'period': f\"{start_date} to {end_date}\",\n                'total_subscriptions': total_subscriptions,\n                'total_unsubscriptions': total_unsubscriptions,\n                'net_growth': total_subscriptions - total_unsubscriptions,\n                'daily_stats': period_stats,\n                'generated_at': get_almaty_now().isoformat()\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get report summary: {e}\")\n            return {'error': str(e)}\n    \n    def cleanup_old_reports(self, days_to_keep: int = 30) -> int:\n        \"\"\"\n        Clean up old report files.\n        \n        Args:\n            days_to_keep: Number of days to keep reports\n            \n        Returns:\n            int: Number of files deleted\n        \"\"\"\n        try:\n            cutoff_time = datetime.now() - timedelta(days=days_to_keep)\n            deleted_count = 0\n            \n            for file_path in self.reports_dir.glob(\"*.xlsx\"):\n                if file_path.stat().st_mtime < cutoff_time.timestamp():\n                    try:\n                        file_path.unlink()\n                        deleted_count += 1\n                        logger.info(f\"Deleted old report: {file_path}\")\n                    except Exception as e:\n                        logger.warning(f\"Failed to delete {file_path}: {e}\")\n            \n            logger.info(f\"Cleanup completed: {deleted_count} files deleted\")\n            return deleted_count\n            \n        except Exception as e:\n            logger.error(f\"Failed to cleanup old reports: {e}\")\n            return 0","size_bytes":25456},"bot_project/reports/scheduler.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ° Ð·Ð°Ð´Ð°Ñ‡ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\n\nÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚:\n- Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½ÑƒÑŽ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð² ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹\n- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÑƒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ \n- Ð Ð°Ð±Ð¾Ñ‚Ñƒ Ñ Ð¼Ð¾ÑÐºÐ¾Ð²ÑÐºÐ¸Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½ÐµÐ¼\n- Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n\"\"\"\n\nimport asyncio\nimport logging\nfrom datetime import datetime, time, timedelta\nfrom typing import Dict, List, Optional, Set, Any, Union, TYPE_CHECKING\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\n\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom apscheduler.triggers.date import DateTrigger\n\n# Type checking imports\nif TYPE_CHECKING:\n    from aiogram import Bot as AiogramBot\n    from aiogram.types import FSInputFile as AiogramFSInputFile\n\n# Runtime imports\ntry:\n    from aiogram import Bot\n    from aiogram.types import FSInputFile\n    AIOGRAM_AVAILABLE = True\nexcept ImportError:\n    # Fallback for when aiogram is not available\n    AIOGRAM_AVAILABLE = False\n    Bot = Any\n    FSInputFile = Any\n\nfrom db.db import DatabaseManager\nfrom utils.time_utils import get_almaty_now, format_datetime_for_report\nfrom utils.logging_conf import get_logger\nfrom reports.report_manager import ReportManager\nfrom reports.unified_report_manager import UnifiedReportManager\n\nlogger = get_logger(__name__)\n\n\n@dataclass\nclass ScheduleConfig:\n    \"\"\"ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n    report_time: time = field(default_factory=lambda: time(23, 59))  # 23:59 Ð¿Ð¾ ÐÐ»Ð¼Ð°Ñ‚Ñ‹\n    target_chats: List[int] = field(default_factory=list)  # Ð¡Ð¿Ð¸ÑÐ¾Ðº chat_id Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸\n    enabled: bool = True\n    report_types: List[str] = field(default_factory=lambda: ['daily'])  # daily, weekly, monthly\n\n\nclass ReportScheduler:\n    \"\"\"\n    ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð¿Ð¾ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÑŽ.\n    \n    ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚:\n    - Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð² ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ\n    - Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ (Ð¿Ð¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸Ðº)\n    - ÐœÐµÑÑÑ‡Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ (1 Ñ‡Ð¸ÑÐ»Ð¾ Ð¼ÐµÑÑÑ†Ð°)\n    - ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÑƒ Ð² Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°Ñ‚Ð¾Ð²\n    - ÐÐ»Ð¼Ð°Ñ‚Ð¸Ð½ÑÐºÐ¾Ðµ Ð²Ñ€ÐµÐ¼Ñ\n    \"\"\"\n    \n    def __init__(self, bot: Optional['AiogramBot'], db_manager: DatabaseManager, \n                 reports_dir: Optional[str] = None):\n        \"\"\"\n        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.\n        \n        Args:\n            bot: Ð­ÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Telegram Ð±Ð¾Ñ‚Ð° (Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ None ÐµÑÐ»Ð¸ aiogram Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½)\n            db_manager: ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n            reports_dir: Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n        \"\"\"\n        self.bot = bot\n        self.db_manager = db_manager\n        reports_dir_str = reports_dir if reports_dir is not None else \"reports_output\"\n        self.report_manager = ReportManager(db_manager, reports_dir_str)\n        # Initialize unified report manager for TZ-compliant reports\n        self.unified_report_manager = UnifiedReportManager(db_manager, reports_dir_str)\n        self.config = ScheduleConfig()\n        self.scheduler = AsyncIOScheduler(timezone='Europe/Moscow')\n        self.running = False\n        self._sent_today: Set[str] = set()  # ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n        \n        logger.info(\"ðŸ•’ [Scheduler] Initialized with default config\")\n    \n    async def configure(self, report_time: Optional[time] = None,\n                        target_chats: Optional[List[int]] = None,\n                        enabled: Optional[bool] = None,\n                        report_types: Optional[List[str]] = None) -> None:\n        \"\"\"\n        ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.\n        \n        Args:\n            report_time: Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² (Ð¿Ð¾ ÐœÐ¾ÑÐºÐ²Ðµ)\n            target_chats: Ð¡Ð¿Ð¸ÑÐ¾Ðº chat_id Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸\n            enabled: Ð’ÐºÐ»ÑŽÑ‡Ñ‘Ð½ Ð»Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\n            report_types: Ð¢Ð¸Ð¿Ñ‹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸\n        \"\"\"\n        if report_time is not None:\n            self.config.report_time = report_time\n        if target_chats is not None:\n            self.config.target_chats = target_chats\n        if enabled is not None:\n            self.config.enabled = enabled\n        if report_types is not None:\n            self.config.report_types = report_types\n        \n        # Auto-enable if we have target chats and use 23:59 timing \n        if len(self.config.target_chats) > 0 and not self.config.enabled:\n            self.config.enabled = True\n            logger.info(f\"ðŸ”„ [Scheduler] Auto-enabled scheduler with {len(self.config.target_chats)} target chats\")\n        \n        logger.info(f\"ðŸ”§ [Scheduler] Configuration updated: time={self.config.report_time}, \"\n                   f\"chats={len(self.config.target_chats)}, enabled={self.config.enabled}\")\n        \n        # ÐŸÐµÑ€ÐµÐ½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÐµÑÐ»Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½\n        if self.running:\n            await self._setup_schedule()\n    \n    def add_target_chat(self, chat_id: int) -> None:\n        \"\"\"Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‡Ð°Ñ‚ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n        if chat_id not in self.config.target_chats:\n            self.config.target_chats.append(chat_id)\n            logger.info(f\"ðŸ“ [Scheduler] Added target chat: {chat_id}\")\n    \n    def remove_target_chat(self, chat_id: int) -> None:\n        \"\"\"Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ñ‡Ð°Ñ‚ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ° Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n        if chat_id in self.config.target_chats:\n            self.config.target_chats.remove(chat_id)\n            logger.info(f\"ðŸ—‘ï¸ [Scheduler] Removed target chat: {chat_id}\")\n    \n    async def start(self) -> None:\n        \"\"\"Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº.\"\"\"\n        if self.running:\n            logger.warning(\"âš ï¸ [Scheduler] Already running\")\n            return\n        \n        if not self.config.enabled:\n            logger.info(\"â¸ï¸ [Scheduler] Disabled in config, not starting\")\n            return\n        \n        if not self.config.target_chats:\n            logger.warning(\"âš ï¸ [Scheduler] No target chats configured\")\n            return\n        \n        if not AIOGRAM_AVAILABLE or self.bot is None:\n            logger.warning(\"âš ï¸ [Scheduler] Aiogram not available or bot is None, scheduler disabled\")\n            return\n        \n        self.running = True\n        await self._setup_schedule()\n        self.scheduler.start()\n        \n        logger.info(f\"ðŸš€ [Scheduler] Started with {len(self.config.target_chats)} target chats\")\n    \n    async def stop(self) -> None:\n        \"\"\"ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº.\"\"\"\n        if not self.running:\n            return\n        \n        self.running = False\n        self.scheduler.shutdown(wait=True)\n        \n        logger.info(\"ðŸ›‘ [Scheduler] Stopped\")\n    \n    async def _setup_schedule(self) -> None:\n        \"\"\"ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².\"\"\"\n        # ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸\n        self.scheduler.remove_all_jobs()\n        \n        # ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°Ñ…\n        self._cleanup_sent_today()\n        \n        if not self.config.enabled:\n            return\n        \n        # Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹\n        if 'daily' in self.config.report_types:\n            self.scheduler.add_job(\n                self._send_daily_reports,\n                CronTrigger(\n                    hour=self.config.report_time.hour,\n                    minute=self.config.report_time.minute,\n                    timezone='Europe/Moscow'\n                ),\n                id='daily_reports',\n                replace_existing=True,\n                misfire_grace_time=300\n            )\n            logger.info(f\"ðŸ“… [Scheduler] Daily reports scheduled for {self.config.report_time}\")\n        \n        # Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ (Ð¿Ð¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸Ðº)\n        if 'weekly' in self.config.report_types:\n            self.scheduler.add_job(\n                self._send_weekly_reports,\n                CronTrigger(\n                    day_of_week='mon',  # Monday\n                    hour=self.config.report_time.hour,\n                    minute=self.config.report_time.minute,\n                    timezone='Europe/Moscow'\n                ),\n                id='weekly_reports',\n                replace_existing=True,\n                misfire_grace_time=300\n            )\n            logger.info(f\"ðŸ“Š [Scheduler] Weekly reports scheduled for Monday {self.config.report_time}\")\n        \n        # ÐœÐµÑÑÑ‡Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ (1 Ñ‡Ð¸ÑÐ»Ð¾ Ð¼ÐµÑÑÑ†Ð°)\n        if 'monthly' in self.config.report_types:\n            self.scheduler.add_job(\n                self._send_monthly_reports,\n                CronTrigger(\n                    day=1,  # 1st of month\n                    hour=self.config.report_time.hour,\n                    minute=self.config.report_time.minute,\n                    timezone='Europe/Moscow'\n                ),\n                id='monthly_reports',\n                replace_existing=True,\n                misfire_grace_time=300\n            )\n            logger.info(f\"ðŸ“ˆ [Scheduler] Monthly reports scheduled for 1st of month {self.config.report_time}\")\n    \n    def _cleanup_sent_today(self) -> None:\n        \"\"\"ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°Ñ… Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ñ Ñ€Ð¾ÑÑ‚Ð° Ð¿Ð°Ð¼ÑÑ‚Ð¸.\"\"\"\n        current_date = get_almaty_now().strftime('%Y-%m-%d')\n        current_week = get_almaty_now().strftime('%Y-W%W')\n        current_month = get_almaty_now().strftime('%Y-%m')\n        \n        # ÐžÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð·Ð° Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ð´ÐµÐ½ÑŒ/Ð½ÐµÐ´ÐµÐ»ÑŽ/Ð¼ÐµÑÑÑ†\n        keys_to_keep = {\n            f\"daily_{current_date}\",\n            f\"weekly_{current_week}\", \n            f\"monthly_{current_month}\"\n        }\n        \n        old_count = len(self._sent_today)\n        self._sent_today = {key for key in self._sent_today if key in keys_to_keep}\n        \n        cleaned_count = old_count - len(self._sent_today)\n        if cleaned_count > 0:\n            logger.info(f\"ðŸ§¹ [Scheduler] Cleaned up {cleaned_count} old sent_today entries\")\n    \n    async def _send_daily_reports(self) -> None:\n        \"\"\"ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹.\"\"\"\n        report_key = f\"daily_{get_almaty_now().strftime('%Y-%m-%d')}\"\n        \n        if report_key in self._sent_today:\n            logger.info(f\"â­ï¸ [Scheduler] Daily report already sent today: {report_key}\")\n            return\n        \n        logger.info(\"ðŸ“… [Scheduler] Generating daily report\")\n        \n        try:\n            # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° Ð·Ð° Ð²Ñ‡ÐµÑ€Ð°ÑˆÐ½Ð¸Ð¹ Ð´ÐµÐ½ÑŒ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ unified system\n            yesterday = get_almaty_now() - timedelta(days=1)\n            target_date = yesterday.strftime(\"%Y-%m-%d\")\n            \n            # Get unified daily report message with download button\n            message_text, download_keyboard = self.unified_report_manager.get_daily_message_with_button(target_date)\n            file_path = self.unified_report_manager.get_excel_file_path()\n            \n            if not file_path:\n                logger.error(\"âŒ [Scheduler] No excel file path in unified report data\")\n                return\n            \n            # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð²Ð¾ Ð²ÑÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹ Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n            await self._send_unified_daily_reports(\n                message_text=message_text,\n                file_path=file_path,\n                keyboard=download_keyboard\n            )\n            \n            self._sent_today.add(report_key)\n            logger.info(f\"âœ… [Scheduler] Daily report sent successfully: {target_date}\")\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Failed to send daily report: {e}\")\n    \n    async def _send_unified_daily_reports(self, message_text: str, file_path: str, \n                                         keyboard: 'InlineKeyboardMarkup') -> None:\n        \"\"\"ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ Ð¢Ð— Ñ ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ.\"\"\"\n        if not self.bot or not AIOGRAM_AVAILABLE:\n            logger.warning(\"âš ï¸ [Scheduler] Bot not available for unified daily reports\")\n            return\n        \n        for chat_id in self.config.target_chats:\n            try:\n                # Send message with keyboard\n                await self.bot.send_message(\n                    chat_id=chat_id,\n                    text=message_text,\n                    reply_markup=keyboard,\n                    parse_mode=None\n                )\n                \n                logger.info(f\"ðŸ“¤ [Scheduler] Unified daily report sent to chat {chat_id}\")\n                \n            except Exception as e:\n                logger.error(f\"âŒ [Scheduler] Failed to send unified daily report to chat {chat_id}: {e}\")\n    \n    async def _send_weekly_reports(self) -> None:\n        \"\"\"ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹.\"\"\"\n        report_key = f\"weekly_{get_almaty_now().strftime('%Y-W%W')}\"\n        \n        if report_key in self._sent_today:\n            logger.info(f\"â­ï¸ [Scheduler] Weekly report already sent this week: {report_key}\")\n            return\n        \n        logger.info(\"ðŸ“Š [Scheduler] Generating weekly report\")\n        \n        try:\n            # ÐžÑ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° Ð¿Ñ€Ð¾ÑˆÐ»ÑƒÑŽ Ð½ÐµÐ´ÐµÐ»ÑŽ\n            now = get_almaty_now()\n            days_since_monday = now.weekday()\n            last_monday = now - timedelta(days=days_since_monday + 7)\n            target_date = last_monday.strftime(\"%Y-%m-%d\")\n            \n            report_data = self.report_manager.generate_weekly_report(target_date)\n            file_path = report_data.get('excel_file')\n            \n            if not file_path:\n                logger.error(\"âŒ [Scheduler] No excel file path in weekly report data\")\n                return\n            \n            # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð²Ð¾ Ð²ÑÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹\n            await self._send_report_to_chats(\n                file_path=file_path,\n                caption=f\"ðŸ“Š Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {format_datetime_for_report(last_monday, False)}\",\n                report_type=\"weekly\"\n            )\n            \n            self._sent_today.add(report_key)\n            logger.info(f\"âœ… [Scheduler] Weekly report sent successfully: {target_date}\")\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Failed to send weekly report: {e}\")\n    \n    async def _send_monthly_reports(self) -> None:\n        \"\"\"ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚.\"\"\"\n        now = get_almaty_now()\n        report_key = f\"monthly_{now.strftime('%Y-%m')}\"\n        \n        if report_key in self._sent_today:\n            logger.info(f\"â­ï¸ [Scheduler] Monthly report already sent this month: {report_key}\")\n            return\n        \n        logger.info(\"ðŸ“ˆ [Scheduler] Generating monthly report\")\n        \n        try:\n            # ÐžÑ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ð¹ Ð¼ÐµÑÑÑ†\n            if now.month == 1:\n                last_month = now.replace(year=now.year - 1, month=12, day=1)\n            else:\n                last_month = now.replace(month=now.month - 1, day=1)\n            \n            target_date = last_month.strftime(\"%Y-%m-%d\")\n            \n            report_data = self.report_manager.generate_monthly_report(target_date)\n            file_path = report_data.get('excel_file')\n            \n            if not file_path:\n                logger.error(\"âŒ [Scheduler] No excel file path in monthly report data\")\n                return\n            \n            # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð²Ð¾ Ð²ÑÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹\n            await self._send_report_to_chats(\n                file_path=file_path,\n                caption=f\"ðŸ“ˆ ÐœÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {format_datetime_for_report(last_month, False)}\",\n                report_type=\"monthly\"\n            )\n            \n            self._sent_today.add(report_key)\n            logger.info(f\"âœ… [Scheduler] Monthly report sent successfully: {target_date}\")\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Failed to send monthly report: {e}\")\n    \n    async def _send_report_to_chats(self, file_path: str, caption: str, \n                                   report_type: str) -> None:\n        \"\"\"\n        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð²Ð¾ Ð²ÑÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ñ‹Ðµ Ñ‡Ð°Ñ‚Ñ‹.\n        \n        Args:\n            file_path: ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\n            caption: ÐŸÐ¾Ð´Ð¿Ð¸ÑÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ\n            report_type: Ð¢Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ\n        \"\"\"\n        if not self.config.target_chats:\n            logger.warning(f\"âš ï¸ [Scheduler] No target chats for {report_type} report\")\n            return\n        \n        if not AIOGRAM_AVAILABLE or self.bot is None:\n            logger.error(f\"âŒ [Scheduler] Aiogram not available or bot is None\")\n            return\n        \n        file_path_obj = Path(file_path)\n        if not file_path_obj.exists():\n            logger.error(f\"âŒ [Scheduler] Report file not found: {file_path}\")\n            return\n        \n        success_count = 0\n        \n        for chat_id in self.config.target_chats:\n            try:\n                # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°\n                if not AIOGRAM_AVAILABLE or FSInputFile is Any:\n                    logger.error(\"âŒ [Scheduler] FSInputFile not available\")\n                    continue\n                document = FSInputFile(file_path_obj, filename=file_path_obj.name)\n                await self.bot.send_document(\n                    chat_id=chat_id,\n                    document=document,\n                    caption=caption\n                )\n                \n                success_count += 1\n                logger.info(f\"ðŸ“¤ [Scheduler] {report_type.title()} report sent to chat {chat_id}\")\n                \n            except Exception as e:\n                logger.exception(f\"âŒ [Scheduler] Failed to send {report_type} report to chat {chat_id}: {e}\")\n        \n        logger.info(f\"ðŸ“Š [Scheduler] {report_type.title()} report sent to {success_count}/{len(self.config.target_chats)} chats\")\n    \n    async def send_test_report(self, chat_id: int, report_type: str = \"daily\") -> bool:\n        \"\"\"\n        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð² ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ñ‡Ð°Ñ‚.\n        \n        Args:\n            chat_id: ID Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸\n            report_type: Ð¢Ð¸Ð¿ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° (daily, weekly, monthly)\n            \n        Returns:\n            bool: Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸\n        \"\"\"\n        logger.info(f\"ðŸ§ª [Scheduler] Sending test {report_type} report to chat {chat_id}\")\n        \n        try:\n            # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\n            now = get_almaty_now()\n            \n            if report_type == \"daily\":\n                yesterday = now - timedelta(days=1)\n                target_date = yesterday.strftime(\"%Y-%m-%d\")\n                report_data = self.report_manager.generate_daily_report(target_date)\n                caption = f\"ðŸ§ª Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {format_datetime_for_report(yesterday, False)}\"\n                \n            elif report_type == \"weekly\":\n                days_since_monday = now.weekday()\n                last_monday = now - timedelta(days=days_since_monday + 7)\n                target_date = last_monday.strftime(\"%Y-%m-%d\")\n                report_data = self.report_manager.generate_weekly_report(target_date)\n                caption = f\"ðŸ§ª Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ {format_datetime_for_report(last_monday, False)}\"\n                \n            elif report_type == \"monthly\":\n                if now.month == 1:\n                    last_month = now.replace(year=now.year - 1, month=12, day=1)\n                else:\n                    last_month = now.replace(month=now.month - 1, day=1)\n                target_date = last_month.strftime(\"%Y-%m-%d\")\n                report_data = self.report_manager.generate_monthly_report(target_date)\n                caption = f\"ðŸ§ª Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {format_datetime_for_report(last_month, False)}\"\n                \n            else:\n                logger.error(f\"âŒ [Scheduler] Unknown report type: {report_type}\")\n                return False\n            \n            file_path = report_data.get('excel_file')\n            if not file_path:\n                logger.error(\"âŒ [Scheduler] No excel file path in test report data\")\n                return False\n                \n            # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°\n            file_path_obj = Path(file_path)\n            if not file_path_obj.exists():\n                logger.error(f\"âŒ [Scheduler] Test report file not found: {file_path}\")\n                return False\n            \n            if not AIOGRAM_AVAILABLE or self.bot is None:\n                logger.error(\"âŒ [Scheduler] Aiogram not available or bot is None\")\n                return False\n            \n            if FSInputFile is Any:\n                logger.error(\"âŒ [Scheduler] FSInputFile not available\")\n                return False\n            \n            document = FSInputFile(file_path_obj, filename=file_path_obj.name)\n            await self.bot.send_document(\n                chat_id=chat_id,\n                document=document,\n                caption=caption\n            )\n            \n            logger.info(f\"âœ… [Scheduler] Test {report_type} report sent successfully to chat {chat_id}\")\n            return True\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Failed to send test {report_type} report to chat {chat_id}: {e}\")\n            return False\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°.\n        \n        Returns:\n            Dict Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n        \"\"\"\n        return {\n            'running': self.running,\n            'config': {\n                'enabled': self.config.enabled,\n                'report_time': self.config.report_time.strftime('%H:%M'),\n                'target_chats_count': len(self.config.target_chats),\n                'report_types': self.config.report_types\n            },\n            'jobs': [job.id for job in self.scheduler.get_jobs()] if self.running else [],\n            'sent_today': list(self._sent_today),\n            'aiogram_available': AIOGRAM_AVAILABLE,\n            'bot_available': self.bot is not None\n        }\n    \n    # ÐœÐµÑ‚Ð¾Ð´Ñ‹ Ð´Ð»Ñ Ñ€ÑƒÑ‡Ð½Ð¾Ð¹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² (Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ)\n    \n    async def send_daily_report_now(self, target_date: Optional[str] = None) -> str:\n        \"\"\"\n        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ñ€ÑÐ¼Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ.\n        \n        Args:\n            target_date: Ð”Ð°Ñ‚Ð° Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YYYY-MM-DD (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ - Ð²Ñ‡ÐµÑ€Ð°)\n            \n        Returns:\n            str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n        \"\"\"\n        logger.info(\"ðŸš€ [Scheduler] Manual daily report generation requested\")\n        \n        if target_date is None:\n            yesterday = get_almaty_now() - timedelta(days=1)\n            target_date = yesterday.strftime(\"%Y-%m-%d\")\n        \n        try:\n            report_data = self.report_manager.generate_daily_report(target_date)\n            file_path = report_data.get('excel_file')\n            \n            if not file_path:\n                raise ValueError(\"No excel file path in report data\")\n            \n            if self.config.target_chats and AIOGRAM_AVAILABLE and self.bot is not None:\n                await self._send_report_to_chats(\n                    file_path=file_path,\n                    caption=f\"ðŸ“… Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð·Ð° {target_date}\",\n                    report_type=\"daily\"\n                )\n            \n            logger.info(f\"âœ… [Scheduler] Manual daily report completed: {target_date}\")\n            return file_path\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Manual daily report failed: {e}\")\n            raise\n    \n    async def send_weekly_report_now(self, target_date: Optional[str] = None) -> str:\n        \"\"\"\n        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ñ€ÑÐ¼Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ.\n        \n        Args:\n            target_date: ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð°Ñ‚Ð° Ð½ÐµÐ´ÐµÐ»Ð¸ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YYYY-MM-DD\n            \n        Returns:\n            str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n        \"\"\"\n        logger.info(\"ðŸš€ [Scheduler] Manual weekly report generation requested\")\n        \n        try:\n            report_data = self.report_manager.generate_weekly_report(target_date)\n            file_path = report_data.get('excel_file')\n            \n            if not file_path:\n                raise ValueError(\"No excel file path in report data\")\n            \n            if self.config.target_chats and AIOGRAM_AVAILABLE and self.bot is not None:\n                await self._send_report_to_chats(\n                    file_path=file_path,\n                    caption=f\"ðŸ“Š Ð•Ð¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\",\n                    report_type=\"weekly\"\n                )\n            \n            logger.info(f\"âœ… [Scheduler] Manual weekly report completed\")\n            return file_path\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Manual weekly report failed: {e}\")\n            raise\n    \n    async def send_monthly_report_now(self, target_date: Optional[str] = None) -> str:\n        \"\"\"\n        ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ñ€ÑÐ¼Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ.\n        \n        Args:\n            target_date: ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð°Ñ‚Ð° Ð¼ÐµÑÑÑ†Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YYYY-MM-DD\n            \n        Returns:\n            str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n        \"\"\"\n        logger.info(\"ðŸš€ [Scheduler] Manual monthly report generation requested\")\n        \n        try:\n            report_data = self.report_manager.generate_monthly_report(target_date)\n            file_path = report_data.get('excel_file')\n            \n            if not file_path:\n                raise ValueError(\"No excel file path in report data\")\n            \n            if self.config.target_chats and AIOGRAM_AVAILABLE and self.bot is not None:\n                await self._send_report_to_chats(\n                    file_path=file_path,\n                    caption=f\"ðŸ“ˆ ÐœÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\",\n                    report_type=\"monthly\"\n                )\n            \n            logger.info(f\"âœ… [Scheduler] Manual monthly report completed\")\n            return file_path\n            \n        except Exception as e:\n            logger.exception(f\"âŒ [Scheduler] Manual monthly report failed: {e}\")\n            raise\n\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ¾Ð¼ Ð² Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¼Ð¾Ð´ÑƒÐ»ÑÑ…\nasync def schedule_daily_report(scheduler: ReportScheduler, target_date: Optional[str] = None) -> str:\n    \"\"\"\n    Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\n    \n    Args:\n        scheduler: Ð­ÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n        target_date: Ð”Ð°Ñ‚Ð° Ð´Ð»Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð° (YYYY-MM-DD), Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð²Ñ‡ÐµÑ€Ð°\n        \n    Returns:\n        str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n    \"\"\"\n    if target_date is None:\n        yesterday = get_almaty_now() - timedelta(days=1)\n        target_date = yesterday.strftime(\"%Y-%m-%d\")\n    \n    logger.info(f\"ðŸ“… [Manual] Generating daily report for {target_date}\")\n    report_data = scheduler.report_manager.generate_daily_report(target_date)\n    file_path = report_data.get('excel_file')\n    if not file_path:\n        raise ValueError(\"No excel file path in report data\")\n    return file_path\n\n\nasync def schedule_weekly_report(scheduler: ReportScheduler, target_date: Optional[str] = None) -> str:\n    \"\"\"\n    Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ ÐµÐ¶ÐµÐ½ÐµÐ´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\n    \n    Args:\n        scheduler: Ð­ÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n        target_date: Ð”Ð°Ñ‚Ð° Ð½Ð°Ñ‡Ð°Ð»Ð° Ð½ÐµÐ´ÐµÐ»Ð¸ (YYYY-MM-DD), Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ð¹ Ð¿Ð¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸Ðº\n        \n    Returns:\n        str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n    \"\"\"\n    if target_date is None:\n        now = get_almaty_now()\n        days_since_monday = now.weekday()\n        last_monday = now - timedelta(days=days_since_monday + 7)\n        target_date = last_monday.strftime(\"%Y-%m-%d\")\n    \n    logger.info(f\"ðŸ“Š [Manual] Generating weekly report for {target_date}\")\n    report_data = scheduler.report_manager.generate_weekly_report(target_date)\n    file_path = report_data.get('excel_file')\n    if not file_path:\n        raise ValueError(\"No excel file path in report data\")\n    return file_path\n\n\nasync def schedule_monthly_report(scheduler: ReportScheduler, target_date: Optional[str] = None) -> str:\n    \"\"\"\n    Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð¼ÐµÑÑÑ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\n    \n    Args:\n        scheduler: Ð­ÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n        target_date: Ð”Ð°Ñ‚Ð° Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¼ÐµÑÑÑ†Ð° (YYYY-MM-DD), Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ð¹ Ð¼ÐµÑÑÑ†\n        \n    Returns:\n        str: ÐŸÑƒÑ‚ÑŒ Ðº ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n    \"\"\"\n    if target_date is None:\n        now = get_almaty_now()\n        if now.month == 1:\n            last_month = now.replace(year=now.year - 1, month=12, day=1)\n        else:\n            last_month = now.replace(month=now.month - 1, day=1)\n        target_date = last_month.strftime(\"%Y-%m-%d\")\n    \n    logger.info(f\"ðŸ“ˆ [Manual] Generating monthly report for {target_date}\")\n    report_data = scheduler.report_manager.generate_monthly_report(target_date)\n    file_path = report_data.get('excel_file')\n    if not file_path:\n        raise ValueError(\"No excel file path in report data\")\n    return file_path","size_bytes":30811},"bot_project/tests/__init__.py":{"content":"","size_bytes":0},"bot_project/utils/__init__.py":{"content":"","size_bytes":0},"bot_project/utils/logging_conf.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nLogging configuration module for Telegram bot reporting system.\nProvides centralized logging setup with file rotation and appropriate formatting.\n\"\"\"\n\nimport logging\nimport logging.handlers\nimport os\nimport sys\nfrom datetime import datetime\nfrom typing import Optional\nfrom pathlib import Path\n\n# Default log directory\nDEFAULT_LOG_DIR = \"logs\"\nDEFAULT_LOG_LEVEL = logging.INFO\nMAX_LOG_FILE_SIZE = 10 * 1024 * 1024  # 10MB\nBACKUP_COUNT = 5\n\n\nclass UTCFormatter(logging.Formatter):\n    \"\"\"\n    Custom formatter that uses UTC time for log messages.\n    \"\"\"\n    \n    def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Format time using UTC timezone.\n        \n        Args:\n            record: Log record\n            datefmt: Date format string\n            \n        Returns:\n            str: Formatted timestamp\n        \"\"\"\n        dt = datetime.utcfromtimestamp(record.created)\n        if datefmt:\n            return dt.strftime(datefmt)\n        else:\n            return dt.strftime('%Y-%m-%d %H:%M:%S UTC')\n\n\ndef setup_logging(\n    log_level: int = DEFAULT_LOG_LEVEL,\n    log_dir: str = DEFAULT_LOG_DIR,\n    app_name: str = \"telegram_bot\",\n    console_output: bool = True,\n    file_output: bool = True\n) -> logging.Logger:\n    \"\"\"\n    Setup centralized logging configuration.\n    \n    Args:\n        log_level: Logging level (default: INFO)\n        log_dir: Directory for log files (default: \"logs\")\n        app_name: Application name for log files\n        console_output: Enable console output (default: True)\n        file_output: Enable file output (default: True)\n        \n    Returns:\n        logging.Logger: Configured logger instance\n    \"\"\"\n    # Create logs directory if it doesn't exist\n    if file_output:\n        Path(log_dir).mkdir(parents=True, exist_ok=True)\n    \n    # Get root logger\n    logger = logging.getLogger()\n    logger.setLevel(log_level)\n    \n    # Clear existing handlers\n    logger.handlers.clear()\n    \n    # Create formatter\n    formatter = UTCFormatter(\n        fmt='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S UTC'\n    )\n    \n    # Console handler\n    if console_output:\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setLevel(log_level)\n        console_handler.setFormatter(formatter)\n        logger.addHandler(console_handler)\n    \n    # File handler with rotation\n    if file_output:\n        log_file_path = os.path.join(log_dir, f\"{app_name}.log\")\n        file_handler = logging.handlers.RotatingFileHandler(\n            log_file_path,\n            maxBytes=MAX_LOG_FILE_SIZE,\n            backupCount=BACKUP_COUNT,\n            encoding='utf-8'\n        )\n        file_handler.setLevel(log_level)\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n    \n    # Set specific loggers levels\n    # Reduce aiogram verbosity\n    logging.getLogger('aiogram').setLevel(logging.WARNING)\n    logging.getLogger('aiohttp').setLevel(logging.WARNING)\n    \n    # Ensure our app logger exists\n    app_logger = logging.getLogger(app_name)\n    app_logger.setLevel(log_level)\n    \n    return app_logger\n\n\ndef get_logger(name: str) -> logging.Logger:\n    \"\"\"\n    Get a logger instance for the specified name.\n    \n    Args:\n        name: Logger name (typically __name__)\n        \n    Returns:\n        logging.Logger: Logger instance\n    \"\"\"\n    return logging.getLogger(name)\n\n\ndef log_function_call(func_name: str, args: tuple = (), kwargs: Optional[dict] = None) -> None:\n    \"\"\"\n    Log function call with arguments.\n    \n    Args:\n        func_name: Function name\n        args: Positional arguments\n        kwargs: Keyword arguments\n    \"\"\"\n    logger = logging.getLogger('function_calls')\n    \n    args_str = ', '.join(repr(arg) for arg in args) if args else ''\n    kwargs_str = ', '.join(f'{k}={repr(v)}' for k, v in (kwargs if kwargs is not None else {}).items())\n    \n    all_args = ', '.join(filter(None, [args_str, kwargs_str]))\n    logger.debug(f\"Calling {func_name}({all_args})\")\n\n\ndef log_database_operation(operation: str, table: str, **kwargs) -> None:\n    \"\"\"\n    Log database operation.\n    \n    Args:\n        operation: Operation type (INSERT, UPDATE, DELETE, SELECT)\n        table: Table name\n        **kwargs: Additional operation details\n    \"\"\"\n    logger = logging.getLogger('database')\n    \n    details = ', '.join(f'{k}={v}' for k, v in kwargs.items()) if kwargs else ''\n    logger.debug(f\"DB {operation} on {table}: {details}\")\n\n\ndef log_telegram_event(event_type: str, user_id: int, username: Optional[str] = None, **kwargs) -> None:\n    \"\"\"\n    Log Telegram bot event.\n    \n    Args:\n        event_type: Type of event (message, callback, etc.)\n        user_id: Telegram user ID\n        username: Telegram username (optional)\n        **kwargs: Additional event details\n    \"\"\"\n    logger = logging.getLogger('telegram_events')\n    \n    user_info = f\"user_id={user_id}\"\n    if username:\n        user_info += f\", username={username}\"\n    \n    details = ', '.join(f'{k}={v}' for k, v in kwargs.items()) if kwargs else ''\n    log_message = f\"Telegram {event_type}: {user_info}\"\n    if details:\n        log_message += f\", {details}\"\n    \n    logger.info(log_message)\n\n\ndef log_report_generation(report_type: str, period: str, status: str, **kwargs) -> None:\n    \"\"\"\n    Log report generation event.\n    \n    Args:\n        report_type: Type of report (daily, weekly, etc.)\n        period: Report period\n        status: Generation status (started, completed, failed)\n        **kwargs: Additional details\n    \"\"\"\n    logger = logging.getLogger('reports')\n    \n    details = ', '.join(f'{k}={v}' for k, v in kwargs.items()) if kwargs else ''\n    log_message = f\"Report {status}: {report_type} for {period}\"\n    if details:\n        log_message += f\", {details}\"\n    \n    if status == 'failed':\n        logger.error(log_message)\n    else:\n        logger.info(log_message)\n\n\ndef log_scheduler_event(task_name: str, status: str, next_run: Optional[str] = None, **kwargs) -> None:\n    \"\"\"\n    Log scheduler event.\n    \n    Args:\n        task_name: Name of scheduled task\n        status: Task status (scheduled, running, completed, failed)\n        next_run: Next run time (optional)\n        **kwargs: Additional details\n    \"\"\"\n    logger = logging.getLogger('scheduler')\n    \n    details = ', '.join(f'{k}={v}' for k, v in kwargs.items()) if kwargs else ''\n    log_message = f\"Task {task_name} {status}\"\n    \n    if next_run:\n        log_message += f\", next run: {next_run}\"\n    \n    if details:\n        log_message += f\", {details}\"\n    \n    if status == 'failed':\n        logger.error(log_message)\n    else:\n        logger.info(log_message)\n\n\ndef setup_development_logging() -> logging.Logger:\n    \"\"\"\n    Setup logging configuration for development environment.\n    \n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    return setup_logging(\n        log_level=logging.DEBUG,\n        log_dir=\"logs\",\n        app_name=\"telegram_bot_dev\",\n        console_output=True,\n        file_output=True\n    )\n\n\ndef setup_production_logging() -> logging.Logger:\n    \"\"\"\n    Setup logging configuration for production environment.\n    Falls back to relative directory if system log directory is not accessible.\n    \n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    log_dir = \"/var/log/telegram_bot\"\n    \n    # Test if we can write to the system log directory\n    try:\n        Path(log_dir).mkdir(parents=True, exist_ok=True)\n        # Test write permissions\n        test_file = os.path.join(log_dir, \"test_write.tmp\")\n        with open(test_file, 'w') as f:\n            f.write(\"test\")\n        os.remove(test_file)\n    except (PermissionError, OSError):\n        # Fall back to relative logs directory\n        log_dir = os.getenv('LOG_DIR', DEFAULT_LOG_DIR)\n        print(f\"Warning: Cannot write to /var/log/telegram_bot, using {log_dir} instead\", file=sys.stderr)\n    \n    return setup_logging(\n        log_level=logging.INFO,\n        log_dir=log_dir,\n        app_name=\"telegram_bot\",\n        console_output=False,  # No console output in production\n        file_output=True\n    )\n\n\ndef configure_logging_from_env() -> logging.Logger:\n    \"\"\"\n    Configure logging based on environment variables.\n    \n    Environment variables:\n        LOG_LEVEL: Logging level (DEBUG, INFO, WARNING, ERROR)\n        LOG_DIR: Directory for log files\n        APP_ENV: Application environment (development, production)\n        \n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    # Get environment variables\n    log_level_str = os.getenv('LOG_LEVEL', 'INFO').upper()\n    log_dir = os.getenv('LOG_DIR', DEFAULT_LOG_DIR)\n    app_env = os.getenv('APP_ENV', 'development').lower()\n    \n    # Convert log level string to constant\n    log_level_map = {\n        'DEBUG': logging.DEBUG,\n        'INFO': logging.INFO,\n        'WARNING': logging.WARNING,\n        'ERROR': logging.ERROR,\n        'CRITICAL': logging.CRITICAL\n    }\n    log_level = log_level_map.get(log_level_str, logging.INFO)\n    \n    # Configure based on environment\n    if app_env == 'production':\n        return setup_logging(\n            log_level=log_level,\n            log_dir=log_dir,\n            app_name=\"telegram_bot\",\n            console_output=False,\n            file_output=True\n        )\n    else:\n        return setup_logging(\n            log_level=log_level,\n            log_dir=log_dir,\n            app_name=\"telegram_bot_dev\",\n            console_output=True,\n            file_output=True\n        )\n\n\n# Convenience function for quick setup\ndef init_logging() -> logging.Logger:\n    \"\"\"\n    Initialize logging with default configuration.\n    This is the main function to call in application startup.\n    \n    Returns:\n        logging.Logger: Configured logger\n    \"\"\"\n    return configure_logging_from_env()\n\n\nif __name__ == \"__main__\":\n    # Test logging configuration\n    logger = init_logging()\n    \n    logger.debug(\"Debug message\")\n    logger.info(\"Info message\")\n    logger.warning(\"Warning message\")\n    logger.error(\"Error message\")\n    \n    # Test specialized logging functions\n    log_telegram_event(\"message\", 12345, \"testuser\", text=\"Test message\")\n    log_database_operation(\"INSERT\", \"users\", user_id=12345, username=\"testuser\")\n    log_report_generation(\"daily\", \"2023-12-01\", \"completed\", rows=100)\n    log_scheduler_event(\"daily_report\", \"completed\", \"2023-12-02 09:00:00\")","size_bytes":10484},"bot_project/utils/time_utils.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nTime utilities module for Telegram bot reporting system.\nProvides timezone-aware date/time operations and formatting functions.\n\"\"\"\n\nfrom datetime import datetime, date, timezone, timedelta\nfrom typing import Optional, Union\nimport pytz\n\n# Almaty timezone\nALMATY_TZ = pytz.timezone('Asia/Almaty')\nUTC_TZ = pytz.timezone('UTC')\n\n\ndef get_almaty_now() -> datetime:\n    \"\"\"\n    Get current datetime in Almaty timezone.\n    \n    Returns:\n        datetime: Current datetime in Almaty timezone\n    \"\"\"\n    return datetime.now(ALMATY_TZ)\n\n\ndef get_utc_now() -> datetime:\n    \"\"\"\n    Get current datetime in UTC timezone.\n    \n    Returns:\n        datetime: Current datetime in UTC timezone\n    \"\"\"\n    return datetime.now(UTC_TZ)\n\n\ndef almaty_to_utc(almaty_dt: datetime) -> datetime:\n    \"\"\"\n    Convert Almaty datetime to UTC.\n    \n    Args:\n        almaty_dt: Datetime in Almaty timezone\n        \n    Returns:\n        datetime: Datetime in UTC timezone\n    \"\"\"\n    if almaty_dt.tzinfo is None:\n        almaty_dt = ALMATY_TZ.localize(almaty_dt)\n    return almaty_dt.astimezone(UTC_TZ)\n\n\ndef utc_to_almaty(utc_dt: datetime) -> datetime:\n    \"\"\"\n    Convert UTC datetime to Almaty timezone.\n    \n    Args:\n        utc_dt: Datetime in UTC timezone\n        \n    Returns:\n        datetime: Datetime in Almaty timezone\n    \"\"\"\n    if utc_dt.tzinfo is None:\n        utc_dt = UTC_TZ.localize(utc_dt)\n    return utc_dt.astimezone(ALMATY_TZ)\n\n\ndef get_today_date_str(tz: Optional[timezone] = None) -> str:\n    \"\"\"\n    Get today's date as ISO string.\n    \n    Args:\n        tz: Timezone to use (default: Moscow)\n        \n    Returns:\n        str: Today's date in YYYY-MM-DD format\n    \"\"\"\n    if tz is None:\n        return get_almaty_now().date().isoformat()\n    else:\n        return datetime.now(tz).date().isoformat()\n\n\ndef get_date_n_days_ago(days: int, tz: Optional[timezone] = None) -> str:\n    \"\"\"\n    Get date N days ago as ISO string.\n    \n    Args:\n        days: Number of days ago\n        tz: Timezone to use (default: Moscow)\n        \n    Returns:\n        str: Date in YYYY-MM-DD format\n    \"\"\"\n    if tz is None:\n        base_date = get_almaty_now().date()\n    else:\n        base_date = datetime.now(tz).date()\n    \n    target_date = base_date - timedelta(days=days)\n    return target_date.isoformat()\n\n\ndef format_datetime_for_report(dt: datetime, include_time: bool = True) -> str:\n    \"\"\"\n    Format datetime for reports in Russian locale.\n    \n    Args:\n        dt: Datetime to format\n        include_time: Whether to include time component\n        \n    Returns:\n        str: Formatted datetime string\n    \"\"\"\n    # Convert to Almaty timezone if needed\n    if dt.tzinfo is None:\n        dt = UTC_TZ.localize(dt)\n    \n    almaty_dt = dt.astimezone(ALMATY_TZ)\n    \n    months_ru = [\n        'ÑÐ½Ð²Ð°Ñ€Ñ', 'Ñ„ÐµÐ²Ñ€Ð°Ð»Ñ', 'Ð¼Ð°Ñ€Ñ‚Ð°', 'Ð°Ð¿Ñ€ÐµÐ»Ñ', 'Ð¼Ð°Ñ', 'Ð¸ÑŽÐ½Ñ',\n        'Ð¸ÑŽÐ»Ñ', 'Ð°Ð²Ð³ÑƒÑÑ‚Ð°', 'ÑÐµÐ½Ñ‚ÑÐ±Ñ€Ñ', 'Ð¾ÐºÑ‚ÑÐ±Ñ€Ñ', 'Ð½Ð¾ÑÐ±Ñ€Ñ', 'Ð´ÐµÐºÐ°Ð±Ñ€Ñ'\n    ]\n    \n    day = almaty_dt.day\n    month = months_ru[almaty_dt.month - 1]\n    year = almaty_dt.year\n    \n    if include_time:\n        hour = almaty_dt.hour\n        minute = almaty_dt.minute\n        return f\"{day} {month} {year} Ð³. Ð² {hour:02d}:{minute:02d}\"\n    else:\n        return f\"{day} {month} {year} Ð³.\"\n\n\ndef parse_iso_datetime(iso_string: str) -> datetime:\n    \"\"\"\n    Parse ISO datetime string to timezone-aware datetime object.\n    \n    Args:\n        iso_string: ISO format datetime string\n        \n    Returns:\n        datetime: Parsed datetime object (always timezone-aware UTC)\n        \n    Raises:\n        ValueError: If the input string is not a valid ISO datetime\n    \"\"\"\n    try:\n        # Try parsing with timezone info\n        dt = datetime.fromisoformat(iso_string)\n    except ValueError:\n        try:\n            # Fallback: handle 'Z' suffix and other common formats\n            dt = datetime.fromisoformat(iso_string.replace('Z', '+00:00'))\n        except ValueError:\n            raise ValueError(f\"Invalid ISO datetime string: {iso_string}\")\n    \n    # Ensure timezone-aware (assume UTC if naive)\n    if dt.tzinfo is None:\n        dt = UTC_TZ.localize(dt)\n    \n    # Convert to UTC for consistency\n    return dt.astimezone(UTC_TZ)\n\n\ndef get_week_start_date(target_date: Optional[Union[date, str]] = None) -> str:\n    \"\"\"\n    Get the start date of the week (Monday) for the given date.\n    \n    Args:\n        target_date: Target date (default: today)\n        \n    Returns:\n        str: Week start date in YYYY-MM-DD format\n    \"\"\"\n    if target_date is None:\n        target_date = get_almaty_now().date()\n    elif isinstance(target_date, str):\n        target_date = date.fromisoformat(target_date)\n    \n    # Calculate days since Monday (0=Monday, 6=Sunday)\n    days_since_monday = target_date.weekday()\n    week_start = target_date - timedelta(days=days_since_monday)\n    \n    return week_start.isoformat()\n\n\ndef get_month_start_date(target_date: Optional[Union[date, str]] = None) -> str:\n    \"\"\"\n    Get the start date of the month for the given date.\n    \n    Args:\n        target_date: Target date (default: today)\n        \n    Returns:\n        str: Month start date in YYYY-MM-DD format\n    \"\"\"\n    if target_date is None:\n        target_date = get_almaty_now().date()\n    elif isinstance(target_date, str):\n        target_date = date.fromisoformat(target_date)\n    \n    month_start = target_date.replace(day=1)\n    return month_start.isoformat()\n\n\ndef get_date_range_days(start_date: str, end_date: str) -> int:\n    \"\"\"\n    Calculate number of days between two dates.\n    \n    Args:\n        start_date: Start date in YYYY-MM-DD format\n        end_date: End date in YYYY-MM-DD format\n        \n    Returns:\n        int: Number of days between dates\n    \"\"\"\n    start = date.fromisoformat(start_date)\n    end = date.fromisoformat(end_date)\n    \n    return (end - start).days\n\n\ndef is_valid_date_string(date_string: str) -> bool:\n    \"\"\"\n    Check if string is a valid ISO date.\n    \n    Args:\n        date_string: Date string to validate\n        \n    Returns:\n        bool: True if valid ISO date format\n    \"\"\"\n    try:\n        date.fromisoformat(date_string)\n        return True\n    except ValueError:\n        return False\n\n\ndef get_retention_check_dates(retention_days: int, check_date: Optional[str] = None) -> list[str]:\n    \"\"\"\n    Get list of dates that need retention checks for the given retention period.\n    \n    Args:\n        retention_days: Number of days for retention check (e.g., 7, 14, 30)\n        check_date: Date to check from (default: today)\n        \n    Returns:\n        list[str]: List of dates that need retention checks\n    \"\"\"\n    if check_date is None:\n        check_date = get_today_date_str()\n    \n    check_date_obj = date.fromisoformat(check_date)\n    target_date = check_date_obj - timedelta(days=retention_days)\n    \n    return [target_date.isoformat()]\n\n\ndef format_time_period_ru(days: int) -> str:\n    \"\"\"\n    Format time period in Russian with correct pluralization.\n    \n    Args:\n        days: Number of days\n        \n    Returns:\n        str: Formatted period in Russian\n    \"\"\"\n    if days == 1:\n        return \"1 Ð´ÐµÐ½ÑŒ\"\n    \n    # Special case for numbers ending in 11-14 (e.g., 11, 12, 13, 14, 111, 112, etc.)\n    if days % 100 in [11, 12, 13, 14]:\n        return f\"{days} Ð´Ð½ÐµÐ¹\"\n    elif days % 10 == 1:\n        return f\"{days} Ð´ÐµÐ½ÑŒ\"\n    elif days % 10 in [2, 3, 4]:\n        return f\"{days} Ð´Ð½Ñ\"\n    else:\n        return f\"{days} Ð´Ð½ÐµÐ¹\"","size_bytes":7564},"src/mastra/index.ts":{"content":"import { Mastra } from \"@mastra/core\";\nimport { MastraError } from \"@mastra/core/error\";\nimport { PinoLogger } from \"@mastra/loggers\";\nimport { LogLevel, MastraLogger } from \"@mastra/core/logger\";\nimport pino from \"pino\";\nimport { MCPServer } from \"@mastra/mcp\";\nimport { NonRetriableError } from \"inngest\";\nimport { z } from \"zod\";\n\nimport { sharedPostgresStorage } from \"./storage\";\nimport { inngest, inngestServe } from \"./inngest\";\n\nclass ProductionPinoLogger extends MastraLogger {\n  protected logger: pino.Logger;\n\n  constructor(\n    options: {\n      name?: string;\n      level?: LogLevel;\n    } = {},\n  ) {\n    super(options);\n\n    this.logger = pino({\n      name: options.name || \"app\",\n      level: options.level || LogLevel.INFO,\n      base: {},\n      formatters: {\n        level: (label: string, _number: number) => ({\n          level: label,\n        }),\n      },\n      timestamp: () => `,\"time\":\"${new Date(Date.now()).toISOString()}\"`,\n    });\n  }\n\n  debug(message: string, args: Record<string, any> = {}): void {\n    this.logger.debug(args, message);\n  }\n\n  info(message: string, args: Record<string, any> = {}): void {\n    this.logger.info(args, message);\n  }\n\n  warn(message: string, args: Record<string, any> = {}): void {\n    this.logger.warn(args, message);\n  }\n\n  error(message: string, args: Record<string, any> = {}): void {\n    this.logger.error(args, message);\n  }\n}\n\nexport const mastra = new Mastra({\n  storage: sharedPostgresStorage,\n  agents: {},\n  workflows: {},\n  mcpServers: {\n    allTools: new MCPServer({\n      name: \"allTools\",\n      version: \"1.0.0\",\n      tools: {},\n    }),\n  },\n  bundler: {\n    // A few dependencies are not properly picked up by\n    // the bundler if they are not added directly to the\n    // entrypoint.\n    externals: [\n      \"@slack/web-api\",\n      \"inngest\",\n      \"inngest/hono\",\n      \"hono\",\n      \"hono/streaming\",\n    ],\n    // sourcemaps are good for debugging.\n    sourcemap: true,\n  },\n  server: {\n    host: \"0.0.0.0\",\n    port: process.env.PORT ? parseInt(process.env.PORT) : 5000,\n    middleware: [\n      async (c, next) => {\n        const mastra = c.get(\"mastra\");\n        const logger = mastra?.getLogger();\n        logger?.debug(\"[Request]\", { method: c.req.method, url: c.req.url });\n        try {\n          await next();\n        } catch (error) {\n          logger?.error(\"[Response]\", {\n            method: c.req.method,\n            url: c.req.url,\n            error,\n          });\n          if (error instanceof MastraError) {\n            if (error.id === \"AGENT_MEMORY_MISSING_RESOURCE_ID\") {\n              // This is typically a non-retirable error. It means that the request was not\n              // setup correctly to pass in the necessary parameters.\n              throw new NonRetriableError(error.message, { cause: error });\n            }\n          } else if (error instanceof z.ZodError) {\n            // Validation errors are never retriable.\n            throw new NonRetriableError(error.message, { cause: error });\n          }\n\n          throw error;\n        }\n      },\n    ],\n    apiRoutes: [\n      // Health check endpoint for deployment health checks\n      {\n        path: \"/healthz\",\n        method: \"GET\",\n        handler: async (c) => {\n          return c.json({ status: \"ok\", timestamp: new Date().toISOString() });\n        },\n      },\n      // This API route is used to register the Mastra workflow (inngest function) on the inngest server\n      {\n        path: \"/api/inngest\",\n        method: \"ALL\",\n        createHandler: async ({ mastra }) => inngestServe({ mastra, inngest }),\n        // The inngestServe function integrates Mastra workflows with Inngest by:\n        // 1. Creating Inngest functions for each workflow with unique IDs (workflow.${workflowId})\n        // 2. Setting up event handlers that:\n        //    - Generate unique run IDs for each workflow execution\n        //    - Create an InngestExecutionEngine to manage step execution\n        //    - Handle workflow state persistence and real-time updates\n        // 3. Establishing a publish-subscribe system for real-time monitoring\n        //    through the workflow:${workflowId}:${runId} channel\n      },\n    ],\n  },\n  logger:\n    process.env.NODE_ENV === \"production\"\n      ? new ProductionPinoLogger({\n          name: \"Mastra\",\n          level: \"info\",\n        })\n      : new PinoLogger({\n          name: \"Mastra\",\n          level: \"info\",\n        }),\n});\n\n/*  Sanity check 1: Throw an error if there are more than 1 workflows.  */\n// !!!!!! Do not remove this check. !!!!!!\nif (Object.keys(mastra.getWorkflows()).length > 1) {\n  throw new Error(\n    \"More than 1 workflows found. Currently, more than 1 workflows are not supported in the UI, since doing so will cause app state to be inconsistent.\",\n  );\n}\n\n/*  Sanity check 2: Throw an error if there are more than 1 agents.  */\n// !!!!!! Do not remove this check. !!!!!!\nif (Object.keys(mastra.getAgents()).length > 1) {\n  throw new Error(\n    \"More than 1 agents found. Currently, more than 1 agents are not supported in the UI, since doing so will cause app state to be inconsistent.\",\n  );\n}\n","size_bytes":5117},"src/triggers/slackTriggers.ts":{"content":"import { format } from \"node:util\";\nimport { Mastra, type WorkflowResult } from \"@mastra/core\";\nimport { IMastraLogger } from \"@mastra/core/logger\";\nimport {\n  type AuthTestResponse,\n  type ChatPostMessageResponse,\n  type ConversationsOpenResponse,\n  type ConversationsRepliesResponse,\n  type UsersConversationsResponse,\n  type WebAPICallError,\n  ErrorCode,\n  WebClient,\n} from \"@slack/web-api\";\nimport type { Context, Handler, MiddlewareHandler } from \"hono\";\nimport { streamSSE } from \"hono/streaming\";\n\nimport { registerApiRoute } from \"../mastra/inngest\";\n\nexport type Methods = \"GET\" | \"POST\" | \"PUT\" | \"DELETE\" | \"PATCH\" | \"ALL\";\n\n// TODO: Remove when Mastra exports this type.\nexport type ApiRoute =\n  | {\n      path: string;\n      method: Methods;\n      handler: Handler;\n      middleware?: MiddlewareHandler | MiddlewareHandler[];\n    }\n  | {\n      path: string;\n      method: Methods;\n      createHandler: ({ mastra }: { mastra: Mastra }) => Promise<Handler>;\n      middleware?: MiddlewareHandler | MiddlewareHandler[];\n    };\n\nexport type TriggerInfoSlackOnNewMessage = {\n  type: \"slack/message.channels\";\n  params: {\n    channel: string;\n    channelDisplayName: string;\n  };\n  payload: any;\n};\n\ntype DiagnosisStep =\n  | {\n      status: \"pending\";\n      name: string;\n      extra?: Record<string, any>;\n    }\n  | {\n      status: \"success\";\n      name: string;\n      extra: Record<string, any>;\n    }\n  | {\n      status: \"failed\";\n      name: string;\n      error: string;\n      extra: Record<string, any>;\n    };\n\nexport async function getClient() {\n  let connectionSettings: any;\n  async function getAccessToken() {\n    if (\n      connectionSettings &&\n      connectionSettings.settings.expires_at &&\n      new Date(connectionSettings.settings.expires_at).getTime() > Date.now()\n    ) {\n      return {\n        token: connectionSettings.settings.access_token,\n        user: connectionSettings.settings.oauth?.credentials?.raw?.authed_user\n          ?.id,\n      };\n    }\n\n    const hostname = process.env.REPLIT_CONNECTORS_HOSTNAME;\n    const xReplitToken = process.env.REPL_IDENTITY\n      ? \"repl \" + process.env.REPL_IDENTITY\n      : process.env.WEB_REPL_RENEWAL\n        ? \"depl \" + process.env.WEB_REPL_RENEWAL\n        : null;\n\n    if (!xReplitToken) {\n      throw new Error(\"X_REPLIT_TOKEN not found for repl/depl\");\n    }\n\n    const res = await fetch(\n      \"https://\" +\n        hostname +\n        \"/api/v2/connection?include_secrets=true&connector_names=slack-agent\",\n      {\n        headers: {\n          Accept: \"application/json\",\n          X_REPLIT_TOKEN: xReplitToken,\n        },\n      },\n    );\n    const resJson = await res.json();\n    connectionSettings = resJson?.items?.[0];\n    if (!connectionSettings || !connectionSettings.settings.access_token) {\n      throw new Error(\n        `Slack not connected: HTTP ${res.status} ${res.statusText}: ${JSON.stringify(resJson)}`,\n      );\n    }\n    return {\n      token: connectionSettings.settings.access_token,\n      user: connectionSettings.settings.oauth?.credentials?.raw?.authed_user\n        ?.id,\n    };\n  }\n\n  const { token, user } = await getAccessToken();\n  const slack = new WebClient(token);\n\n  const response = await slack.auth.test();\n\n  return { slack, auth: response, user };\n}\n\n// Keep up to 200 recent events, to prevent duplicates\nconst recentEvents: string[] = [];\n\nfunction isWebAPICallError(err: unknown): err is WebAPICallError {\n  return (\n    err !== null && typeof err === \"object\" && \"code\" in err && \"data\" in err\n  );\n}\n\nfunction checkDuplicateEvent(eventName: string) {\n  if (recentEvents.includes(eventName)) {\n    return true;\n  }\n  recentEvents.push(eventName);\n  if (recentEvents.length > 200) {\n    recentEvents.shift();\n  }\n  return false;\n}\n\nfunction createReactToMessage({\n  slack,\n  logger,\n}: {\n  slack: WebClient;\n  logger: IMastraLogger;\n}) {\n  const addReaction = async (\n    channel: string,\n    timestamp: string,\n    emoji: string,\n  ) => {\n    logger.info(`[Slack] Adding reaction to message`, {\n      emoji,\n      timestamp,\n      channel,\n    });\n    try {\n      await slack.reactions.add({ channel, timestamp, name: emoji });\n    } catch (error) {\n      logger.error(`[Slack] Error adding reaction to message`, {\n        emoji,\n        timestamp,\n        channel,\n        error: format(error),\n      });\n    }\n  };\n\n  const removeAllReactions = async (channel: string, timestamp: string) => {\n    logger.info(`[Slack] Removing all reactions from message`, {\n      timestamp,\n      channel,\n    });\n    const emojis = [\n      \"hourglass\",\n      \"hourglass_flowing_sand\",\n      \"white_check_mark\",\n      \"x\",\n      \"alarm_clock\",\n    ];\n\n    for (const emoji of emojis) {\n      try {\n        await slack.reactions.remove({ channel, timestamp, name: emoji });\n      } catch (error) {\n        if (\n          isWebAPICallError(error) &&\n          (error.code !== ErrorCode.PlatformError ||\n            error.data?.error !== \"no_reaction\")\n        ) {\n          logger.error(\"[Slack] Error removing reaction\", {\n            emoji,\n            timestamp,\n            channel,\n            error: format(error),\n          });\n        }\n      }\n    }\n  };\n\n  return async function reactToMessage(\n    channel: string,\n    timestamp: string,\n    result: WorkflowResult<any, any> | null,\n  ) {\n    // Remove all of our reactions.\n    await removeAllReactions(channel, timestamp);\n    if (result?.status === \"success\") {\n      await addReaction(channel, timestamp, \"white_check_mark\");\n    } else if (result?.status === \"failed\") {\n      await addReaction(channel, timestamp, \"x\");\n    } else if (result !== null) {\n      await addReaction(channel, timestamp, \"alarm_clock\");\n    }\n  };\n}\n\nexport function registerSlackTrigger<\n  Env extends { Variables: { mastra: Mastra } },\n>({\n  triggerType,\n  handler,\n}: {\n  triggerType: string;\n  handler: (\n    mastra: Mastra,\n    triggerInfo: TriggerInfoSlackOnNewMessage,\n  ) => Promise<WorkflowResult<any, any> | null>;\n}): Array<ApiRoute> {\n  return [\n    registerApiRoute(\"/webhooks/slack/action\", {\n      method: \"POST\",\n      handler: async (c) => {\n        const mastra = c.get(\"mastra\");\n        const logger = mastra.getLogger();\n        try {\n          const payload = await c.req.json();\n          const { slack, auth } = await getClient();\n          const reactToMessage = createReactToMessage({ slack, logger });\n\n          // Handle challenge\n          if (payload && payload[\"challenge\"]) {\n            return c.text(payload[\"challenge\"], 200);\n          }\n\n          logger?.info(\"ðŸ“ [Slack] payload\", { payload });\n\n          // Augment event with channel info\n          if (payload && payload.event && payload.event.channel) {\n            try {\n              const result = await slack.conversations.info({\n                channel: payload.event.channel,\n              });\n              logger?.info(\"ðŸ“ [Slack] result\", { result });\n              payload.channel = result.channel;\n            } catch (error) {\n              logger?.error(\"Error fetching channel info\", {\n                error: format(error),\n              });\n              // Continue processing even if channel info fetch fails\n            }\n          }\n\n          // Check subtype\n          if (\n            payload.event?.subtype === \"message_changed\" ||\n            payload.event?.subtype === \"message_deleted\"\n          ) {\n            return c.text(\"OK\", 200);\n          }\n\n          if (\n            (payload.event?.channel_type === \"im\" &&\n              payload.event?.text === \"test:ping\") ||\n            payload.event?.text === `<@${auth.user_id}> test:ping`\n          ) {\n            // This is a test message to the bot saying just \"test:ping\", or a mention that contains \"test:ping\".\n            // We'll reply in the same thread.\n            await slack.chat.postMessage({\n              channel: payload.event.channel,\n              text: \"pong\",\n              thread_ts: payload.event.ts,\n            });\n            logger?.info(\"ðŸ“ [Slack] pong\");\n            return c.text(\"OK\", 200);\n          }\n\n          if (payload.event?.bot_id) {\n            return c.text(\"OK\", 200);\n          }\n\n          if (checkDuplicateEvent(payload.event_id)) {\n            return c.text(\"OK\", 200);\n          }\n\n          const result = await handler(mastra, {\n            type: triggerType,\n            params: {\n              channel: payload.event.channel,\n              channelDisplayName: payload.channel.name,\n            },\n            payload,\n          } as TriggerInfoSlackOnNewMessage);\n\n          await reactToMessage(payload.event.channel, payload.event.ts, result);\n\n          return c.text(\"OK\", 200);\n        } catch (error) {\n          logger?.error(\"Error handling Slack webhook\", {\n            error: format(error),\n          });\n          return c.text(\"Internal Server Error\", 500);\n        }\n      },\n    }),\n    {\n      path: \"/test/slack\",\n      method: \"GET\",\n      handler: async (c: Context<Env>) => {\n        return streamSSE(c, async (stream) => {\n          let id = 1;\n          const mastra = c.get(\"mastra\");\n          const logger = mastra.getLogger() ?? {\n            info: console.log,\n            error: console.error,\n          };\n\n          let diagnosisStepAuth: DiagnosisStep = {\n            status: \"pending\",\n            name: \"authentication with Slack\",\n          };\n          let diagnosisStepConversation: DiagnosisStep = {\n            status: \"pending\",\n            name: \"open a conversation with user\",\n          };\n          let diagnosisStepPostMessage: DiagnosisStep = {\n            status: \"pending\",\n            name: \"send a message to the user\",\n          };\n          let diagnosisStepReadReplies: DiagnosisStep = {\n            status: \"pending\",\n            name: \"read replies from bot\",\n          };\n          const updateDiagnosisSteps = async (event: string) =>\n            stream.writeSSE({\n              data: JSON.stringify([\n                diagnosisStepAuth,\n                diagnosisStepConversation,\n                diagnosisStepPostMessage,\n                diagnosisStepReadReplies,\n              ]),\n              event,\n              id: String(id++),\n            });\n\n          let slack: WebClient;\n          let auth: AuthTestResponse;\n          let user: string | undefined;\n          try {\n            ({ slack, auth, user } = await getClient());\n          } catch (error) {\n            logger?.error(\"âŒ [Slack] test:auth failed\", {\n              error: format(error),\n            });\n            diagnosisStepAuth = {\n              ...diagnosisStepAuth,\n              status: \"failed\",\n              error: \"authentication failed\",\n              extra: { error: format(error) },\n            };\n            await updateDiagnosisSteps(\"error\");\n            return;\n          }\n\n          if (!auth?.user_id) {\n            logger?.error(\"âŒ [Slack] test:auth not working\", {\n              auth,\n            });\n            diagnosisStepAuth = {\n              ...diagnosisStepAuth,\n              status: \"failed\",\n              error: \"authentication failed\",\n              extra: { auth },\n            };\n            await updateDiagnosisSteps(\"error\");\n            return;\n          }\n\n          diagnosisStepAuth = {\n            ...diagnosisStepAuth,\n            status: \"success\",\n            extra: { auth },\n          };\n          await updateDiagnosisSteps(\"progress\");\n\n          logger?.info(\"ðŸ“ [Slack] test:auth found\", { auth });\n\n          let channel: ConversationsOpenResponse[\"channel\"];\n          if (user) {\n            // Open a DM with itself.\n            let conversationsResponse: ConversationsOpenResponse;\n            try {\n              conversationsResponse = await slack.conversations.open({\n                users: user,\n              });\n            } catch (error) {\n              logger?.error(\"âŒ [Slack] test:conversation not found\", {\n                error: format(error),\n              });\n              diagnosisStepConversation = {\n                ...diagnosisStepConversation,\n                status: \"failed\",\n                error: \"opening a conversation failed\",\n                extra: { error: format(error) },\n              };\n              await updateDiagnosisSteps(\"error\");\n              return;\n            }\n\n            if (!conversationsResponse?.channel?.id) {\n              logger?.error(\"âŒ [Slack] test:conversation not found\", {\n                conversationsResponse,\n              });\n              diagnosisStepConversation = {\n                ...diagnosisStepConversation,\n                status: \"failed\",\n                error: \"conversation channel not found\",\n                extra: { conversationsResponse },\n              };\n              await updateDiagnosisSteps(\"error\");\n              return;\n            }\n\n            channel = conversationsResponse.channel;\n          } else {\n            // Find the first channel where the bot is installed.\n            let conversationsResponse: UsersConversationsResponse;\n            try {\n              conversationsResponse = await slack.users.conversations({\n                user: auth.user_id,\n              });\n            } catch (error) {\n              logger?.error(\"âŒ [Slack] test:conversation not found\", {\n                error: format(error),\n              });\n              diagnosisStepConversation = {\n                ...diagnosisStepConversation,\n                status: \"failed\",\n                error: \"opening a conversation failed\",\n                extra: { error: format(error) },\n              };\n              await updateDiagnosisSteps(\"error\");\n              return;\n            }\n\n            if (!conversationsResponse?.channels?.length) {\n              logger?.error(\"âŒ [Slack] test:channel not found\", {\n                conversationsResponse,\n              });\n              diagnosisStepConversation = {\n                ...diagnosisStepConversation,\n                status: \"failed\",\n                error: \"channel not found\",\n                extra: { conversationsResponse },\n              };\n              await updateDiagnosisSteps(\"error\");\n              return;\n            }\n            channel = conversationsResponse.channels![0]!;\n          }\n\n          if (!channel.id) {\n            logger?.error(\"âŒ [Slack] test:channel not found\", {\n              channel,\n            });\n            diagnosisStepConversation = {\n              ...diagnosisStepConversation,\n              status: \"failed\",\n              error: \"channel not found\",\n              extra: { channel },\n            };\n            await updateDiagnosisSteps(\"error\");\n            return;\n          }\n\n          diagnosisStepConversation = {\n            ...diagnosisStepConversation,\n            status: \"success\",\n            extra: { channel },\n          };\n          await updateDiagnosisSteps(\"progress\");\n\n          logger?.info(\"ðŸ“ [Slack] test:channel found\", { channel });\n\n          // Post a message in the DMs.\n          let message: ChatPostMessageResponse;\n          try {\n            message = await slack.chat.postMessage({\n              channel: channel.id,\n              text: `<@${auth.user_id}> test:ping`,\n            });\n          } catch (error) {\n            logger?.error(\"âŒ [Slack] test:message not posted\", {\n              error: format(error),\n            });\n            diagnosisStepPostMessage = {\n              ...diagnosisStepPostMessage,\n              status: \"failed\",\n              error: \"posting message failed\",\n              extra: { error: format(error) },\n            };\n            await updateDiagnosisSteps(\"error\");\n            return;\n          }\n\n          if (!message?.ts) {\n            logger?.error(\"âŒ [Slack] test:message not posted\", { message });\n            diagnosisStepPostMessage = {\n              ...diagnosisStepPostMessage,\n              status: \"failed\",\n              error: \"posting message missing timestamp\",\n              extra: { message },\n            };\n            await updateDiagnosisSteps(\"error\");\n            return;\n          }\n\n          logger?.info(\"ðŸ“ [Slack] test:ping sent\", { message });\n\n          diagnosisStepPostMessage = {\n            ...diagnosisStepPostMessage,\n            status: \"success\",\n            extra: { message },\n          };\n          await updateDiagnosisSteps(\"progress\");\n\n          const sleep = (ms: number) =>\n            new Promise((resolve) => setTimeout(resolve, ms));\n\n          // Wait for the bot to reply.\n          let lastReplies: ConversationsRepliesResponse | undefined = undefined;\n          for (let i = 0; i < 30; i++) {\n            await sleep(1000);\n            let replies: ConversationsRepliesResponse;\n            try {\n              replies = await slack.conversations.replies({\n                ts: message.ts,\n                channel: channel.id,\n              });\n            } catch (error) {\n              logger?.error(\"âŒ [Slack] test:replies not found\", { message });\n              diagnosisStepReadReplies = {\n                ...diagnosisStepReadReplies,\n                status: \"failed\",\n                error: \"replies not found\",\n                extra: { error: format(error) },\n              };\n              await updateDiagnosisSteps(\"error\");\n              return;\n            }\n            logger?.info(\"ðŸ“ [Slack] test:replies\", { replies });\n            diagnosisStepReadReplies.extra = { replies };\n            lastReplies = replies;\n            if (replies?.messages?.some((m) => m.text === \"pong\")) {\n              // Victory!\n              logger?.info(\"ðŸ“ [Slack] test:pong successful\");\n              diagnosisStepReadReplies = {\n                ...diagnosisStepReadReplies,\n                status: \"success\",\n                extra: { replies },\n              };\n              await updateDiagnosisSteps(\"result\");\n              return;\n            }\n\n            await updateDiagnosisSteps(\"progress\");\n          }\n\n          logger?.error(\"âŒ [Slack] test:timeout\");\n\n          diagnosisStepReadReplies = {\n            ...diagnosisStepReadReplies,\n            status: \"failed\",\n            error: \"replies timed out\",\n            extra: { lastReplies },\n          };\n          await updateDiagnosisSteps(\"error\");\n        });\n      },\n    },\n  ];\n}\n","size_bytes":18261},"src/triggers/telegramTriggers.ts":{"content":"import type { ContentfulStatusCode } from \"hono/utils/http-status\";\n\nimport { registerApiRoute } from \"../mastra/inngest\";\nimport { Mastra } from \"@mastra/core\";\n\nif (!process.env.TELEGRAM_BOT_TOKEN) {\n  console.warn(\n    \"Trying to initialize Telegram triggers without TELEGRAM_BOT_TOKEN. Can you confirm that the Telegram integration is configured correctly?\",\n  );\n}\n\nexport type TriggerInfoTelegramOnNewMessage = {\n  type: \"telegram/message\";\n  params: {\n    userName: string;\n    message: string;\n  };\n  payload: any;\n};\n\nexport function registerTelegramTrigger({\n  triggerType,\n  handler,\n}: {\n  triggerType: string;\n  handler: (\n    mastra: Mastra,\n    triggerInfo: TriggerInfoTelegramOnNewMessage,\n  ) => Promise<void>;\n}) {\n  return [\n    registerApiRoute(\"/webhooks/telegram/action\", {\n      method: \"POST\",\n      handler: async (c) => {\n        const mastra = c.get(\"mastra\");\n        const logger = mastra.getLogger();\n        try {\n          const payload = await c.req.json();\n\n          logger?.info(\"ðŸ“ [Telegram] payload\", payload);\n\n          await handler(mastra, {\n            type: triggerType,\n            params: {\n              userName: payload.message.from.username,\n              message: payload.message.text,\n            },\n            payload,\n          } as TriggerInfoTelegramOnNewMessage);\n\n          return c.text(\"OK\", 200);\n        } catch (error) {\n          logger?.error(\"Error handling Telegram webhook:\", error);\n          return c.text(\"Internal Server Error\", 500);\n        }\n      },\n    }),\n  ];\n}\n","size_bytes":1545},"src/mastra/inngest/client.ts":{"content":"import { Inngest } from \"inngest\";\nimport { realtimeMiddleware } from \"@inngest/realtime\";\n\n// Use development configuration when NODE_ENV is not \"production\"\nexport const inngest = new Inngest(\n  process.env.NODE_ENV === \"production\"\n    ? {\n        id: \"replit-agent-workflow\",\n        name: \"Replit Agent Workflow System\",\n      }\n    : {\n        id: \"mastra\",\n        baseUrl: \"http://localhost:5000\",\n        isDev: true,\n        middleware: [realtimeMiddleware()],\n      },\n);\n","size_bytes":483},"src/mastra/inngest/index.ts":{"content":"import { inngest } from \"./client\";\nimport { init, InngestWorkflow } from \"@mastra/inngest\";\nimport { registerApiRoute as originalRegisterApiRoute } from \"@mastra/core/server\";\nimport { type Mastra } from \"@mastra/core\";\nimport { type Inngest, InngestFunction, NonRetriableError } from \"inngest\";\nimport { serve as originalInngestServe } from \"inngest/hono\";\n\n// Initialize Inngest with Mastra to get Inngest-compatible workflow helpers\nconst {\n  createWorkflow: originalCreateWorkflow,\n  createStep,\n  cloneStep,\n} = init(inngest);\n\nexport function createWorkflow(\n  params: Parameters<typeof originalCreateWorkflow>[0],\n): ReturnType<typeof originalCreateWorkflow> {\n  return originalCreateWorkflow({\n    ...params,\n    retryConfig: {\n      attempts: 3,\n      ...(params.retryConfig ?? {}),\n    },\n  });\n}\n\n// Export the Inngest client and Inngest-compatible workflow helpers\nexport { inngest, createStep, cloneStep };\n\nconst inngestFunctions: InngestFunction.Any[] = [];\n\n// Create a middleware for Inngest to be able to route triggers to Mastra directly.\nexport function registerApiRoute<P extends string>(\n  ...args: Parameters<typeof originalRegisterApiRoute<P>>\n): ReturnType<typeof originalRegisterApiRoute<P>> {\n  const [path, options] = args;\n  if (path.startsWith(\"/api/\") || typeof options !== \"object\") {\n    // This will throw an error.\n    return originalRegisterApiRoute(...args);\n  }\n  inngestFunctions.push(\n    inngest.createFunction(\n      {\n        id: `api-${path.replace(/^\\/+/, \"\").replaceAll(/\\/+/g, \"-\")}`,\n        name: path,\n      },\n      {\n        event: `event/api.${path.replace(/^\\/+/, \"\").replaceAll(/\\/+/g, \".\")}`,\n      },\n      async ({ event, step }) => {\n        await step.run(\"forward request to Mastra\", async () => {\n          // It is hard to obtain an internal handle on the Hono server,\n          // so we just forward the request to the local Mastra server.\n          const response = await fetch(`http://localhost:5000${path}`, {\n            method: event.data.method,\n            headers: event.data.headers,\n            body: event.data.body,\n          });\n\n          if (!response.ok) {\n            if (\n              (response.status >= 500 && response.status < 600) ||\n              response.status == 429 ||\n              response.status == 408\n            ) {\n              // 5XX, 429 (Rate-Limit Exceeded), 408 (Request Timeout) are retriable.\n              throw new Error(\n                `Failed to forward request to Mastra: ${response.statusText}`,\n              );\n            } else {\n              // All other errors are non-retriable.\n              throw new NonRetriableError(\n                `Failed to forward request to Mastra: ${response.statusText}`,\n              );\n            }\n          }\n        });\n      },\n    ),\n  );\n\n  return originalRegisterApiRoute(...args);\n}\n\nexport function registerCronWorkflow(cronExpression: string, workflow: any) {\n  const f = inngest.createFunction(\n    { id: \"cron-trigger\" },\n    [{ event: \"replit/cron.trigger\" }, { cron: cronExpression }],\n    async ({ event, step }) => {\n      const run = await workflow.createRunAsync();\n      const result = await run.start({ inputData: {} });\n      return result;\n    },\n  );\n  inngestFunctions.push(f);\n}\n\nexport function inngestServe({\n  mastra,\n  inngest,\n}: {\n  mastra: Mastra;\n  inngest: Inngest;\n}): ReturnType<typeof originalInngestServe> {\n  const wfs = mastra.getWorkflows();\n\n  const functions = new Set<InngestFunction.Any>();\n  for (const wf of Object.values(wfs)) {\n    if (!(wf instanceof InngestWorkflow)) {\n      continue;\n    }\n    wf.__registerMastra(mastra);\n    for (const f of wf.getFunctions()) {\n      functions.add(f);\n    }\n  }\n  for (const fn of inngestFunctions) {\n    functions.add(fn);\n  }\n  let serveHost: string | undefined = undefined;\n  if (process.env.NODE_ENV === \"production\") {\n    if (process.env.REPLIT_DOMAINS) {\n      serveHost = `https://${process.env.REPLIT_DOMAINS.split(\",\")[0]}`;\n    }\n  } else {\n    serveHost = \"http://localhost:5000\";\n  }\n  return originalInngestServe({\n    client: inngest,\n    functions: Array.from(functions),\n    serveHost,\n  });\n}\n","size_bytes":4156},"src/mastra/storage/index.ts":{"content":"import { PostgresStore } from \"@mastra/pg\";\n\n// Create a single shared PostgreSQL storage instance\n// In production, DATABASE_URL is required. Local fallback only for development.\nconst connectionString = process.env.DATABASE_URL || \n  (process.env.NODE_ENV === \"production\" \n    ? (() => { throw new Error(\"DATABASE_URL is required in production\"); })()\n    : \"postgresql://localhost:5432/mastra\");\n\nexport const sharedPostgresStorage = new PostgresStore({\n  connectionString,\n});\n","size_bytes":482},"bot_project/bot.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„Ð°Ð¹Ð» Telegram Ð±Ð¾Ñ‚Ð° Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð² Ñ‡Ð°Ñ‚Ð°Ñ….\n\nÐ¤ÑƒÐ½ÐºÑ†Ð¸Ð¸:\n- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÑÐµÑ… Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\n- ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¾Ð² ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´\n- Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ° Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n- Graceful shutdown Ð¿Ñ€Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ\n\"\"\"\n\nimport asyncio\nimport logging\nimport signal\nimport sys\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom aiogram import Bot, Dispatcher\nfrom aiogram.client.default import DefaultBotProperties\nfrom aiogram.enums import ParseMode\nfrom aiogram.webhook.aiohttp_server import SimpleRequestHandler, setup_application\nfrom aiohttp import web\nfrom dotenv import load_dotenv\n\n# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ñ‹ Ð¼Ð¾Ð´ÑƒÐ»ÐµÐ¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°\nfrom db.db import get_db, init_database\nfrom utils.logging_conf import setup_logging, get_logger\nfrom utils.time_utils import get_almaty_now\nfrom utils.adapter import init_adapters\nfrom handlers.events import events_router\nfrom handlers.commands import commands_router, initialize_admin_ids, initialize_scheduler\nfrom handlers.ui import ui_router\nfrom handlers.flows import flows_router\nfrom reports.scheduler import ReportScheduler\n\n# Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\nload_dotenv()\n\n# ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ\nsetup_logging()\nlogger = get_logger(__name__)\n\n# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÐµÐ¼\nbot: Optional[Bot] = None\ndp: Optional[Dispatcher] = None\nscheduler: Optional[ReportScheduler] = None\nweb_app: Optional[web.Application] = None\n\n\nasync def create_bot() -> Bot:\n    \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð±Ð¾Ñ‚Ð° Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸.\"\"\"\n    bot_token = os.getenv('BOT_TOKEN')\n    if not bot_token:\n        logger.error(\"âŒ BOT_TOKEN not found in environment variables\")\n        sys.exit(1)\n    \n    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð±Ð¾Ñ‚Ð° Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ\n    bot = Bot(\n        token=bot_token,\n        default=DefaultBotProperties(\n            parse_mode=ParseMode.MARKDOWN\n        )\n    )\n    \n    logger.info(f\"ðŸ¤– Bot created with token: {bot_token[:8]}...\")\n    return bot\n\n\nasync def setup_dispatcher() -> Dispatcher:\n    \"\"\"ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð´Ð¸ÑÐ¿ÐµÑ‚Ñ‡ÐµÑ€ Ñ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ð°Ð¼Ð¸ Ð¸ middleware.\"\"\"\n    dp = Dispatcher()\n    \n    # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ€Ð¾ÑƒÑ‚ÐµÑ€Ñ‹\n    dp.include_router(ui_router)        # UI Ñ inline ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð°Ð¼Ð¸ (Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚)\n    dp.include_router(flows_router)     # FSM flows Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²\n    dp.include_router(events_router)    # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ñ‡Ð°Ñ‚Ð°\n    dp.include_router(commands_router)  # Ð¡Ñ‚Ð°Ñ€Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ (fallback)\n    \n    logger.info(\"ðŸ“¡ Dispatcher configured with routers\")\n    return dp\n\n\nasync def initialize_database():\n    \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ….\"\"\"\n    try:\n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n        await init_database()\n        \n        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ\n        db = get_db()\n        db.get_user_stats_summary()\n        \n        logger.info(\"ðŸ’¾ Database initialized successfully\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Failed to initialize database: {e}\")\n        sys.exit(1)\n\n\nasync def initialize_components(bot: Bot):\n    \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²ÑÐµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹.\"\"\"\n    global scheduler\n    \n    try:\n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n        await initialize_database()\n        \n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€Ñ‹ Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸\n        init_adapters()\n        \n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð°Ð´Ð¼Ð¸Ð½Ð¾Ð² Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\n        initialize_admin_ids()\n        \n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\n        initialize_scheduler(bot)\n        \n        # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ\n        from handlers.commands import get_scheduler\n        scheduler = get_scheduler()\n        if scheduler:\n            await configure_scheduler_from_env(scheduler)\n        \n        logger.info(\"ðŸš€ All components initialized successfully\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Failed to initialize components: {e}\")\n        sys.exit(1)\n\n\nasync def configure_scheduler_from_env(scheduler: ReportScheduler):\n    \"\"\"ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ.\"\"\"\n    try:\n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\n        report_time_str = os.getenv('REPORT_TIME', '23:59')\n        target_chats_str = os.getenv('TARGET_CHATS', '')\n        scheduler_enabled = os.getenv('SCHEDULER_ENABLED', 'true').lower() == 'true'\n        report_types_str = os.getenv('REPORT_TYPES', 'daily')\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð²Ñ€ÐµÐ¼Ñ\n        try:\n            from datetime import time as time_class\n            hour, minute = map(int, report_time_str.split(':'))\n            report_time = time_class(hour, minute)\n        except ValueError:\n            logger.warning(f\"âš ï¸ Invalid REPORT_TIME format: {report_time_str}, using default 23:59\")\n            from datetime import time as time_class\n            report_time = time_class(23, 59)\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ‡Ð°Ñ‚Ñ‹\n        target_chats = []\n        if target_chats_str:\n            try:\n                target_chats = [int(chat_id.strip()) for chat_id in target_chats_str.split(',') if chat_id.strip()]\n            except ValueError:\n                logger.warning(f\"âš ï¸ Invalid TARGET_CHATS format: {target_chats_str}\")\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ñ‚Ð¸Ð¿Ñ‹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð²\n        report_types = [t.strip() for t in report_types_str.split(',') if t.strip()]\n        \n        # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\n        await scheduler.configure(\n            report_time=report_time,\n            target_chats=target_chats,\n            enabled=scheduler_enabled,\n            report_types=report_types\n        )\n        \n        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº ÐµÑÐ»Ð¸ Ð²ÐºÐ»ÑŽÑ‡Ñ‘Ð½ Ð¸ ÐµÑÑ‚ÑŒ Ñ‡Ð°Ñ‚Ñ‹\n        if scheduler_enabled and target_chats:\n            await scheduler.start()\n            logger.info(f\"â° Scheduler started: {report_time}, {len(target_chats)} chats\")\n        else:\n            logger.info(\"â¸ï¸ Scheduler configured but not started (disabled or no target chats)\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Failed to configure scheduler: {e}\")\n\n\nasync def setup_webhook_mode(bot: Bot, dp: Dispatcher) -> web.Application:\n    \"\"\"ÐÐ°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ webhook Ñ€ÐµÐ¶Ð¸Ð¼ (Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ð°).\"\"\"\n    webhook_url = os.getenv('WEBHOOK_URL')\n    webhook_path = os.getenv('WEBHOOK_PATH', '/webhook')\n    webhook_secret = os.getenv('WEBHOOK_SECRET')\n    port = int(os.getenv('PORT', 8080))\n    \n    if not webhook_url:\n        raise ValueError(\"WEBHOOK_URL is required for webhook mode\")\n    \n    # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ webhook\n    await bot.set_webhook(\n        url=f\"{webhook_url}{webhook_path}\",\n        secret_token=webhook_secret,\n        allowed_updates=dp.resolve_used_update_types()\n    )\n    \n    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð²ÐµÐ±-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ\n    app = web.Application()\n    \n    # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº webhook\n    webhook_requests_handler = SimpleRequestHandler(\n        dispatcher=dp,\n        bot=bot,\n        secret_token=webhook_secret\n    )\n    webhook_requests_handler.register(app, path=webhook_path)\n    \n    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ health check endpoint\n    async def health_check(request):\n        return web.json_response({\n            'status': 'ok',\n            'timestamp': get_almaty_now().isoformat(),\n            'bot_id': bot.id\n        })\n    \n    app.router.add_get('/health', health_check)\n    \n    logger.info(f\"ðŸ•¸ï¸ Webhook configured: {webhook_url}{webhook_path}\")\n    return app\n\n\nasync def run_polling_mode(bot: Bot, dp: Dispatcher):\n    \"\"\"Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð±Ð¾Ñ‚Ð° Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ polling (Ð´Ð»Ñ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸).\"\"\"\n    try:\n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ webhook ÐµÑÐ»Ð¸ Ð±Ñ‹Ð» ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½\n        await bot.delete_webhook(drop_pending_updates=True)\n        \n        logger.info(\"ðŸ”„ Starting bot in polling mode...\")\n        \n        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ polling Ñ ÑÐ²Ð½Ñ‹Ð¼ ÑƒÐºÐ°Ð·Ð°Ð½Ð¸ÐµÐ¼ allowed_updates Ð´Ð»Ñ chat_member ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\n        allowed_updates = [\n            \"message\", \"callback_query\", \"inline_query\", \"chosen_inline_result\",\n            \"chat_member\", \"my_chat_member\"  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²\n        ]\n        await dp.start_polling(\n            bot,\n            allowed_updates=allowed_updates,\n            drop_pending_updates=True\n        )\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Error in polling mode: {e}\")\n        raise\n\n\nasync def run_webhook_mode(bot: Bot, dp: Dispatcher):\n    \"\"\"Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð±Ð¾Ñ‚Ð° Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ webhook (Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ð°).\"\"\"\n    global web_app\n    \n    try:\n        # ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ webhook\n        web_app = await setup_webhook_mode(bot, dp)\n        \n        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²ÐµÐ±-ÑÐµÑ€Ð²ÐµÑ€\n        port = int(os.getenv('PORT', 8080))\n        host = os.getenv('HOST', '0.0.0.0')\n        \n        logger.info(f\"ðŸ•¸ï¸ Starting bot in webhook mode on {host}:{port}...\")\n        \n        runner = web.AppRunner(web_app)\n        await runner.setup()\n        \n        site = web.TCPSite(runner, host, port)\n        await site.start()\n        \n        logger.info(f\"âœ… Webhook server started on {host}:{port}\")\n        \n        # Ð–Ð´Ñ‘Ð¼ ÑÐ¸Ð³Ð½Ð°Ð»Ð° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸\n        stop_event = asyncio.Event()\n        \n        def signal_handler():\n            logger.info(\"ðŸ“¡ Received shutdown signal\")\n            stop_event.set()\n        \n        # Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²\n        if sys.platform != 'win32':\n            for sig in (signal.SIGTERM, signal.SIGINT):\n                asyncio.get_event_loop().add_signal_handler(sig, signal_handler)\n        \n        await stop_event.wait()\n        \n        # Graceful shutdown\n        await runner.cleanup()\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Error in webhook mode: {e}\")\n        raise\n\n\nasync def shutdown_components():\n    \"\"\"Graceful shutdown Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð².\"\"\"\n    global bot, scheduler, web_app\n    \n    logger.info(\"ðŸ›‘ Starting graceful shutdown...\")\n    \n    try:\n        # ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº\n        if scheduler:\n            await scheduler.stop()\n            logger.info(\"â° Scheduler stopped\")\n        \n        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²ÐµÐ±-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ\n        if web_app:\n            await web_app.cleanup()\n            logger.info(\"ðŸ•¸ï¸ Web application cleaned up\")\n        \n        # Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ Ð±Ð¾Ñ‚Ð°\n        if bot:\n            await bot.session.close()\n            logger.info(\"ðŸ¤– Bot session closed\")\n        \n        logger.info(\"âœ… Graceful shutdown completed\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Error during shutdown: {e}\")\n\n\nasync def main():\n    \"\"\"Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð±Ð¾Ñ‚Ð°.\"\"\"\n    global bot, dp\n    \n    try:\n        logger.info(\"ðŸš€ Starting Telegram Bot...\")\n        logger.info(f\"ðŸ“… Start time: {get_almaty_now()}\")\n        \n        # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð±Ð¾Ñ‚Ð° Ð¸ Ð´Ð¸ÑÐ¿ÐµÑ‚Ñ‡ÐµÑ€\n        bot = await create_bot()\n        dp = await setup_dispatcher()\n        \n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð²ÑÐµ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹\n        await initialize_components(bot)\n        \n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð±Ð¾Ñ‚Ðµ\n        bot_info = await bot.get_me()\n        logger.info(f\"ðŸ¤– Bot started: @{bot_info.username} ({bot_info.first_name})\")\n        \n        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÐµÐ¶Ð¸Ð¼ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹\n        webhook_mode = os.getenv('WEBHOOK_MODE', 'false').lower() == 'true'\n        \n        if webhook_mode:\n            await run_webhook_mode(bot, dp)\n        else:\n            await run_polling_mode(bot, dp)\n            \n    except KeyboardInterrupt:\n        logger.info(\"âŒ¨ï¸ Received keyboard interrupt\")\n    except Exception as e:\n        logger.exception(f\"âŒ Critical error in main: {e}\")\n        sys.exit(1)\n    finally:\n        await shutdown_components()\n\n\nif __name__ == '__main__':\n    try:\n        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Python Ð²ÐµÑ€ÑÐ¸ÑŽ\n        if sys.version_info < (3, 8):\n            logger.error(\"âŒ Python 3.8+ is required\")\n            sys.exit(1)\n        \n        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð³Ð»Ð°Ð²Ð½ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ\n        asyncio.run(main())\n        \n    except KeyboardInterrupt:\n        logger.info(\"ðŸ‘‹ Bot stopped by user\")\n    except Exception as e:\n        logger.exception(f\"âŒ Fatal error: {e}\")\n        sys.exit(1)","size_bytes":13145},"bot_project/start.sh":{"content":"#!/bin/bash\n\n# Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð·Ð°Ð¿ÑƒÑÐºÐ° Telegram Ð±Ð¾Ñ‚Ð°\n# ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ñ‹ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð¾ÑˆÐ¸Ð±Ð¾Ðº\n\nset -euo pipefail  # Ð¡Ñ‚Ñ€Ð¾Ð³Ð¸Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ bash\n\n# Ð¦Ð²ÐµÑ‚Ð° Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ\nlog() {\n    echo -e \"${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1\"\n}\n\nlog_error() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1\"\n}\n\nlog_warning() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING:${NC} $1\"\n}\n\nlog_success() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] SUCCESS:${NC} $1\"\n}\n\n# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°\nPROJECT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\ncd \"$PROJECT_DIR\"\n\nlog \"ðŸš€ Starting Telegram Bot...\"\nlog \"ðŸ“ Project directory: $PROJECT_DIR\"\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹\ncheck_dependencies() {\n    log \"ðŸ” Checking dependencies...\"\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Python\n    if ! command -v python3 &> /dev/null; then\n        log_error \"Python 3 is not installed\"\n        exit 1\n    fi\n    \n    local python_version=$(python3 -c 'import sys; print(\".\".join(map(str, sys.version_info[:2])))')\n    log \"ðŸ Python version: $python_version\"\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²ÐµÑ€ÑÐ¸ÑŽ Python (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð»Ñ Ð¼Ð°Ð¶Ð¾Ñ€Ð½Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸)\n    local major_version=$(echo \"$python_version\" | cut -d. -f1)\n    local minor_version=$(echo \"$python_version\" | cut -d. -f2)\n    \n    if [[ $major_version -lt 3 ]] || [[ $major_version -eq 3 && $minor_version -lt 8 ]]; then\n        log_error \"Python 3.8+ is required, found $python_version\"\n        exit 1\n    fi\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ pip\n    if ! command -v pip3 &> /dev/null; then\n        log_error \"pip3 is not installed\"\n        exit 1\n    fi\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹\ninstall_dependencies() {\n    log \"ðŸ“¦ Installing dependencies...\"\n    \n    if [[ ! -f \"requirements.txt\" ]]; then\n        log_error \"requirements.txt not found\"\n        exit 1\n    fi\n    \n    # Ð’ Nix Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÑƒ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹\n    log_warning \"Dependency installation skipped (using Nix packages)\"\n    log_success \"Dependencies managed by Nix environment\"\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\ncheck_environment() {\n    log \"ðŸ”§ Checking environment variables...\"\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ .env Ñ„Ð°Ð¹Ð»\n    if [[ ! -f \".env\" ]]; then\n        log_warning \".env file not found\"\n        if [[ -f \".env.example\" ]]; then\n            log \"ðŸ“‹ Copy .env.example to .env and configure it:\"\n            log \"   cp .env.example .env\"\n            log \"   nano .env\"\n        fi\n        log_error \"Please create .env file with required variables\"\n        exit 1\n    fi\n    \n    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ\n    set -a\n    source .env\n    set +a\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ\n    local required_vars=(\"BOT_TOKEN\")\n    local missing_vars=()\n    \n    for var in \"${required_vars[@]}\"; do\n        if [[ -z \"${!var:-}\" ]]; then\n            missing_vars+=(\"$var\")\n        fi\n    done\n    \n    if [[ ${#missing_vars[@]} -gt 0 ]]; then\n        log_error \"Missing required environment variables:\"\n        for var in \"${missing_vars[@]}\"; do\n            log_error \"  - $var\"\n        done\n        exit 1\n    fi\n    \n    log_success \"Environment variables OK\"\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\ninit_database() {\n    log \"ðŸ’¾ Initializing database...\"\n    \n    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚\n    mkdir -p data\n    \n    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n    if python3 -c \"\nimport asyncio\nimport sys\nsys.path.append('.')\nfrom db.db import init_database\n\nasync def main():\n    try:\n        await init_database()\n        print('Database initialized successfully')\n    except Exception as e:\n        print(f'Database initialization failed: {e}')\n        sys.exit(1)\n\nasyncio.run(main())\n\"; then\n        log_success \"Database initialized\"\n    else\n        log_error \"Failed to initialize database\"\n        exit 1\n    fi\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\ncheck_scheduler_config() {\n    log \"â° Checking scheduler configuration...\"\n    \n    if [[ -n \"${TARGET_CHATS:-}\" ]]; then\n        log \"ðŸ“¡ Target chats configured: $TARGET_CHATS\"\n    else\n        log_warning \"TARGET_CHATS not set - scheduler will not send reports automatically\"\n        log \"   Tip: Set TARGET_CHATS with your chat ID for automated daily reports\"\n    fi\n    \n    local report_time=\"${REPORT_TIME:-23:59}\"\n    log \"ðŸ• Report time: $report_time (Moscow timezone)\"\n    \n    local scheduler_enabled=\"${SCHEDULER_ENABLED:-true}\"\n    if [[ \"$scheduler_enabled\" == \"true\" ]]; then\n        log \"âœ… Scheduler enabled\"\n    else\n        log \"â¸ï¸ Scheduler disabled\"\n    fi\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ unified Excel ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\ncheck_unified_excel_system() {\n    log \"ðŸ“Š Checking unified Excel reporting system...\"\n    \n    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚\n    mkdir -p reports_output\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²\n    local required_files=(\n        \"reports/unified_excel_template.py\"\n        \"reports/unified_report_manager.py\"\n    )\n    \n    for file in \"${required_files[@]}\"; do\n        if [[ ! -f \"$file\" ]]; then\n            log_error \"Required unified Excel file missing: $file\"\n            exit 1\n        fi\n    done\n    \n    log \"âœ… Unified Excel system files OK\"\n    log \"ðŸ“ subscribers_report.xlsx will be created in reports_output/\"\n    log \"ðŸ“‹ Features: Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ, Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°, daily sheets (Ð”Ð”-ÐœÐœ-Ð“Ð“Ð“Ð“)\"\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ unified ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\ntest_unified_system() {\n    log \"ðŸ§ª Testing unified Excel reporting system...\"\n    \n    if python3 -c \"\nimport asyncio\nimport sys\nsys.path.append('.')\n\nasync def test_unified():\n    try:\n        from reports.unified_report_manager import UnifiedReportManager\n        from db.db import get_db\n        \n        # Initialize system\n        db = get_db()\n        unified_manager = UnifiedReportManager(db)\n        \n        # Test message generation\n        message_text, download_keyboard = unified_manager.get_daily_message_with_button()\n        \n        print('âœ… Unified system test passed')\n        print('ðŸ“Š Daily message format: OK')\n        print('ðŸ”— Download button: OK')\n        print('ðŸ“ Excel file path:', unified_manager.get_excel_file_path())\n        \n    except Exception as e:\n        print(f'âŒ Unified system test failed: {e}')\n        sys.exit(1)\n\nasyncio.run(test_unified())\n\"; then\n        log_success \"Unified Excel system test passed\"\n    else\n        log_error \"Unified Excel system test failed\"\n        exit 1\n    fi\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ð±Ð¾Ñ‚Ð°\nstart_bot() {\n    log \"ðŸ¤– Starting bot...\"\n    \n    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÐµÐ¶Ð¸Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐ°\n    local webhook_mode=\"${WEBHOOK_MODE:-false}\"\n    \n    if [[ \"$webhook_mode\" == \"true\" ]]; then\n        log \"ðŸ•¸ï¸ Running in webhook mode\"\n        if [[ -z \"${WEBHOOK_URL:-}\" ]]; then\n            log_error \"WEBHOOK_URL is required for webhook mode\"\n            exit 1\n        fi\n    else\n        log \"ðŸ”„ Running in polling mode\"\n    fi\n    \n    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð±Ð¾Ñ‚Ð°\n    exec python3 bot.py\n}\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð¿Ñ€Ð¸ Ð²Ñ‹Ñ…Ð¾Ð´Ðµ\ncleanup() {\n    log \"ðŸ§¹ Cleaning up...\"\n    \n    # Ð—Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ñ„Ð¾Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÑ‹\n    jobs -p | xargs -r kill\n    \n    log \"ðŸ‘‹ Bot stopped\"\n}\n\n# Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð½Ð° Ð²Ñ‹Ñ…Ð¾Ð´\ntrap cleanup EXIT INT TERM\n\n# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð¸\nshow_help() {\n    echo \"Telegram Bot Startup Script\"\n    echo \"\"\n    echo \"Usage: $0 [OPTIONS]\"\n    echo \"\"\n    echo \"Options:\"\n    echo \"  --install-deps     Install Python dependencies\"\n    echo \"  --init-db         Initialize database only\"\n    echo \"  --check           Check configuration without starting\"\n    echo \"  --test-unified    Test unified Excel reporting system\"\n    echo \"  --dev             Development mode (force polling)\"\n    echo \"  --prod            Production mode (force webhook if configured)\"\n    echo \"  --help            Show this help message\"\n    echo \"\"\n    echo \"Environment variables:\"\n    echo \"  BOT_TOKEN         Telegram bot token (required)\"\n    echo \"  WEBHOOK_MODE      Use webhook mode (true/false, default: false)\"\n    echo \"  WEBHOOK_URL       Webhook URL (required if webhook mode)\"\n    echo \"  TARGET_CHATS      Comma-separated chat IDs for unified Excel reports\"\n    echo \"  REPORT_TIME       Time to send daily reports (HH:MM, default: 23:59)\"\n    echo \"  SCHEDULER_ENABLED Enable automatic reports (true/false, default: true)\"\n    echo \"  ADMIN_IDS         Comma-separated admin user IDs\"\n    echo \"\"\n    echo \"Unified Excel System:\"\n    echo \"  ðŸ“Š Creates subscribers_report.xlsx with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ, Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheets\"\n    echo \"  ðŸ“… Daily sheets in Ð”Ð”-ÐœÐœ-Ð“Ð“Ð“Ð“ format\"\n    echo \"  â° Automated daily reports at 23:59 Moscow time\"\n    echo \"  ðŸ“¤ Download button in Telegram messages\"\n    echo \"  ðŸ§ª Test with: /test_unified command (admin only)\"\n    echo \"\"\n}\n\n# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸\nINSTALL_DEPS=false\nINIT_DB_ONLY=false\nCHECK_ONLY=false\nTEST_UNIFIED=false\nDEV_MODE=false\nPROD_MODE=false\n\nwhile [[ $# -gt 0 ]]; do\n    case $1 in\n        --install-deps)\n            INSTALL_DEPS=true\n            shift\n            ;;\n        --init-db)\n            INIT_DB_ONLY=true\n            shift\n            ;;\n        --check)\n            CHECK_ONLY=true\n            shift\n            ;;\n        --test-unified)\n            TEST_UNIFIED=true\n            shift\n            ;;\n        --dev)\n            DEV_MODE=true\n            export WEBHOOK_MODE=false\n            shift\n            ;;\n        --prod)\n            PROD_MODE=true\n            shift\n            ;;\n        --help)\n            show_help\n            exit 0\n            ;;\n        *)\n            log_error \"Unknown option: $1\"\n            show_help\n            exit 1\n            ;;\n    esac\ndone\n\n# ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ°\nmain() {\n    log \"ðŸ“‹ Telegram Bot Starting Sequence\"\n    log \"================================\"\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸\n    check_dependencies\n    \n    # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²ÐºÑƒ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹ Ð² Nix Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ð¸\n    if [[ \"$INSTALL_DEPS\" == \"true\" ]]; then\n        log_warning \"Skipping dependency installation (Nix environment)\"\n    fi\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ\n    check_environment\n    \n    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…\n    init_database\n    \n    # Ð•ÑÐ»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð‘Ð”\n    if [[ \"$INIT_DB_ONLY\" == \"true\" ]]; then\n        log_success \"Database initialization completed\"\n        exit 0\n    fi\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ unified Excel ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ\n    check_unified_excel_system\n    \n    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸ÐºÐ°\n    check_scheduler_config\n    \n    # Ð•ÑÐ»Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ unified ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹\n    if [[ \"$TEST_UNIFIED\" == \"true\" ]]; then\n        test_unified_system\n        log_success \"Unified system test completed\"\n        exit 0\n    fi\n    \n    # Ð•ÑÐ»Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°\n    if [[ \"$CHECK_ONLY\" == \"true\" ]]; then\n        log_success \"Configuration check completed\"\n        exit 0\n    fi\n    \n    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°Ð¿ÑƒÑÐºÐ¾Ð¼\n    log \"âœ… All checks passed\"\n    log \"ðŸš€ Starting bot in 3 seconds...\"\n    sleep 3\n    \n    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð±Ð¾Ñ‚Ð°\n    start_bot\n}\n\n# Ð—Ð°Ð¿ÑƒÑÐº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸\nmain \"$@\"","size_bytes":12307},"replit.md":{"content":"# Replit.md\n\n## Overview\n\nThis repository contains a multi-faceted agent framework built with Mastra, combining Telegram bot functionality with advanced agent orchestration capabilities. The project integrates:\n\n- **Telegram Bot System**: A comprehensive Python-based bot for chat activity tracking and reporting, featuring subscription/unsubscription monitoring, Excel report generation, and automated daily reporting\n- **Agent Framework**: A TypeScript-based system using Mastra for creating dynamic agents with runtime context adaptation, tool selection, and multi-model support\n- **Workflow Orchestration**: Inngest-powered workflow management with real-time capabilities and trigger-based automation\n- **Storage & Database**: PostgreSQL storage integration with optional SQLite fallback for the Telegram bot component\n\nThe architecture supports both standalone bot operations and integrated agent workflows, making it suitable for complex automation scenarios requiring both chat interaction and intelligent agent processing.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Technologies\n- **Frontend**: Mastra playground with real-time updates via SSE\n- **Backend**: Node.js with TypeScript, Python for Telegram bot\n- **Agents**: Mastra framework with dynamic configuration support\n- **Workflows**: Inngest for async processing and event handling\n- **Storage**: PostgreSQL primary, SQLite for bot data\n\n### Agent System Design\nThe agent architecture uses dynamic configuration patterns where agents adapt their behavior based on runtime context:\n- **Dynamic Instructions**: Agents modify their system prompts based on user context (subscription tier, language preferences)\n- **Model Selection**: Different AI models chosen dynamically (GPT-4 for enterprise, GPT-3.5 for others)\n- **Tool Access**: Context-driven tool availability (basic vs advanced analytics)\n- **Multi-Provider Support**: OpenAI and OpenRouter integration for model diversity\n\n### Telegram Bot Architecture\nThe bot system follows a modular approach:\n- **Event Handling**: Tracks chat member updates, subscription changes\n- **Database Layer**: SQLite with proper transaction management and connection pooling\n- **Report Generation**: Excel file creation with pandas/openpyxl, daily automated reports\n- **Scheduling**: APScheduler for time-based report delivery\n- **Logging**: Comprehensive logging with rotation and Almaty timezone handling (UTC+5)\n\n### Workflow Integration\n- **Trigger System**: API route registration for external webhook handling\n- **Event Processing**: Inngest functions for async workflow execution\n- **Real-time Updates**: SSE for live system monitoring\n- **Error Handling**: Retry mechanisms with exponential backoff\n\n### Storage Strategy\n- **Primary Storage**: PostgreSQL via DATABASE_URL for production scalability\n- **Bot Storage**: Local SQLite for rapid development and simple deployment\n- **File Storage**: Local filesystem for Excel reports and logs\n- **State Management**: Runtime context preservation across agent interactions\n\n### Development Environment\n- **Hot Reload**: File watching with automatic restart\n- **Type Safety**: Full TypeScript coverage with strict type checking\n- **Testing**: pytest for Python components, structured for async testing\n- **Deployment**: Replit-optimized with proper environment variable handling\n\nThe system is designed for both development flexibility and production robustness, with clear separation between the Telegram bot's Python ecosystem and the agent framework's TypeScript environment.\n\n## External Dependencies\n\n### AI & ML Services\n- **OpenAI**: GPT models for agent responses and reasoning\n- **OpenRouter**: Alternative model provider for diverse AI capabilities\n\n### Communication Platforms\n- **Telegram Bot API**: Message handling, webhook processing, chat management\n- **Slack API**: Channel monitoring, message posting, user interaction\n\n### Workflow & Infrastructure\n- **Inngest**: Async workflow orchestration, event processing, real-time features\n- **PostgreSQL**: Primary database for production data storage\n- **Exa**: Search and information retrieval capabilities\n\n### Data Processing\n- **Pandas**: Excel report generation and data manipulation\n- **OpenPyXL**: Excel file creation and formatting for bot reports\n- **SQLite**: Local database for Telegram bot data storage\n\n### Development Tools\n- **Mastra Framework**: Core agent orchestration and management\n- **APScheduler**: Time-based task scheduling for automated reports\n- **Pino**: Structured logging for system monitoring\n- **Zod**: Runtime type validation and schema definition\n\n### Optional Integrations\n- **MCP (Model Context Protocol)**: For advanced agent communication\n- **LibSQL**: Alternative database option for specific use cases\n- **Pytz**: Timezone handling for Almaty-based scheduling (UTC+5)\n\nThe system is architected to gracefully handle missing optional dependencies while requiring core services for full functionality.","size_bytes":5024},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.12\"\ndependencies = []\n","size_bytes":143},"bot_project/demo_bot.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐ”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Telegram Ð±Ð¾Ñ‚Ð° Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼ UI.\nÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°.\n\"\"\"\n\nimport os\nimport sys\n\ndef show_bot_structure():\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ ÑÐ¾Ð·Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð±Ð¾Ñ‚Ð°.\"\"\"\n    print(\"ðŸ¤– TELEGRAM BOT - ÐŸÐžÐ›ÐÐ«Ð™ Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡ Ð¡ ÐœÐ•ÐÐ®\")\n    print(\"=\" * 50)\n    print()\n    \n    print(\"ðŸ“ Ð¡Ð¢Ð Ð£ÐšÐ¢Ð£Ð Ð ÐŸÐ ÐžÐ•ÐšÐ¢Ð:\")\n    print(\"â”œâ”€â”€ utils/adapter.py       # ÐÐ´Ð°Ð¿Ñ‚ÐµÑ€Ñ‹ Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸\")\n    print(\"â”œâ”€â”€ handlers/ui.py         # UI Ñ inline ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð°Ð¼Ð¸\")  \n    print(\"â”œâ”€â”€ handlers/flows.py      # FSM flows Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²\")\n    print(\"â”œâ”€â”€ handlers/events.py     # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ Ñ‡Ð°Ñ‚Ð°\")\n    print(\"â”œâ”€â”€ handlers/commands.py   # ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹ Ð±Ð¾Ñ‚Ð°\")\n    print(\"â”œâ”€â”€ db/db.py              # Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… SQLite\")\n    print(\"â”œâ”€â”€ reports/              # Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² Excel\")\n    print(\"â””â”€â”€ bot.py                # Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð±Ð¾Ñ‚Ð°\")\n    print()\n    \n    print(\"ðŸ” ÐÐ”ÐœÐ˜Ð ÐœÐ•ÐÐ®:\")\n    print(\"âž• Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ\")\n    print(\"ðŸ‘¥ Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…\")\n    print(\"ðŸ“Š ÐžÑ‚Ñ‡Ñ‘Ñ‚Ñ‹ â†’ [Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ|ÐÐµÐ´ÐµÐ»Ñ|ÐœÐµÑÑÑ†|Excel]\")\n    print(\"ðŸ† Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹\")\n    print(\"ðŸ”Ž ÐÐ°Ð¹Ñ‚Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\") \n    print(\"ðŸ“ Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ\")\n    print(\"âŒ Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\")\n    print(\"ðŸ”” ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹\")\n    print(\"ðŸ“¤ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Excel\")\n    print()\n    \n    print(\"ðŸ‘¤ ÐŸÐžÐ›Ð¬Ð—ÐžÐ’ÐÐ¢Ð•Ð›Ð¬Ð¡ÐšÐžÐ• ÐœÐ•ÐÐ®:\")\n    print(\"ðŸ“¥ ÐœÐ¾Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÑ‘Ð½Ð½Ñ‹Ðµ\")\n    print(\"ðŸ† ÐœÐ¾Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\") \n    print(\"ðŸ“¤ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel (Ð¼Ð¾Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ)\")\n    print()\n    \n    print(\"ðŸ”„ FSM Ð”Ð˜ÐÐ›ÐžÐ“Ð˜:\")\n    print(\"âœ… Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº\")\n    print(\"âœ… ÐœÐ½Ð¾Ð³Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹\")\n    print(\"âœ… ÐŸÐ¾Ð¸ÑÐº Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹\")\n    print(\"âœ… ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²\")\n    print(\"âœ… Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°Ð¼Ð¸\")\n    print()\n    \n    print(\"ðŸ“Š Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ ÐžÐ¢Ð§Ð•Ð¢ÐžÐ’:\")\n    print(\"âœ… Excel Ð¾Ñ‚Ñ‡ÐµÑ‚Ñ‹ (Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ, Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°, Ð”Ð½ÐµÐ²Ð½Ñ‹Ðµ)\")\n    print(\"âœ… ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ð¾ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸ÑŽ\")\n    print(\"âœ… Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹\")\n    print(\"âœ… ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\")\n    print()\n    \n    print(\"ðŸ›¡ï¸ Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐžÐ¡Ð¢Ð¬:\")\n    print(\"âœ… ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¿Ñ€Ð°Ð² Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°\")\n    print(\"âœ… Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¾Ð³Ð¾ Ð²Ð²Ð¾Ð´Ð°\")\n    print(\"âœ… ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº\")\n    print(\"âœ… Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²ÑÐµÑ… Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹\")\n    print()\n    \n    print(\"ðŸ’¾ Ð‘ÐÐ—Ð Ð”ÐÐÐÐ«Ð¥:\")\n    print(\"âœ… users - Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ Telegram\")\n    print(\"âœ… inviters - Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ð¸ Ð¸ ÑÑÑ‹Ð»ÐºÐ¸\")\n    print(\"âœ… journal - Ð¶ÑƒÑ€Ð½Ð°Ð» Ð²ÑÐµÑ… ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\")\n    print(\"âœ… retention_checks - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\")\n    print()\n    \n    print(\"ðŸš€ Ð”Ð›Ð¯ Ð—ÐÐŸÐ£Ð¡ÐšÐ ÐÐ Ð¡Ð•Ð Ð’Ð•Ð Ð•:\")\n    print(\"1. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸: pip install -r requirements.txt\")\n    print(\"2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ .env Ñ„Ð°Ð¹Ð» Ñ BOT_TOKEN\")\n    print(\"3. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ: python3 bot.py\")\n    print()\n    print(\"âœ¨ Ð’Ð¡Ð• Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ Ð Ð•ÐÐ›Ð˜Ð—ÐžÐ’ÐÐÐ« Ð¡ÐžÐ“Ð›ÐÐ¡ÐÐž Ð¢Ð—!\")\n\nif __name__ == \"__main__\":\n    try:\n        show_bot_structure()\n        print(\"\\nðŸ” ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²...\")\n        \n        # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð°ÑˆÐ¸ Ð¼Ð¾Ð´ÑƒÐ»Ð¸\n        sys.path.append('.')\n        \n        from utils.adapter import init_adapters\n        print(\"âœ… utils.adapter imported\")\n        \n        from handlers.ui import ui_router\n        print(\"âœ… handlers.ui imported\")\n        \n        from handlers.flows import flows_router  \n        print(\"âœ… handlers.flows imported\")\n        \n        print(\"\\nðŸŽ‰ Ð’Ð¡Ð• ÐœÐžÐ”Ð£Ð›Ð˜ Ð˜ÐÐ¢Ð•Ð Ð¤Ð•Ð™Ð¡Ð Ð£Ð¡ÐŸÐ•Ð¨ÐÐž Ð¡ÐžÐ—Ð”ÐÐÐ«!\")\n        print(\"\\nÐ”Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑÑ Python Ð¿Ð°ÐºÐµÑ‚Ñ‹:\")\n        print(\"- aiogram (Telegram Bot API)\")\n        print(\"- pandas, openpyxl (Excel Ð¾Ñ‚Ñ‡ÐµÑ‚Ñ‹)\")\n        print(\"- python-dotenv (ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ)\")\n        print(\"- apscheduler (Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº)\")\n        \n    except ImportError as e:\n        print(f\"âš ï¸ Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚ Ð¼Ð¾Ð´ÑƒÐ»Ñ Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÑ: {e}\")\n        print(\"Ð­Ñ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð² Nix Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ð¸ Ð±ÐµÐ· ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð°ÐºÐµÑ‚Ð¾Ð²\")\n        print(\"ÐÐ° ÑÐµÑ€Ð²ÐµÑ€Ðµ Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑÐ¼Ð¸ Ð²ÑÑ‘ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ!\")\n    except Exception as e:\n        print(f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}\")","size_bytes":5264},"bot_project/handlers/flows.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nFSM flows Ð´Ð»Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ð² Telegram Ð±Ð¾Ñ‚Ðµ.\nÐ ÐµÐ°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ð¼Ð½Ð¾Ð³Ð¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¸ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ, ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸.\n\"\"\"\n\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\n\nfrom aiogram import Router, F\nfrom aiogram.types import Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton\nfrom aiogram.fsm.context import FSMContext\nfrom aiogram.fsm.state import State, StatesGroup\n\nfrom handlers.commands import is_admin\nfrom handlers.ui import UIStates, back_kb, main_admin_kb, confirm_delete_kb\nfrom utils.adapter import add_user_manual, delete_user, find_user, get_settings_manager\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ€Ð¾ÑƒÑ‚ÐµÑ€ Ð´Ð»Ñ flows\nflows_router = Router(name=\"flows\")\n\n\n# === MANUAL ADD USER FLOW ===\n\n@flows_router.callback_query(F.data == \"menu:manual_add\")\nasync def start_manual_add_flow(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"ðŸ“ **Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ**\\n\\n\"\n        \"Ð¨Ð°Ð³ 1 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Telegram ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_user_id)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_user_id)\nasync def handle_user_id_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° user ID.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        user_id_str = message.text.strip()\n        user_id = int(user_id_str)\n        \n        if user_id <= 0:\n            raise ValueError(\"Invalid user ID\")\n        \n        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ user_id Ð² ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸\n        await state.update_data(tg_user_id=user_id)\n        \n        text = (\n            f\"âœ… User ID: `{user_id}`\\n\\n\"\n            \"Ð¨Ð°Ð³ 2 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ username (Ð±ÐµÐ· @) Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ:\"\n        )\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÑƒ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°\n        skip_kb = InlineKeyboardMarkup(inline_keyboard=[\n            [InlineKeyboardButton(text=\"â­ ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ\", callback_data=\"skip:username\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ])\n        \n        await message.answer(text, reply_markup=skip_kb, parse_mode=\"Markdown\")\n        await state.set_state(UIStates.waiting_username)\n        \n    except ValueError:\n        await message.reply(\n            \"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚. Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ Telegram ID:\",\n            reply_markup=back_kb()\n        )\n\n\n@flows_router.message(UIStates.waiting_username)\nasync def handle_username_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° username.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    username = message.text.strip()\n    \n    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ @ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ\n    if username.startswith('@'):\n        username = username[1:]\n    \n    await state.update_data(username=username if username else None)\n    \n    data = await state.get_data()\n    user_id = data.get('tg_user_id')\n    \n    text = (\n        f\"âœ… User ID: `{user_id}`\\n\"\n        f\"âœ… Username: {f'@{username}' if username else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½'}\\n\\n\"\n        \"Ð¨Ð°Ð³ 3 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ:\"\n    )\n    \n    skip_kb = InlineKeyboardMarkup(inline_keyboard=[\n        [InlineKeyboardButton(text=\"â­ ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ\", callback_data=\"skip:name\")],\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ])\n    \n    await message.answer(text, reply_markup=skip_kb, parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_user_name)\n\n\n@flows_router.callback_query(F.data == \"skip:username\")\nasync def skip_username(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð²Ð²Ð¾Ð´ username.\"\"\"\n    await state.update_data(username=None)\n    \n    data = await state.get_data()\n    user_id = data.get('tg_user_id')\n    \n    text = (\n        f\"âœ… User ID: `{user_id}`\\n\"\n        f\"âœ… Username: Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½\\n\\n\"\n        \"Ð¨Ð°Ð³ 3 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ:\"\n    )\n    \n    skip_kb = InlineKeyboardMarkup(inline_keyboard=[\n        [InlineKeyboardButton(text=\"â­ ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ\", callback_data=\"skip:name\")],\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ])\n    \n    await callback.message.edit_text(text, reply_markup=skip_kb, parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_user_name)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_user_name)\nasync def handle_user_name_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    name = message.text.strip()\n    await state.update_data(name=name if name else None)\n    \n    data = await state.get_data()\n    user_id = data.get('tg_user_id')\n    username = data.get('username')\n    \n    text = (\n        f\"âœ… User ID: `{user_id}`\\n\"\n        f\"âœ… Username: {f'@{username}' if username else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½'}\\n\"\n        f\"âœ… Ð˜Ð¼Ñ: {name if name else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾'}\\n\\n\"\n        \"Ð¨Ð°Ð³ 4 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ:\"\n    )\n    \n    skip_kb = InlineKeyboardMarkup(inline_keyboard=[\n        [InlineKeyboardButton(text=\"â­ ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ\", callback_data=\"skip:inviter\")],\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ])\n    \n    await message.answer(text, reply_markup=skip_kb, parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_inviter)\n\n\n@flows_router.callback_query(F.data == \"skip:name\")\nasync def skip_name(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð²Ð²Ð¾Ð´ Ð¸Ð¼ÐµÐ½Ð¸.\"\"\"\n    await state.update_data(name=None)\n    \n    data = await state.get_data()\n    user_id = data.get('tg_user_id')\n    username = data.get('username')\n    \n    text = (\n        f\"âœ… User ID: `{user_id}`\\n\"\n        f\"âœ… Username: {f'@{username}' if username else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½'}\\n\"\n        f\"âœ… Ð˜Ð¼Ñ: Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾\\n\\n\"\n        \"Ð¨Ð°Ð³ 4 Ð¸Ð· 4: Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ:\"\n    )\n    \n    skip_kb = InlineKeyboardMarkup(inline_keyboard=[\n        [InlineKeyboardButton(text=\"â­ ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ\", callback_data=\"skip:inviter\")],\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ])\n    \n    await callback.message.edit_text(text, reply_markup=skip_kb, parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_inviter)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_inviter)\nasync def handle_inviter_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ñ.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        inviter_name = message.text.strip()\n        \n        data = await state.get_data()\n        data['inviter_name'] = inviter_name if inviter_name else None\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n        success = add_user_manual(data)\n        \n        if success:\n            text = (\n                \"âœ… **ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½!**\\n\\n\"\n                f\"ðŸ‘¤ User ID: `{data['tg_user_id']}`\\n\"\n                f\"ðŸ‘¤ Username: {'@' + data['username'] if data.get('username') else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½'}\\n\"\n                f\"ðŸ‘¤ Ð˜Ð¼Ñ: {data.get('name', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾')}\\n\"\n                f\"ðŸ‘¤ ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ: {data.get('inviter_name', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½')}\\n\"\n            )\n        else:\n            text = \"âŒ **ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ**\\n\\nÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.\"\n        \n        await message.answer(text, reply_markup=main_admin_kb(), parse_mode=\"Markdown\")\n        await state.clear()\n        \n        if success:\n            logger.info(f\"Manually added user {data['tg_user_id']} by admin {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error in manual add flow: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\")\n\n\n@flows_router.callback_query(F.data == \"skip:inviter\")\nasync def skip_inviter(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð²Ð²Ð¾Ð´ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ.\"\"\"\n    try:\n        data = await state.get_data()\n        data['inviter_name'] = None\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n        success = add_user_manual(data)\n        \n        if success:\n            text = (\n                \"âœ… **ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½!**\\n\\n\"\n                f\"ðŸ‘¤ User ID: `{data['tg_user_id']}`\\n\"\n                f\"ðŸ‘¤ Username: {'@' + data['username'] if data.get('username') else 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½'}\\n\"\n                f\"ðŸ‘¤ Ð˜Ð¼Ñ: {data.get('name', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾')}\\n\"\n                f\"ðŸ‘¤ ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ: Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½\\n\"\n            )\n        else:\n            text = \"âŒ **ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ**\\n\\nÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.\"\n        \n        await callback.message.edit_text(text, reply_markup=main_admin_kb(), parse_mode=\"Markdown\")\n        await state.clear()\n        await callback.answer(\"âœ… ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½!\")\n        \n        if success:\n            logger.info(f\"Manually added user {data['tg_user_id']} by admin {callback.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error in manual add flow: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸\", show_alert=True)\n\n\n# === DELETE USER FLOW ===\n\n@flows_router.callback_query(F.data == \"menu:delete_user\")\nasync def start_delete_user_flow(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"âŒ **Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ**\\n\\n\"\n        \"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ @username Ð¸Ð»Ð¸ user_id Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_delete_user)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_delete_user)\nasync def handle_delete_user_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        search_query = message.text.strip()\n        user_data = find_user(search_query)\n        \n        if not user_data:\n            await message.reply(\n                f\"âŒ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ '{search_query}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.\\n\\nÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·:\",\n                reply_markup=back_kb()\n            )\n            return\n        \n        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð´Ð»Ñ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ\n        await state.update_data(\n            search_query=search_query,\n            user_data=user_data\n        )\n        \n        username_display = f\"@{user_data.get('username')}\" if user_data.get('username') else f\"ID: {user_data['tg_user_id']}\"\n        name_display = user_data.get('name', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾')\n        \n        text = (\n            f\"âš ï¸ **ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ**\\n\\n\"\n            f\"Ð’Ñ‹ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ?\\n\\n\"\n            f\"ðŸ‘¤ **{username_display}**\\n\"\n            f\"ðŸ“ Ð˜Ð¼Ñ: {name_display}\\n\"\n            f\"ðŸ“Š ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ¾Ðº: {user_data.get('subscribe_count', 0)}\\n\"\n            f\"ðŸ“Š ÐžÑ‚Ð¿Ð¸ÑÐ¾Ðº: {user_data.get('unsubscribe_count', 0)}\\n\\n\"\n            \"â—ï¸ Ð­Ñ‚Ð¾ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ Ð½ÐµÐ»ÑŒÐ·Ñ Ð¾Ñ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ!\"\n        )\n        \n        await message.answer(\n            text, \n            reply_markup=confirm_delete_kb(search_query), \n            parse_mode=\"Markdown\"\n        )\n        await state.set_state(UIStates.waiting_delete_confirm)\n        \n    except Exception as e:\n        logger.exception(f\"Error in delete user flow: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¸ÑÐºÐµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\")\n\n\n@flows_router.callback_query(F.data.startswith(\"confirm:delete:\"))\nasync def handle_delete_confirmation(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ username Ð¸Ð· callback data\n        search_query = callback.data.split(\":\", 2)[2]\n        \n        success = delete_user(search_query)\n        \n        if success:\n            text = f\"âœ… **ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ {search_query} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½!**\"\n            await callback.answer(\"âœ… ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ´Ð°Ð»ÐµÐ½!\")\n        else:\n            text = f\"âŒ **ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {search_query}**\"\n            await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸\", show_alert=True)\n        \n        await callback.message.edit_text(text, reply_markup=main_admin_kb(), parse_mode=\"Markdown\")\n        await state.clear()\n        \n        if success:\n            logger.info(f\"Deleted user {search_query} by admin {callback.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error confirming delete: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸\", show_alert=True)\n\n\n# === SETTINGS FLOW ===\n\n@flows_router.callback_query(F.data == \"menu:settings\")\nasync def handle_settings_menu(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐœÐµÐ½ÑŽ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        settings = get_settings_manager().get_current_settings()\n        \n        text = (\n            \"ðŸ”” **ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹**\\n\\n\"\n            f\"â° Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²: {settings['report_time']}\\n\"\n            f\"ðŸ‘¥ ÐŸÐ¾Ð»ÑƒÑ‡Ð°Ñ‚ÐµÐ»Ð¸: {len(settings['target_chats'])} Ñ‡Ð°Ñ‚(Ð¾Ð²)\\n\"\n            f\"ðŸ“Š ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº: {'Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½' if settings['scheduler_enabled'] else 'Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½'}\\n\"\n            f\"ðŸ‘‘ ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñ‹: {len(settings['admin_ids'])}\"\n        )\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"â° Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼Ñ\", callback_data=\"settings:time\")],\n            [InlineKeyboardButton(text=\"ðŸ‘‘ Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð°Ð´Ð¼Ð¸Ð½Ð°\", callback_data=\"settings:add_admin\")],\n            [InlineKeyboardButton(text=\"ðŸ“Š ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ\", callback_data=\"settings:show\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error in settings menu: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº\", show_alert=True)\n\n\n@flows_router.callback_query(F.data == \"settings:time\")\nasync def handle_change_time(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"â° **Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²**\\n\\n\"\n        \"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ Ð§Ð§:ÐœÐœ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 09:30):\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_report_time)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_report_time)\nasync def handle_report_time_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        time_str = message.text.strip()\n        \n        success = get_settings_manager().set_report_time(time_str)\n        \n        if success:\n            text = f\"âœ… **Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¾ Ð½Ð° {time_str}**\"\n        else:\n            text = \"âŒ **ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸**\\n\\nÐ˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð§Ð§:ÐœÐœ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, 09:30)\"\n        \n        await message.answer(text, reply_markup=main_admin_kb(), parse_mode=\"Markdown\")\n        await state.clear()\n        \n        if success:\n            logger.info(f\"Report time changed to {time_str} by admin {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error setting report time: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸\")\n\n\n@flows_router.callback_query(F.data == \"settings:add_admin\")\nasync def handle_add_admin(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"ðŸ‘‘ **Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°**\\n\\n\"\n        \"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Telegram ID Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_admin_id)\n    await callback.answer()\n\n\n@flows_router.message(UIStates.waiting_admin_id)\nasync def handle_admin_id_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° ID Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        admin_id_str = message.text.strip()\n        admin_id = int(admin_id_str)\n        \n        if admin_id <= 0:\n            raise ValueError(\"Invalid admin ID\")\n        \n        success = get_settings_manager().add_admin(admin_id)\n        \n        if success:\n            text = f\"âœ… **ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€ {admin_id} Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½!**\"\n        else:\n            text = \"âŒ **ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°**\"\n        \n        await message.answer(text, reply_markup=main_admin_kb(), parse_mode=\"Markdown\")\n        await state.clear()\n        \n        if success:\n            logger.info(f\"Added admin {admin_id} by admin {message.from_user.id}\")\n        \n    except ValueError:\n        await message.reply(\n            \"âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚. Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ Telegram ID:\",\n            reply_markup=back_kb()\n        )\n    except Exception as e:\n        logger.exception(f\"Error adding admin: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°\")\n\n\n@flows_router.callback_query(F.data == \"settings:show\")\nasync def handle_show_settings(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        settings = get_settings_manager().get_current_settings()\n        \n        text = \"ðŸ”” **ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸**\\n\\n\"\n        text += f\"â° **Ð’Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²:** {settings['report_time']}\\n\"\n        text += f\"ðŸ“Š **ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº:** {'Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½' if settings['scheduler_enabled'] else 'Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½'}\\n\\n\"\n        \n        if settings['target_chats']:\n            text += f\"ðŸ‘¥ **Ð§Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² ({len(settings['target_chats'])}):**\\n\"\n            for chat_id in settings['target_chats'][:5]:  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 5\n                text += f\"â€¢ `{chat_id}`\\n\"\n            if len(settings['target_chats']) > 5:\n                text += f\"â€¢ ... Ð¸ ÐµÑ‰Ðµ {len(settings['target_chats']) - 5}\\n\"\n        else:\n            text += \"ðŸ‘¥ **Ð§Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²:** Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹\\n\"\n        \n        text += \"\\n\"\n        \n        if settings['admin_ids']:\n            text += f\"ðŸ‘‘ **ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñ‹ ({len(settings['admin_ids'])}):**\\n\"\n            for admin_id in settings['admin_ids'][:5]:  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ñ… 5\n                text += f\"â€¢ `{admin_id}`\\n\"\n            if len(settings['admin_ids']) > 5:\n                text += f\"â€¢ ... Ð¸ ÐµÑ‰Ðµ {len(settings['admin_ids']) - 5}\\n\"\n        else:\n            text += \"ðŸ‘‘ **ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ñ‹:** Ð½Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹\\n\"\n        \n        back_settings_kb = InlineKeyboardMarkup(inline_keyboard=[\n            [InlineKeyboardButton(text=\"â—€ï¸ Ðš Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼\", callback_data=\"menu:settings\")]\n        ])\n        \n        await callback.message.edit_text(text, reply_markup=back_settings_kb, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error showing settings: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾ÐºÐ°Ð·Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº\", show_alert=True)","size_bytes":23301},"bot_project/handlers/ui.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nUI Ð¼Ð¾Ð´ÑƒÐ»ÑŒ Ñ inline ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð°Ð¼Ð¸ Ð´Ð»Ñ Telegram Ð±Ð¾Ñ‚Ð°.\nÐ ÐµÐ°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— Ñ Ð¿Ñ€Ð°Ð²Ð°Ð¼Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ð¸ callback-Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ°Ð¼Ð¸.\n\"\"\"\n\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\n\nfrom aiogram import Router, F\nfrom aiogram.types import (\n    Message, CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton,\n    FSInputFile\n)\nfrom aiogram.filters import Command, CommandStart\nfrom aiogram.fsm.context import FSMContext\nfrom aiogram.fsm.state import State, StatesGroup\nfrom pathlib import Path\n\nfrom handlers.commands import is_admin, ADMIN_IDS\nfrom utils.adapter import (\n    create_invite_for, get_invites, find_user, add_user_manual, \n    delete_user, export_excel, get_stats, get_inviter_list,\n    get_invite_manager, get_user_manager, get_report_adapter, get_settings_manager\n)\nfrom reports.unified_report_manager import UnifiedReportManager\nfrom db.db import get_db\nfrom utils.logging_conf import get_logger\nfrom utils.time_utils import format_datetime_for_report, get_almaty_now\n\nlogger = get_logger(__name__)\n\n# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ€Ð¾ÑƒÑ‚ÐµÑ€ Ð´Ð»Ñ UI\nui_router = Router(name=\"ui\")\n\n# FSM ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð´Ð»Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð²\nclass UIStates(StatesGroup):\n    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸\n    waiting_inviter_name = State()\n    \n    # ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n    waiting_user_search = State()\n    \n    # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ\n    waiting_user_id = State()\n    waiting_username = State()\n    waiting_user_name = State()\n    waiting_inviter = State()\n    \n    # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n    waiting_delete_confirm = State()\n    waiting_delete_user = State()\n    \n    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸\n    waiting_report_time = State()\n    waiting_admin_id = State()\n\n\ndef main_admin_kb() -> InlineKeyboardMarkup:\n    \"\"\"Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ Ð´Ð»Ñ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð².\"\"\"\n    buttons = [\n        [InlineKeyboardButton(text=\"âž• Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ\", callback_data=\"menu:create_invite\")],\n        [InlineKeyboardButton(text=\"ðŸ‘¥ Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…\", callback_data=\"menu:list_invites\")],\n        [\n            InlineKeyboardButton(text=\"ðŸ“Š ÐžÑ‚Ñ‡Ñ‘Ñ‚Ñ‹\", callback_data=\"menu:reports\"),\n            InlineKeyboardButton(text=\"ðŸ† Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³\", callback_data=\"menu:rating\")\n        ],\n        [InlineKeyboardButton(text=\"ðŸ“¤ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Excel\", callback_data=\"menu:export_excel\")]\n    ]\n    return InlineKeyboardMarkup(inline_keyboard=buttons)\n\n\ndef user_menu_kb() -> InlineKeyboardMarkup:\n    \"\"\"ÐœÐµÐ½ÑŽ Ð´Ð»Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ (Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹).\"\"\"\n    buttons = [\n        [InlineKeyboardButton(text=\"ðŸ“¥ ÐœÐ¾Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÑ‘Ð½Ð½Ñ‹Ðµ\", callback_data=\"user:my_invited\")],\n        [InlineKeyboardButton(text=\"ðŸ† ÐœÐ¾Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\", callback_data=\"user:my_stats\")],\n        [InlineKeyboardButton(text=\"ðŸ“¤ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel (Ð¼Ð¾Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ)\", callback_data=\"user:my_excel\")]\n    ]\n    return InlineKeyboardMarkup(inline_keyboard=buttons)\n\n\ndef reports_kb() -> InlineKeyboardMarkup:\n    \"\"\"ÐŸÐ¾Ð´Ð¼ÐµÐ½ÑŽ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    buttons = [\n        [\n            InlineKeyboardButton(text=\"ðŸ“… Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ\", callback_data=\"reports:today\"),\n            InlineKeyboardButton(text=\"ðŸ“Š ÐÐµÐ´ÐµÐ»Ñ\", callback_data=\"reports:week\")\n        ],\n        [\n            InlineKeyboardButton(text=\"ðŸ“ˆ ÐœÐµÑÑÑ†\", callback_data=\"reports:month\"),\n            InlineKeyboardButton(text=\"ðŸ“’ ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Excel\", callback_data=\"reports:excel\")\n        ],\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ]\n    return InlineKeyboardMarkup(inline_keyboard=buttons)\n\n\ndef back_kb() -> InlineKeyboardMarkup:\n    \"\"\"ÐšÐ½Ð¾Ð¿ÐºÐ° Ð½Ð°Ð·Ð°Ð´.\"\"\"\n    return InlineKeyboardMarkup(inline_keyboard=[\n        [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n    ])\n\n\ndef confirm_delete_kb(username: str) -> InlineKeyboardMarkup:\n    \"\"\"ÐšÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ð° Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ.\"\"\"\n    buttons = [\n        [\n            InlineKeyboardButton(text=\"âœ… Ð”Ð°, ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ\", callback_data=f\"confirm:delete:{username}\"),\n            InlineKeyboardButton(text=\"âŒ ÐžÑ‚Ð¼ÐµÐ½Ð°\", callback_data=\"menu:back\")\n        ]\n    ]\n    return InlineKeyboardMarkup(inline_keyboard=buttons)\n\n\n@ui_router.message(CommandStart())\nasync def handle_start_ui(message: Message, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ /start Ñ UI Ð¼ÐµÐ½ÑŽ.\"\"\"\n    user = message.from_user\n    user_id = user.id\n    \n    logger.info(f\"UI Start command from user {user_id} (@{user.username})\")\n    \n    # ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ\n    welcome_text = f\"ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚, {user.first_name}!\\n\\n\"\n    \n    if is_admin(user_id):\n        welcome_text += (\n            \"ðŸ” **ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°**\\n\\n\"\n            \"Ð£Ð¿Ñ€Ð°Ð²Ð»ÑÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸, Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸ Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°Ð¼Ð¸:\"\n        )\n        keyboard = main_admin_kb()\n    else:\n        welcome_text += (\n            \"ðŸ“Š **Ð›Ð¸Ñ‡Ð½Ñ‹Ð¹ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ**\\n\\n\"\n            \"ÐŸÑ€Ð¾ÑÐ¼Ð°Ñ‚Ñ€Ð¸Ð²Ð°Ð¹Ñ‚Ðµ ÑÐ²Ð¾ÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸ÑÐ¼Ð¸:\"\n        )\n        keyboard = user_menu_kb()\n    \n    await message.answer(welcome_text, reply_markup=keyboard, parse_mode=\"Markdown\")\n\n\n@ui_router.message(Command(\"menu\"))\nasync def handle_menu_command(message: Message, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð³Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ.\"\"\"\n    await handle_start_ui(message, **kwargs)\n\n\n# === ADMIN MENU HANDLERS ===\n\n@ui_router.callback_query(F.data == \"menu:create_invite\")\nasync def handle_create_invite_menu(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐœÐµÐ½ÑŽ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹\n        inviter_list = get_inviter_list()\n        \n        text = (\n            \"âž• **Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸**\\n\\n\"\n            \"Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¸Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾:\"\n        )\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ñƒ Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑÐ¼Ð¸\n        buttons = []\n        for inviter in inviter_list[:10]:  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾\n            buttons.append([InlineKeyboardButton(\n                text=f\"ðŸ‘¤ {inviter}\", \n                callback_data=f\"invite:existing:{inviter}\"\n            )])\n        \n        buttons.append([InlineKeyboardButton(\n            text=\"âž• ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ\", \n            callback_data=\"invite:new\"\n        )])\n        buttons.append([InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")])\n        \n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error in create invite menu: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¼ÐµÐ½ÑŽ\", show_alert=True)\n\n\n@ui_router.callback_query(F.data.startswith(\"invite:existing:\"))\nasync def handle_existing_inviter(callback: CallbackQuery, **kwargs):\n    \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð´Ð»Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        inviter_name = callback.data.split(\":\", 2)[2]\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÑÑ‹Ð»ÐºÑƒ Ð² ÐºÐ°Ð½Ð°Ð»\n        bot = callback.bot\n        invite_link = await create_invite_for(inviter_name, bot)\n        \n        text = (\n            f\"âœ… **Ð¡ÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð° Ð´Ð»Ñ {inviter_name}!**\\n\\n\"\n            f\"`{invite_link}`\\n\\n\"\n            \"Ð¡ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÑÑ‹Ð»ÐºÑƒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŽ.\"\n        )\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð´Ð»Ñ ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð°\n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ”— Ð¡ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ\", url=invite_link)],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:create_invite\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer(\"âœ… Ð¡ÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð°!\")\n        \n        logger.info(f\"Created invite link for {inviter_name} by admin {callback.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error creating invite for existing inviter: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÑÑÑ‹Ð»ÐºÐ¸\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"invite:new\")\nasync def handle_new_inviter(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"Ð—Ð°Ð¿Ñ€Ð¾Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"âœï¸ **ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ**\\n\\n\"\n        \"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_inviter_name)\n    await callback.answer()\n\n\n@ui_router.message(UIStates.waiting_inviter_name)\nasync def handle_inviter_name_input(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ð²Ð¾Ð´Ð° Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        inviter_name = message.text.strip()\n        \n        if not inviter_name or len(inviter_name) > 50:\n            await message.reply(\n                \"âŒ Ð˜Ð¼Ñ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚ 1 Ð´Ð¾ 50 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð². ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·:\",\n                reply_markup=back_kb()\n            )\n            return\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÑÑ‹Ð»ÐºÑƒ Ð² ÐºÐ°Ð½Ð°Ð»\n        bot = message.bot\n        invite_link = await create_invite_for(inviter_name, bot)\n        \n        text = (\n            f\"âœ… **Ð¡ÑÑ‹Ð»ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð° Ð´Ð»Ñ {inviter_name}!**\\n\\n\"\n            f\"`{invite_link}`\\n\\n\"\n            \"Ð¡ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÑÑ‹Ð»ÐºÑƒ Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŽ.\"\n        )\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ”— Ð¡ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ\", url=invite_link)],\n            [InlineKeyboardButton(text=\"ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await message.answer(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await state.clear()\n        \n        logger.info(f\"Created new inviter {inviter_name} by admin {message.from_user.id}\")\n        \n    except Exception as e:\n        logger.exception(f\"Error creating new inviter: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÑÑÑ‹Ð»ÐºÐ¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.\")\n\n\n@ui_router.callback_query(F.data == \"menu:list_invites\")\nasync def handle_list_invites(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        invites = get_invites()\n        \n        if not invites:\n            text = \"ðŸ“ **Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº**\\n\\nÐ¡Ð¿Ð¸ÑÐ¾Ðº Ð¿ÑƒÑÑ‚. Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¿ÐµÑ€Ð²ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ!\"\n            await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n            await callback.answer()\n            return\n        \n        from datetime import datetime\n        current_time = get_almaty_now().strftime(\"%H:%M\")\n        text = f\"ðŸ‘¥ **Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº** (Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {current_time})\\n\\n\"\n        \n        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾ Ñ ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ\n        buttons = []\n        for i, invite in enumerate(invites[:15], 1):  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð¾ 15 ÑÑÑ‹Ð»Ð¾Ðº\n            name = invite['name']\n            total = invite.get('total_invited', 0)\n            active = invite.get('active_now', 0)\n            retention = invite.get('retention_rate', 0)\n            invite_id = invite.get('id', i)\n            \n            # ÐžÑ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÑÑ‹Ð»ÐºÐµ\n            text += f\"**{i}. {name}**\\n\"\n            text += f\"ðŸ‘¥ ÐŸÑ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾: {total} | ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ…: {active} | Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ: {retention}%\\n\"\n            text += f\"ðŸ”— `{invite.get('invite_link', 'ÐÐµÑ‚ ÑÑÑ‹Ð»ÐºÐ¸')}`\\n\\n\"\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ½Ð¾Ð¿ÐºÑƒ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸\n            buttons.append([\n                InlineKeyboardButton(\n                    text=f\"ðŸ—‘ Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ {name}\",\n                    callback_data=f\"delete:invite:{invite_id}:{name}\"\n                )\n            ])\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ð±Ñ‰Ð¸Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ\n        buttons.extend([\n            [InlineKeyboardButton(text=\"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ\", callback_data=\"menu:list_invites\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ])\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error listing invites: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ ÑÐ¿Ð¸ÑÐºÐ°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"menu:reports\")\nasync def handle_reports_menu(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾Ð´Ð¼ÐµÐ½ÑŽ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"ðŸ“Š **ÐžÑ‚Ñ‡Ñ‘Ñ‚Ñ‹**\\n\\n\"\n        \"Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿ÐµÑ€Ð¸Ð¾Ð´ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=reports_kb(), parse_mode=\"Markdown\")\n    await callback.answer()\n\n\n@ui_router.callback_query(F.data.startswith(\"reports:\"))\nasync def handle_reports(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        report_type = callback.data.split(\":\")[1]\n        \n        if report_type == \"excel\":\n            # ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Excel Ð¾Ñ‚Ñ‡ÐµÑ‚\n            await callback.answer(\"ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Excel Ð¾Ñ‚Ñ‡ÐµÑ‚...\")\n            \n            file_path = export_excel(\"full\")\n            if not file_path or not Path(file_path).exists():\n                await callback.message.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°\")\n                return\n            \n            document = FSInputFile(Path(file_path), filename=Path(file_path).name)\n            await callback.message.answer_document(\n                document=document,\n                caption=f\"ðŸ“Š ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Excel\\nðŸ• Ð¡Ð¾Ð·Ð´Ð°Ð½: {format_datetime_for_report(get_almaty_now())}\"\n            )\n            \n        else:\n            # Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚\n            await callback.answer(\"ðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¾Ñ‚Ñ‡ÐµÑ‚...\")\n            \n            stats = get_stats(report_type)\n            \n            period_names = {\n                \"today\": \"ÑÐµÐ³Ð¾Ð´Ð½Ñ\",\n                \"week\": \"Ð·Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ\", \n                \"month\": \"Ð·Ð° Ð¼ÐµÑÑÑ†\"\n            }\n            \n            period_name = period_names.get(report_type, report_type)\n            \n            text = f\"ðŸ“Š **ÐžÑ‚Ñ‡ÐµÑ‚ {period_name}**\\n\\n\"\n            text += f\"ðŸ‘¥ ÐÐ¾Ð²Ñ‹Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸: {stats.get('total_subscriptions', 0)}\\n\"\n            text += f\"âŒ ÐžÑ‚Ð¿Ð¸ÑÐºÐ¸: {stats.get('total_unsubscriptions', 0)}\\n\" \n            text += f\"ðŸ“ˆ Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð¿Ñ€Ð¸Ñ€Ð¾ÑÑ‚: {stats.get('net_growth', 0)}\\n\"\n            text += f\"ðŸ‘¤ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: {stats.get('unique_subscribers', 0)}\\n\"\n            \n            await callback.message.answer(text, reply_markup=reports_kb(), parse_mode=\"Markdown\")\n        \n    except Exception as e:\n        logger.exception(f\"Error handling report {report_type}: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"menu:rating\")\nasync def handle_rating(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        rating_data = get_report_adapter().get_rating()\n        \n        from datetime import datetime\n        current_time = get_almaty_now().strftime(\"%H:%M\")\n        text = f\"ðŸ† **Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹** (Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {current_time})\\n\\n\"\n        \n        if not rating_data:\n            text += \"Ð”Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚.\"\n        else:\n            for i, data in enumerate(rating_data[:10], 1):  # Ð¢Ð¾Ð¿-10\n                name = data.get('inviter_name', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹')\n                total = data.get('total_invited', 0)\n                active = data.get('currently_subscribed', 0)\n                retention = data.get('retention_percentage', 0)\n                \n                medal = \"ðŸ¥‡\" if i == 1 else \"ðŸ¥ˆ\" if i == 2 else \"ðŸ¥‰\" if i == 3 else f\"{i}.\"\n                text += f\"{medal} **{name}**: {total} Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾, {active} Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… ({retention}%)\\n\"\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ\", callback_data=\"menu:rating\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error showing rating: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"menu:find_user\")\nasync def handle_find_user_menu(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"ÐœÐµÐ½ÑŽ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    text = (\n        \"ðŸ”Ž **ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ**\\n\\n\"\n        \"Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ @username Ð¸Ð»Ð¸ user_id Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°:\"\n    )\n    \n    await callback.message.edit_text(text, reply_markup=back_kb(), parse_mode=\"Markdown\")\n    await state.set_state(UIStates.waiting_user_search)\n    await callback.answer()\n\n\n@ui_router.message(UIStates.waiting_user_search)\nasync def handle_user_search(message: Message, state: FSMContext, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    if not is_admin(message.from_user.id):\n        await message.reply(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\")\n        return\n    \n    try:\n        search_query = message.text.strip()\n        user_data = find_user(search_query)\n        \n        if not user_data:\n            await message.reply(\n                f\"âŒ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ '{search_query}' Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½.\\n\\nÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·:\",\n                reply_markup=back_kb()\n            )\n            return\n        \n        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ\n        text = f\"ðŸ‘¤ **Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ**\\n\\n\"\n        text += f\"**ID:** `{user_data['tg_user_id']}`\\n\"\n        text += f\"**Username:** @{user_data.get('username', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½')}\\n\"\n        text += f\"**Ð˜Ð¼Ñ:** {user_data.get('name', 'Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾')}\\n\"\n        text += f\"**Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** {user_data.get('current_status', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚ÐµÐ½')}\\n\"\n        text += f\"**ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ¾Ðº:** {user_data.get('subscribe_count', 0)}\\n\"\n        text += f\"**ÐžÑ‚Ð¿Ð¸ÑÐ¾Ðº:** {user_data.get('unsubscribe_count', 0)}\\n\"\n        text += f\"**ÐŸÐ¾ÑÐ»ÐµÐ´Ð½ÑÑ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ:** {user_data.get('last_activity', 'Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾')}\\n\\n\"\n        \n        # Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 5 ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹)\n        history = user_data.get('history', [])[:5]\n        if history:\n            text += \"**ðŸ“‹ ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ:**\\n\"\n            for event in history:\n                event_type = \"âž•\" if event['event_type'] == 'subscribe' else \"âž–\"\n                inviter = f\" (Ð¾Ñ‚ {event['inviter_name']})\" if event['inviter_name'] else \"\"\n                text += f\"{event_type} {event['event_type']}{inviter} - {event['event_time'][:10]}\\n\"\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ—‚ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸\", callback_data=f\"export:user:{user_data['tg_user_id']}\")],\n            [InlineKeyboardButton(text=\"ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await message.answer(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await state.clear()\n        \n    except Exception as e:\n        logger.exception(f\"Error searching user: {e}\")\n        await message.reply(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¸ÑÐºÐµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\")\n\n\n@ui_router.callback_query(F.data.startswith(\"delete:invite:\"))\nasync def handle_delete_invite_callback(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ: delete:invite:ID:name\n        parts = callback.data.split(\":\", 3)\n        if len(parts) < 4:\n            await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…\", show_alert=True)\n            return\n        \n        invite_id = parts[2]\n        name = parts[3]\n        \n        # ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ\n        text = f\"âš ï¸ **ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¸Ñ‚Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ**\\n\\n\"\n        text += f\"Ð’Ñ‹ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð´Ð»Ñ **{name}**?\\n\\n\"\n        text += f\"ID: `{invite_id}`\\n\\n\"\n        text += \"âš ï¸ Ð­Ñ‚Ð¾ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ Ð½ÐµÐ¾Ð±Ñ€Ð°Ñ‚Ð¸Ð¼Ð¾!\"\n        \n        buttons = [\n            [\n                InlineKeyboardButton(\n                    text=\"âœ… Ð”Ð°, ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ\",\n                    callback_data=f\"confirm:delete:invite:{invite_id}:{name}\"\n                ),\n                InlineKeyboardButton(\n                    text=\"âŒ ÐžÑ‚Ð¼ÐµÐ½Ð°\",\n                    callback_data=\"menu:list_invites\"\n                )\n            ]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error in delete invite callback: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data.startswith(\"confirm:delete:invite:\"))\nasync def handle_confirm_delete_invite(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐžÐºÐ¾Ð½Ñ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ: confirm:delete:invite:ID:name\n        parts = callback.data.split(\":\", 4)\n        if len(parts) < 5:\n            await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…\", show_alert=True)\n            return\n        \n        invite_id = parts[3]\n        name = parts[4]\n        \n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑÑÑ‹Ð»ÐºÑƒ\n        invite_manager = get_invite_manager()\n        success = invite_manager.delete_invite(invite_id)\n        \n        if success:\n            text = f\"âœ… **Ð¡ÑÑ‹Ð»ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð°**\\n\\n\"\n            text += f\"ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÑÑ‹Ð»ÐºÐ° Ð´Ð»Ñ **{name}** (ID: {invite_id}) ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½Ð°.\"\n            \n            await callback.answer(\"âœ… Ð¡ÑÑ‹Ð»ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð°!\", show_alert=True)\n            logger.info(f\"Admin {callback.from_user.id} deleted invite {invite_id} for {name}\")\n            \n        else:\n            text = f\"âŒ **ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ**\\n\\n\"\n            text += f\"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ Ð´Ð»Ñ **{name}** (ID: {invite_id}).\\n\\n\"\n            text += \"Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, ÑÑÑ‹Ð»ÐºÐ° ÑƒÐ¶Ðµ Ð±Ñ‹Ð»Ð° ÑƒÐ´Ð°Ð»ÐµÐ½Ð° Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ….\"\n            \n            await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ\", show_alert=True)\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ“‹ Ðš ÑÐ¿Ð¸ÑÐºÑƒ ÑÑÑ‹Ð»Ð¾Ðº\", callback_data=\"menu:list_invites\")],\n            [InlineKeyboardButton(text=\"ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        \n    except Exception as e:\n        logger.exception(f\"Error confirming delete invite: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ð¸ ÑÑÑ‹Ð»ÐºÐ¸\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"menu:export_excel\")\nasync def handle_export_excel(callback: CallbackQuery, **kwargs):\n    \"\"\"Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Excel Ñ„Ð°Ð¹Ð»Ð°.\"\"\"\n    if not is_admin(callback.from_user.id):\n        await callback.answer(\"âŒ ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð°Ð²\", show_alert=True)\n        return\n    \n    try:\n        await callback.answer(\"ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Excel Ñ„Ð°Ð¹Ð»...\")\n        \n        file_path = export_excel(\"full\")\n        if not file_path or not Path(file_path).exists():\n            await callback.message.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°\")\n            return\n        \n        document = FSInputFile(Path(file_path), filename=Path(file_path).name)\n        await callback.message.answer_document(\n            document=document,\n            caption=f\"ðŸ“Š ÐŸÐ¾Ð»Ð½Ð°Ñ Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Excel\\nðŸ• Ð¡Ð¾Ð·Ð´Ð°Ð½: {format_datetime_for_report(get_almaty_now())}\"\n        )\n        \n    except Exception as e:\n        logger.exception(f\"Error exporting excel: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ\", show_alert=True)\n\n\n# === USER MENU HANDLERS (Ð´Ð»Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹) ===\n\n@ui_router.callback_query(F.data == \"user:my_invited\")\nasync def handle_my_invited(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼.\"\"\"\n    user_id = callback.from_user.id\n    \n    try:\n        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð½Ñ‹Ñ… ÑÑ‚Ð¸Ð¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼\n        user_manager = get_user_manager()\n        db = get_db()\n        \n        with db.get_connection() as conn:\n            # ÐÐ°Ð¹Ð´ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ Ð¿Ð¾ user_id\n            cursor = conn.execute(\n                \"SELECT id, name FROM inviters WHERE name = ? OR invite_link LIKE ?\",\n                (callback.from_user.username or str(user_id), f\"%{user_id}%\")\n            )\n            inviter_row = cursor.fetchone()\n            \n            if not inviter_row:\n                text = \"âŒ **Ð’Ñ‹ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÐµÑÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¼**\\n\\nÐ’Ñ‹ Ð½Ðµ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ð»Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº.\"\n                await callback.message.edit_text(text, reply_markup=user_menu_kb(), parse_mode=\"Markdown\")\n                await callback.answer()\n                return\n            \n            inviter_id = inviter_row[0]\n            inviter_name = inviter_row[1]\n            \n            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð½Ñ‹Ñ…\n            cursor = conn.execute(\n                \"\"\"SELECT j.tg_user_id, j.username, j.name, j.event_time, j.status\n                   FROM journal j\n                   WHERE j.inviter_id = ? AND j.event_type = 'subscribe'\n                   ORDER BY j.event_time DESC\n                   LIMIT 20\"\"\",\n                (inviter_id,)\n            )\n            invited_users = [dict(row) for row in cursor.fetchall()]\n        \n        from datetime import datetime\n        current_time = get_almaty_now().strftime(\"%H:%M\")\n        text = f\"ðŸ“¥ **ÐœÐ¾Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð½Ñ‹Ðµ ({len(invited_users)})** (Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {current_time})\\n\\n\"\n        \n        if not invited_users:\n            text += \"ÐŸÐ¾ÐºÐ° Ð½Ð¸ÐºÐ¾Ð³Ð¾ Ð½Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð»Ð¸.\"\n        else:\n            for i, user in enumerate(invited_users[:10], 1):  # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ñ… 10\n                username_display = f\"@{user['username']}\" if user['username'] else f\"ID:{user['tg_user_id']}\"\n                name_display = user['name'] or 'Ð±ÐµÐ· Ð¸Ð¼ÐµÐ½Ð¸'\n                status_emoji = \"âœ…\" if user['status'] == 'subscribed' else \"âŒ\"\n                date_str = user['event_time'][:10]  # YYYY-MM-DD\n                \n                text += f\"{i}. {status_emoji} {name_display} ({username_display}) - {date_str}\\n\"\n            \n            if len(invited_users) > 10:\n                text += f\"\\n... Ð¸ ÐµÑ‰Ðµ {len(invited_users) - 10} Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº\"\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ\", callback_data=\"user:my_invited\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error showing my invited: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ…\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"user:my_stats\")\nasync def handle_my_stats(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    user_id = callback.from_user.id\n    \n    try:\n        db = get_db()\n        \n        with db.get_connection() as conn:\n            # ÐÐ°Ð¹Ð´ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            cursor = conn.execute(\n                \"SELECT id, name FROM inviters WHERE name = ? OR invite_link LIKE ?\",\n                (callback.from_user.username or str(user_id), f\"%{user_id}%\")\n            )\n            inviter_row = cursor.fetchone()\n            \n            if not inviter_row:\n                text = \"âŒ **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\\n\\nÐ’Ñ‹ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÐµÑÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¼.\"\n                await callback.message.edit_text(text, reply_markup=user_menu_kb(), parse_mode=\"Markdown\")\n                await callback.answer()\n                return\n            \n            inviter_id = inviter_row[0]\n            inviter_name = inviter_row[1]\n            \n            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\n            # Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾\n            cursor = conn.execute(\n                \"SELECT COUNT(*) FROM journal WHERE inviter_id = ? AND event_type = 'subscribe'\",\n                (inviter_id,)\n            )\n            total_invited = cursor.fetchone()[0]\n            \n            # ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… ÑÐµÐ¹Ñ‡Ð°Ñ\n            cursor = conn.execute(\n                \"\"\"SELECT COUNT(DISTINCT j1.tg_user_id) FROM journal j1 \n                   WHERE j1.inviter_id = ? AND j1.event_type = 'subscribe'\n                   AND j1.tg_user_id NOT IN (\n                       SELECT j2.tg_user_id FROM journal j2 \n                       WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j1.event_time\n                   )\"\"\",\n                (inviter_id,)\n            )\n            active_now = cursor.fetchone()[0]\n            \n            # Ð£ÑˆÐ»Ð¸\n            left_count = total_invited - active_now\n            \n            # ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\n            retention_rate = (active_now / total_invited * 100) if total_invited > 0 else 0\n            \n            # Ð—Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 7 Ð´Ð½ÐµÐ¹\n            from datetime import datetime, timedelta\n            week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n            cursor = conn.execute(\n                \"SELECT COUNT(*) FROM journal WHERE inviter_id = ? AND event_type = 'subscribe' AND event_time >= ?\",\n                (inviter_id, week_ago)\n            )\n            week_invited = cursor.fetchone()[0]\n        \n        from datetime import datetime\n        current_time = get_almaty_now().strftime(\"%H:%M\")\n        text = f\"ðŸ† **ÐœÐ¾Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°** (Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ {current_time})\\n\\n\"\n        text += f\"ðŸ‘¤ **ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ:** {inviter_name}\\n\\n\"\n        text += f\"ðŸ“Š **Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾:** {total_invited}\\n\"\n        text += f\"âœ… **ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… ÑÐµÐ¹Ñ‡Ð°Ñ:** {active_now}\\n\"\n        text += f\"âŒ **Ð£ÑˆÐ»Ð¸:** {left_count}\\n\"\n        text += f\"ðŸ“ˆ **% ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ:** {retention_rate:.1f}%\\n\\n\"\n        text += f\"ðŸ“… **Ð—Ð° Ð½ÐµÐ´ÐµÐ»ÑŽ:** +{week_invited} Ð½Ð¾Ð²Ñ‹Ñ…\\n\"\n        \n        # ÐžÑ†ÐµÐ½ÐºÐ°\n        if retention_rate >= 80:\n            text += \"\\nðŸ¥‡ **ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°!** Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ!\"\n        elif retention_rate >= 60:\n            text += \"\\nðŸ¥ˆ **Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾!** Ð¡Ñ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹.\"\n        elif retention_rate >= 40:\n            text += \"\\nðŸ¥‰ **ÐÐµÐ¿Ð»Ð¾Ñ…Ð¾!** Ð•ÑÑ‚ÑŒ Ð¼ÐµÑÑ‚Ð¾ Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ.\"\n        else:\n            text += \"\\nðŸ“ˆ **Ð•ÑÑ‚ÑŒ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»!** Ð Ð°Ð±Ð¾Ñ‚Ð°Ð¹Ñ‚Ðµ Ð½Ð°Ð´ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸.\"\n        \n        buttons = [\n            [InlineKeyboardButton(text=\"ðŸ”„ ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ\", callback_data=\"user:my_stats\")],\n            [InlineKeyboardButton(text=\"â—€ï¸ ÐÐ°Ð·Ð°Ð´\", callback_data=\"menu:back\")]\n        ]\n        keyboard = InlineKeyboardMarkup(inline_keyboard=buttons)\n        \n        await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n        await callback.answer()\n        \n    except Exception as e:\n        logger.exception(f\"Error showing my stats: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"user:my_excel\")\nasync def handle_my_excel(callback: CallbackQuery, **kwargs):\n    \"\"\"Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    user_id = callback.from_user.id\n    \n    try:\n        await callback.answer(\"ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð²Ð°Ñˆ Ð¾Ñ‚Ñ‡ÐµÑ‚...\")\n        \n        db = get_db()\n        \n        with db.get_connection() as conn:\n            # ÐÐ°Ð¹Ð´ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            cursor = conn.execute(\n                \"SELECT id, name FROM inviters WHERE name = ? OR invite_link LIKE ?\",\n                (callback.from_user.username or str(user_id), f\"%{user_id}%\")\n            )\n            inviter_row = cursor.fetchone()\n            \n            if not inviter_row:\n                await callback.message.answer(\n                    \"âŒ **Excel Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½**\\n\\nÐ’Ñ‹ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÐµÑÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¼.\",\n                    reply_markup=user_menu_kb(),\n                    parse_mode=\"Markdown\"\n                )\n                return\n            \n            inviter_id = inviter_row[0]\n            inviter_name = inviter_row[1]\n            \n            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n            cursor = conn.execute(\n                \"\"\"SELECT j.event_time, j.event_type, j.tg_user_id, j.username, j.name, j.status, j.note\n                   FROM journal j\n                   WHERE j.inviter_id = ?\n                   ORDER BY j.event_time DESC\"\"\",\n                (inviter_id,)\n            )\n            user_data = [dict(row) for row in cursor.fetchall()]\n        \n        if not user_data:\n            await callback.message.answer(\n                \"âŒ **ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°**\\n\\nÐ’Ñ‹ ÐµÑ‰Ðµ Ð½Ð¸ÐºÐ¾Ð³Ð¾ Ð½Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð»Ð¸.\",\n                reply_markup=user_menu_kb(),\n                parse_mode=\"Markdown\"\n            )\n            return\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Excel Ñ„Ð°Ð¹Ð»\n        import pandas as pd\n        from pathlib import Path\n        \n        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚\n        reports_dir = Path(\"reports/user_exports\")\n        reports_dir.mkdir(parents=True, exist_ok=True)\n        \n        filename = f\"my_data_{inviter_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n        file_path = reports_dir / filename\n        \n        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² DataFrame\n        df = pd.DataFrame(user_data)\n        \n        # ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ð¹\n        df.columns = ['Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ', 'Ð”ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ', 'User ID', 'Username', 'Ð˜Ð¼Ñ', 'Ð¡Ñ‚Ð°Ñ‚ÑƒÑ', 'ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ']\n        \n        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Excel\n        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n            df.to_excel(writer, sheet_name='ÐœÐ¾Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð½Ñ‹Ðµ', index=False)\n        \n        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»\n        document = FSInputFile(file_path, filename=filename)\n        await callback.message.answer_document(\n            document=document,\n            caption=f\"ðŸ“Š **Ð’Ð°ÑˆÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ**\\nðŸ‘¤ ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ: {inviter_name}\\nðŸ“… Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚: {format_datetime_for_report(get_almaty_now())}\"\n        )\n        \n        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»\n        file_path.unlink(missing_ok=True)\n        \n    except Exception as e:\n        logger.exception(f\"Error generating user excel: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"download:unified_excel\")\nasync def handle_download_unified_excel(callback: CallbackQuery, **kwargs):\n    \"\"\"Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ unified Excel Ñ„Ð°Ð¹Ð» (subscribers_report.xlsx).\"\"\"\n    try:\n        # Initialize unified report manager\n        db = get_db()\n        unified_manager = UnifiedReportManager(db)\n        \n        # Get Excel file path\n        file_path = unified_manager.export_excel_file()\n        \n        if not Path(file_path).exists():\n            await callback.answer(\"âŒ Excel Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½\", show_alert=True)\n            return\n        \n        # Send file\n        document = FSInputFile(file_path, filename=\"subscribers_report.xlsx\")\n        await callback.message.answer_document(\n            document=document,\n            caption=\"ðŸ“Š **ÐžÑ‚Ñ‡Ñ‘Ñ‚ subscribers_report.xlsx**\\n\\nÐ¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:\\nâ€¢ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ â€” Ð²ÑÐµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\\nâ€¢ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° â€” ÑÐ²Ð¾Ð´ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑÐ¼\\nâ€¢ Ð”Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹\",\n            parse_mode=\"Markdown\"\n        )\n        \n        await callback.answer(\"âœ… Ð¤Ð°Ð¹Ð» Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½\")\n        \n    except Exception as e:\n        logger.exception(f\"Error downloading unified Excel: {e}\")\n        await callback.answer(\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð°\", show_alert=True)\n\n\n@ui_router.callback_query(F.data == \"menu:back\")\nasync def handle_back_to_main(callback: CallbackQuery, state: FSMContext, **kwargs):\n    \"\"\"Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ð² Ð³Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ.\"\"\"\n    await state.clear()  # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ\n    \n    if is_admin(callback.from_user.id):\n        text = \"ðŸ” **ÐŸÐ°Ð½ÐµÐ»ÑŒ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°**\\n\\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:\"\n        keyboard = main_admin_kb()\n    else:\n        text = \"ðŸ“Š **Ð›Ð¸Ñ‡Ð½Ñ‹Ð¹ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚**\\n\\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ:\"\n        keyboard = user_menu_kb()\n    \n    await callback.message.edit_text(text, reply_markup=keyboard, parse_mode=\"Markdown\")\n    await callback.answer()\n\n\n# === ERROR HANDLER ===\n\n@ui_router.callback_query()\nasync def handle_unknown_callback(callback: CallbackQuery, **kwargs):\n    \"\"\"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ñ… callback'Ð¾Ð².\"\"\"\n    logger.warning(f\"Unknown callback: {callback.data} from user {callback.from_user.id}\")\n    await callback.answer(\"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°\", show_alert=True)","size_bytes":42287},"bot_project/utils/adapter.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nÐÐ´Ð°Ð¿Ñ‚ÐµÑ€Ñ‹ Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð±Ð¸Ð·Ð½ÐµÑ-Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹ Ð±Ð¾Ñ‚Ð°.\nÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ API-Ð¾Ð±ÐµÑ€Ñ‚ÐºÐ¸ Ð´Ð»Ñ UI Ð¼Ð¾Ð´ÑƒÐ»Ñ Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐ¸.\n\"\"\"\n\nimport os\nimport logging\nimport secrets\nimport string\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime, date, timedelta\nfrom pathlib import Path\n\nfrom db.db import get_db, DatabaseManager\nfrom reports.report_manager import ReportManager\nfrom utils.time_utils import get_almaty_now, get_today_date_str\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass InviteManager:\n    \"\"\"Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ ÑÑÑ‹Ð»ÐºÐ°Ð¼Ð¸ Ð´Ð»Ñ ÐºÐ°Ð½Ð°Ð»Ð¾Ð².\"\"\"\n    \n    def __init__(self, db: DatabaseManager, bot=None):\n        self.db = db\n        self.bot = bot\n        self.target_channels = self._get_target_channels()\n    \n    async def create_invite_for(self, inviter_name: str) -> str:\n        \"\"\"\n        Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð² ÐºÐ°Ð½Ð°Ð» Ð´Ð»Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ.\n        \n        Args:\n            inviter_name: Ð˜Ð¼Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            \n        Returns:\n            str: ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÑÑ‹Ð»ÐºÐ° Ð² ÐºÐ°Ð½Ð°Ð»\n        \"\"\"\n        try:\n            if not self.bot:\n                raise ValueError(\"Bot instance not available for creating channel invites\")\n            \n            if not self.target_channels:\n                raise ValueError(\"No target channels configured. Set TARGET_CHANNELS or TARGET_CHATS environment variable.\")\n            \n            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ð¹ ÐºÐ°Ð½Ð°Ð»\n            channel_id = self.target_channels[0]\n            \n            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ðµ Ð² ÐºÐ°Ð½Ð°Ð» Ñ Ð¸Ð¼ÐµÐ½ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            invite_link = await self._create_channel_invite(channel_id, inviter_name)\n            \n            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ð‘Ð” - Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ID\n            with self.db.get_connection() as conn:\n                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒ\n                existing = conn.execute(\n                    \"SELECT id FROM inviters WHERE name = ?\", (inviter_name,)\n                ).fetchone()\n                \n                if existing:\n                    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ ID\n                    cursor = conn.execute(\n                        \"UPDATE inviters SET username = ?, invite_link = ?, channel_id = ? WHERE id = ?\",\n                        (inviter_name, invite_link, channel_id, existing[0])\n                    )\n                    logger.info(f\"Updated existing invite for {inviter_name}\")\n                else:\n                    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ð½Ð¾Ð²ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ \n                    cursor = conn.execute(\n                        \"INSERT INTO inviters (name, username, invite_link, channel_id) VALUES (?, ?, ?, ?)\",\n                        (inviter_name, inviter_name, invite_link, channel_id)\n                    )\n                conn.commit()\n                \n                logger.info(f\"Created channel invite for {inviter_name}: {invite_link}\")\n                return invite_link\n                \n        except Exception as e:\n            logger.exception(f\"Failed to create channel invite for {inviter_name}: {e}\")\n            raise\n    \n    def get_invites(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑÑ‹Ð»ÐºÐ¸.\n        \n        Returns:\n            List[Dict]: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹ Ð¸ Ð¸Ñ… ÑÑÑ‹Ð»Ð¾Ðº\n        \"\"\"\n        try:\n            with self.db.get_connection() as conn:\n                cursor = conn.execute(\n                    \"SELECT id, name, invite_link, channel_id FROM inviters ORDER BY name\"\n                )\n                invites = []\n                for row in cursor.fetchall():\n                    invite_data = dict(row)\n                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ\n                    stats = self._get_invite_stats(invite_data['id'])\n                    invite_data.update(stats)\n                    invites.append(invite_data)\n                \n                return invites\n                \n        except Exception as e:\n            logger.exception(f\"Failed to get invites: {e}\")\n            raise\n    \n    def get_inviter_list(self) -> List[str]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸Ð¼ÐµÐ½ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n        try:\n            with self.db.get_connection() as conn:\n                cursor = conn.execute(\"SELECT DISTINCT name FROM inviters ORDER BY name\")\n                return [row[0] for row in cursor.fetchall()]\n        except Exception as e:\n            logger.exception(f\"Failed to get inviter list: {e}\")\n            return []\n    \n    def delete_invite(self, invite_id: int) -> bool:\n        \"\"\"\n        Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ.\n        \n        Args:\n            invite_id: ID Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸\n            \n        Returns:\n            bool: True ÐµÑÐ»Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾\n        \"\"\"\n        try:\n            with self.db.get_connection() as conn:\n                cursor = conn.execute(\n                    \"DELETE FROM inviters WHERE id = ?\",\n                    (invite_id,)\n                )\n                conn.commit()\n                \n                if cursor.rowcount > 0:\n                    logger.info(f\"Deleted invite {invite_id}\")\n                    return True\n                return False\n                \n        except Exception as e:\n            logger.exception(f\"Failed to delete invite {invite_id}: {e}\")\n            return False\n    \n    def get_invite_info(self, invite_id: int) -> Optional[Dict[str, Any]]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐµ.\"\"\"\n        try:\n            with self.db.get_connection() as conn:\n                cursor = conn.execute(\n                    \"SELECT id, name, invite_link, channel_id FROM inviters WHERE id = ?\",\n                    (invite_id,)\n                )\n                row = cursor.fetchone()\n                if row:\n                    invite_data = dict(row)\n                    stats = self._get_invite_stats(invite_id)\n                    invite_data.update(stats)\n                    return invite_data\n                return None\n                \n        except Exception as e:\n            logger.exception(f\"Failed to get invite info {invite_id}: {e}\")\n            return None\n    \n    def _get_target_channels(self) -> List[str]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ°Ð½Ð°Ð»Ð¾Ð² Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ð¹.\"\"\"\n        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ TARGET_CHANNELS, Ð·Ð°Ñ‚ÐµÐ¼ TARGET_CHATS ÐºÐ°Ðº fallback\n        channels_str = os.getenv('TARGET_CHANNELS', '') or os.getenv('TARGET_CHATS', '')\n        if not channels_str:\n            logger.warning(\"TARGET_CHANNELS or TARGET_CHATS not configured - cannot create channel invites\")\n            return []\n        \n        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ ÐºÐ°Ð½Ð°Ð»Ñ‹ Ð¸Ð· ÑÑ‚Ñ€Ð¾ÐºÐ¸ (Ñ‡ÐµÑ€ÐµÐ· Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ)\n        channels = [ch.strip() for ch in channels_str.split(',') if ch.strip()]\n        logger.info(f\"Configured target channels: {channels}\")\n        return channels\n    \n    async def _create_channel_invite(self, channel_id: str, inviter_name: str) -> str:\n        \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ðµ Ð² ÐºÐ°Ð½Ð°Ð» Ñ‡ÐµÑ€ÐµÐ· Telegram API.\"\"\"\n        if not self.bot:\n            raise ValueError(\"Bot instance not available\")\n            \n        try:\n            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ðµ Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            invite_link_obj = await self.bot.create_chat_invite_link(\n                chat_id=channel_id,\n                name=f\"ÐŸÑ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ðµ Ð¾Ñ‚ {inviter_name}\",\n                creates_join_request=False  # ÐŸÑ€ÑÐ¼Ð¾Ðµ Ð¿Ñ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°\n            )\n            \n            return invite_link_obj.invite_link\n            \n        except Exception as e:\n            logger.error(f\"Failed to create invite for channel {channel_id}: {e}\")\n            # Fallback - Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾ÑÑ‚Ð¾ÑÐ½Ð½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ\n            try:\n                invite_link = await self.bot.export_chat_invite_link(chat_id=channel_id)\n                logger.info(f\"Using exported invite link for {inviter_name}\")\n                return invite_link\n            except Exception as fallback_error:\n                logger.error(f\"Fallback export also failed: {fallback_error}\")\n                raise Exception(f\"Cannot create invite for channel {channel_id}. Bot may not be admin.\")\n    \n    def _get_invite_stats(self, inviter_id: int) -> Dict[str, Any]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŽ.\"\"\"\n        try:\n            with self.db.get_connection() as conn:\n                # Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾\n                cursor = conn.execute(\n                    \"SELECT COUNT(*) FROM journal WHERE inviter_id = ? AND event_type = 'subscribe'\",\n                    (inviter_id,)\n                )\n                total_invited = cursor.fetchone()[0]\n                \n                # ÐÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… ÑÐµÐ¹Ñ‡Ð°Ñ (Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð½Ñ‹ Ð¸ Ð½Ðµ Ð²Ñ‹ÑˆÐ»Ð¸)\n                cursor = conn.execute(\n                    \"\"\"SELECT COUNT(DISTINCT tg_user_id) FROM journal j1 \n                       WHERE j1.inviter_id = ? AND j1.event_type = 'subscribe'\n                       AND j1.tg_user_id NOT IN (\n                           SELECT j2.tg_user_id FROM journal j2 \n                           WHERE j2.event_type = 'unsubscribe' AND j2.event_time > j1.event_time\n                       )\"\"\",\n                    (inviter_id,)\n                )\n                active_now = cursor.fetchone()[0]\n                \n                retention_rate = (active_now / total_invited * 100) if total_invited > 0 else 0\n                \n                return {\n                    'total_invited': total_invited,\n                    'active_now': active_now,\n                    'retention_rate': round(retention_rate, 1)\n                }\n                \n        except Exception as e:\n            logger.exception(f\"Failed to get invite stats for {inviter_id}: {e}\")\n            return {'total_invited': 0, 'active_now': 0, 'retention_rate': 0}\n\n\nclass UserManager:\n    \"\"\"Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸.\"\"\"\n    \n    def __init__(self, db: DatabaseManager):\n        self.db = db\n    \n    def find_user(self, search_query: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        ÐÐ°Ð¹Ñ‚Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¿Ð¾ username Ð¸Ð»Ð¸ user_id.\n        \n        Args:\n            search_query: @username Ð¸Ð»Ð¸ user_id\n            \n        Returns:\n            Dict: Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ðµ Ð¸Ð»Ð¸ None\n        \"\"\"\n        try:\n            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ Ð¿Ð¾Ð¸ÑÐºÐ°\n            if search_query.startswith('@'):\n                username = search_query[1:]  # ÑƒÐ±Ð¸Ñ€Ð°ÐµÐ¼ @\n                search_field = 'username'\n                search_value = username\n            else:\n                try:\n                    user_id = int(search_query)\n                    search_field = 'tg_user_id'\n                    search_value = user_id\n                except ValueError:\n                    return None\n            \n            # Ð˜Ñ‰ÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n            with self.db.get_connection() as conn:\n                cursor = conn.execute(\n                    f\"SELECT DISTINCT tg_user_id, username, name FROM journal WHERE {search_field} = ? LIMIT 1\",\n                    (search_value,)\n                )\n                user_row = cursor.fetchone()\n                \n                if not user_row:\n                    return None\n                \n                user_data = dict(user_row)\n                \n                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹\n                cursor = conn.execute(\n                    \"\"\"SELECT j.event_time, j.event_type, j.status, j.note, i.name as inviter_name\n                       FROM journal j\n                       LEFT JOIN inviters i ON j.inviter_id = i.id\n                       WHERE j.tg_user_id = ?\n                       ORDER BY j.event_time DESC\"\"\",\n                    (user_data['tg_user_id'],)\n                )\n                \n                history = [dict(row) for row in cursor.fetchall()]\n                user_data['history'] = history\n                \n                # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\n                subscribe_count = len([h for h in history if h['event_type'] == 'subscribe'])\n                unsubscribe_count = len([h for h in history if h['event_type'] == 'unsubscribe'])\n                \n                # Ð¢ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ\n                last_event = history[0] if history else None\n                current_status = last_event['status'] if last_event else 'unknown'\n                \n                user_data.update({\n                    'subscribe_count': subscribe_count,\n                    'unsubscribe_count': unsubscribe_count,\n                    'current_status': current_status,\n                    'last_activity': last_event['event_time'] if last_event else None\n                })\n                \n                return user_data\n                \n        except Exception as e:\n            logger.exception(f\"Failed to find user {search_query}: {e}\")\n            return None\n    \n    def add_user_manual(self, user_data: Dict[str, Any]) -> bool:\n        \"\"\"\n        Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\n        \n        Args:\n            user_data: {tg_user_id, username, name, inviter_name, event_date}\n            \n        Returns:\n            bool: True ÐµÑÐ»Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾\n        \"\"\"\n        try:\n            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n            inviter_id = None\n            if user_data.get('inviter_name'):\n                with self.db.get_connection() as conn:\n                    cursor = conn.execute(\n                        \"SELECT id FROM inviters WHERE name = ? LIMIT 1\",\n                        (user_data['inviter_name'],)\n                    )\n                    row = cursor.fetchone()\n                    if row:\n                        inviter_id = row[0]\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n            user_id = self.db.insert_user_if_not_exists(\n                user_data['tg_user_id'],\n                user_data.get('username'),\n                user_data.get('name')\n            )\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð² Ð¶ÑƒÑ€Ð½Ð°Ð»\n            self.db.insert_journal_event(\n                event_type='manual_add',\n                tg_user_id=user_data['tg_user_id'],\n                username=user_data.get('username'),\n                name=user_data.get('name'),\n                inviter_id=inviter_id,\n                status='subscribed',\n                note='manually_added'\n            )\n            \n            logger.info(f\"Manually added user {user_data['tg_user_id']}\")\n            return True\n            \n        except Exception as e:\n            logger.exception(f\"Failed to add user manually: {e}\")\n            return False\n    \n    def delete_user(self, username_or_id: str) -> bool:\n        \"\"\"\n        Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ (Ð¿Ð¾Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ ÐºÐ°Ðº ÑƒÐ´Ð°Ð»ÐµÐ½).\n        \n        Args:\n            username_or_id: @username Ð¸Ð»Ð¸ user_id\n            \n        Returns:\n            bool: True ÐµÑÐ»Ð¸ ÑƒÐ´Ð°Ð»ÐµÐ½ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾\n        \"\"\"\n        try:\n            user_data = self.find_user(username_or_id)\n            if not user_data:\n                return False\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ\n            self.db.insert_journal_event(\n                event_type='manual_delete',\n                tg_user_id=user_data['tg_user_id'],\n                username=user_data.get('username'),\n                name=user_data.get('name'),\n                status='deleted',\n                note='manually_deleted'\n            )\n            \n            logger.info(f\"Deleted user {username_or_id}\")\n            return True\n            \n        except Exception as e:\n            logger.exception(f\"Failed to delete user {username_or_id}: {e}\")\n            return False\n\n\nclass ReportAdapter:\n    \"\"\"ÐÐ´Ð°Ð¿Ñ‚ÐµÑ€ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    \n    def __init__(self, db: DatabaseManager):\n        self.db = db\n        self.report_manager = ReportManager(db)\n        # ÐÐ¾Ð²Ñ‹Ð¹ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ ÐµÐ´Ð¸Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° subscribers_database.xlsx\n        from reports.subscribers_database_manager import SubscribersDatabaseManager\n        self.database_manager = SubscribersDatabaseManager(db)\n    \n    def export_excel(self, report_type: str = \"full\") -> str:\n        \"\"\"\n        Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² Excel ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— - ÐµÐ´Ð¸Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» subscribers_database.xlsx.\n        \n        Args:\n            report_type: Ð¢Ð¸Ð¿ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° (full, daily, weekly, monthly)\n            \n        Returns:\n            str: ÐŸÑƒÑ‚ÑŒ Ðº ÐµÐ´Ð¸Ð½Ð¾Ð¼Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ subscribers_database.xlsx\n        \"\"\"\n        try:\n            # Ð¡Ð¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— - Ð²ÑÐµÐ³Ð´Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ´Ð¸Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» subscribers_database.xlsx\n            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸ ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð½ÐµÐ²Ð½Ñ‹Ðµ Ð¾Ñ‚Ñ‡ÐµÑ‚Ñ‹ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾\n            return self.database_manager.export_database()\n                \n        except Exception as e:\n            logger.exception(f\"Failed to export unified database: {e}\")\n            raise\n    \n    def get_stats(self, period: str = \"today\") -> Dict[str, Any]:\n        \"\"\"\n        ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð·Ð° Ð¿ÐµÑ€Ð¸Ð¾Ð´.\n        \n        Args:\n            period: today, week, month\n            \n        Returns:\n            Dict: Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\n        \"\"\"\n        try:\n            today = get_today_date_str()\n            \n            if period == \"today\":\n                return self.db.get_daily_stats(today)\n            elif period == \"week\":\n                week_start = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n                return self.db.get_weekly_stats(week_start)\n            elif period == \"month\":\n                month_start = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')\n                return self.db.get_monthly_stats(month_start)\n            else:\n                return self.db.get_daily_stats(today)\n                \n        except Exception as e:\n            logger.exception(f\"Failed to get stats for {period}: {e}\")\n            return {}\n    \n    def get_rating(self) -> List[Dict[str, Any]]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n        try:\n            return self.db.get_statistics_data()\n        except Exception as e:\n            logger.exception(f\"Failed to get rating: {e}\")\n            return []\n\n\nclass SettingsManager:\n    \"\"\"Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ð¹.\"\"\"\n    \n    def __init__(self):\n        self.env_file = Path('.env')\n    \n    def get_current_settings(self) -> Dict[str, Any]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸.\"\"\"\n        return {\n            'report_time': os.getenv('REPORT_TIME', '23:59'),\n            'target_chats': os.getenv('TARGET_CHATS', '').split(',') if os.getenv('TARGET_CHATS') else [],\n            'scheduler_enabled': os.getenv('SCHEDULER_ENABLED', 'true').lower() == 'true',\n            'admin_ids': os.getenv('ADMIN_IDS', '').split(',') if os.getenv('ADMIN_IDS') else []\n        }\n    \n    def set_report_time(self, time_str: str) -> bool:\n        \"\"\"Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n        try:\n            # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸\n            hour, minute = map(int, time_str.split(':'))\n            if 0 <= hour <= 23 and 0 <= minute <= 59:\n                self._update_env_variable('REPORT_TIME', time_str)\n                return True\n            return False\n        except Exception as e:\n            logger.exception(f\"Failed to set report time {time_str}: {e}\")\n            return False\n    \n    def add_admin(self, user_id: int) -> bool:\n        \"\"\"Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.\"\"\"\n        try:\n            current_admins = self.get_current_settings()['admin_ids']\n            if str(user_id) not in current_admins:\n                current_admins.append(str(user_id))\n                self._update_env_variable('ADMIN_IDS', ','.join(current_admins))\n            return True\n        except Exception as e:\n            logger.exception(f\"Failed to add admin {user_id}: {e}\")\n            return False\n    \n    def _update_env_variable(self, key: str, value: str):\n        \"\"\"ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð² .env Ñ„Ð°Ð¹Ð»Ðµ.\"\"\"\n        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ - Ð² Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐµÐ½Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÑƒ python-dotenv\n        logger.info(f\"Would update {key}={value} in .env file\")\n\n\n# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ñ‹ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€Ð¾Ð²\ninvite_manager: Optional[InviteManager] = None\nuser_manager: Optional[UserManager] = None\nreport_adapter: Optional[ReportAdapter] = None\nsettings_manager: Optional[SettingsManager] = None\n\n\ndef init_adapters():\n    \"\"\"Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²ÑÐµÑ… Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€Ð¾Ð².\"\"\"\n    global invite_manager, user_manager, report_adapter, settings_manager\n    \n    try:\n        db = get_db()\n        invite_manager = InviteManager(db, bot=None)  # Bot Ð±ÑƒÐ´ÐµÑ‚ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½ Ð¿Ð¾Ð·Ð¶Ðµ\n        user_manager = UserManager(db)\n        report_adapter = ReportAdapter(db)\n        settings_manager = SettingsManager()\n        \n        logger.info(\"âœ… All adapters initialized successfully\")\n        \n    except Exception as e:\n        logger.exception(f\"âŒ Failed to initialize adapters: {e}\")\n        raise\n\n\ndef get_invite_manager() -> InviteManager:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÑÑ‹Ð»Ð¾Ðº.\"\"\"\n    if invite_manager is None:\n        init_adapters()\n    if invite_manager is None:\n        raise RuntimeError(\"Failed to initialize invite manager\")\n    return invite_manager\n\n\ndef get_user_manager() -> UserManager:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n    if user_manager is None:\n        init_adapters()\n    if user_manager is None:\n        raise RuntimeError(\"Failed to initialize user manager\")\n    return user_manager\n\n\ndef get_report_adapter() -> ReportAdapter:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð².\"\"\"\n    if report_adapter is None:\n        init_adapters()\n    if report_adapter is None:\n        raise RuntimeError(\"Failed to initialize report adapter\")\n    return report_adapter\n\n\ndef get_settings_manager() -> SettingsManager:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº.\"\"\"\n    if settings_manager is None:\n        init_adapters()\n    if settings_manager is None:\n        raise RuntimeError(\"Failed to initialize settings manager\")\n    return settings_manager\n\n\n# Ð£Ð´Ð¾Ð±Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸-Ð¾Ð±ÐµÑ€Ñ‚ÐºÐ¸ Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ñ Ð¢Ð—\nasync def create_invite_for(name: str, bot=None) -> str:\n    \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð´Ð»Ñ ÐºÐ°Ð½Ð°Ð»Ð°.\"\"\"\n    manager = get_invite_manager()\n    if bot and not manager.bot:\n        manager.bot = bot  # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ bot instance ÐµÑÐ»Ð¸ Ð½Ðµ Ð±Ñ‹Ð» Ð¿ÐµÑ€ÐµÐ´Ð°Ð½\n    return await manager.create_invite_for(name)\n\n\ndef get_invites() -> List[Dict[str, Any]]:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑÑ‹Ð»ÐºÐ¸.\"\"\"\n    return get_invite_manager().get_invites()\n\n\ndef find_user(search_query: str) -> Optional[Dict[str, Any]]:\n    \"\"\"ÐÐ°Ð¹Ñ‚Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    return get_user_manager().find_user(search_query)\n\n\ndef add_user_manual(data: Dict[str, Any]) -> bool:\n    \"\"\"Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ.\"\"\"\n    return get_user_manager().add_user_manual(data)\n\n\ndef delete_user(username: str) -> bool:\n    \"\"\"Ð£Ð´Ð°Ð»Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.\"\"\"\n    return get_user_manager().delete_user(username)\n\n\ndef export_excel(report_type: str = \"full\") -> str:\n    \"\"\"Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² Excel.\"\"\"\n    return get_report_adapter().export_excel(report_type)\n\n\ndef get_stats(period: str = \"today\") -> Dict[str, Any]:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ.\"\"\"\n    return get_report_adapter().get_stats(period)\n\n\ndef get_inviter_list() -> List[str]:\n    \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n    return get_invite_manager().get_inviter_list()","size_bytes":25158},"bot_project/reports/unified_excel_template.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nUnified Excel template for subscribers_report.xlsx according to TZ specification.\nCreates and maintains a single Excel file with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ, Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°, and daily sheets.\n\"\"\"\n\nimport os\nimport logging\nfrom datetime import datetime, date, timedelta\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom pathlib import Path\n\nimport pandas as pd\nfrom openpyxl import Workbook, load_workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment, Border, Side\nfrom openpyxl.utils.dataframe import dataframe_to_rows\nfrom openpyxl.worksheet.worksheet import Worksheet\n\nfrom db.db import DatabaseManager\nfrom utils.time_utils import get_almaty_now, format_datetime_for_report\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass UnifiedExcelTemplate:\n    \"\"\"\n    Unified Excel template that maintains subscribers_report.xlsx \n    with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ, Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°, and daily report sheets.\n    \"\"\"\n    \n    def __init__(self, db_manager: DatabaseManager, reports_dir: str = \"reports_output\"):\n        \"\"\"Initialize unified Excel template.\"\"\"\n        self.db = db_manager\n        self.reports_dir = Path(reports_dir)\n        self.reports_dir.mkdir(exist_ok=True)\n        self.excel_file = self.reports_dir / \"subscribers_report.xlsx\"\n        \n        # Initialize Excel file if it doesn't exist\n        self._ensure_excel_file_exists()\n        \n        logger.info(f\"UnifiedExcelTemplate initialized: {self.excel_file}\")\n    \n    def _ensure_excel_file_exists(self) -> None:\n        \"\"\"Create Excel file with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ and Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheets if it doesn't exist.\"\"\"\n        if not self.excel_file.exists():\n            logger.info(\"Creating new subscribers_report.xlsx with base sheets\")\n            \n            wb = Workbook()\n            \n            # Remove default sheet\n            if 'Sheet' in wb.sheetnames:\n                wb.remove(wb['Sheet'])\n            \n            # Create Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ sheet\n            self._create_history_sheet(wb)\n            \n            # Create Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet  \n            self._create_statistics_sheet(wb)\n            \n            wb.save(self.excel_file)\n            logger.info(\"âœ… Created subscribers_report.xlsx with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ and Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheets\")\n    \n    def _create_history_sheet(self, wb: Workbook) -> None:\n        \"\"\"Create Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ sheet with proper headers.\"\"\"\n        ws = wb.create_sheet(\"Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ\")\n        \n        # Headers according to TZ\n        headers = [\n            \"Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ\", \"Ð”ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ\", \"User ID\", \"Username\", \n            \"Ð˜Ð¼Ñ\", \"ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð²ÑˆÐ¸Ð¹\", \"Ð¡Ñ‚Ð°Ñ‚ÑƒÑ\"\n        ]\n        \n        # Add headers\n        for col, header in enumerate(headers, 1):\n            cell = ws.cell(row=1, column=col, value=header)\n            cell.font = Font(bold=True)\n            cell.fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n            cell.alignment = Alignment(horizontal=\"center\")\n        \n        # Auto-adjust column widths\n        self._auto_adjust_columns(ws)\n    \n    def _create_statistics_sheet(self, wb: Workbook) -> None:\n        \"\"\"Create Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet with proper headers.\"\"\"\n        ws = wb.create_sheet(\"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\")\n        \n        # Headers according to TZ\n        headers = [\n            \"ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð²ÑˆÐ¸Ð¹\", \"Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾\", \"ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ°Ð½Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ\", \n            \"ÐžÑ‚Ð¿Ð¸ÑÐ°Ð»Ð¸ÑÑŒ\", \"% ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ\"\n        ]\n        \n        # Add headers\n        for col, header in enumerate(headers, 1):\n            cell = ws.cell(row=1, column=col, value=header)\n            cell.font = Font(bold=True)\n            cell.fill = PatternFill(start_color=\"CCCCCC\", end_color=\"CCCCCC\", fill_type=\"solid\")\n            cell.alignment = Alignment(horizontal=\"center\")\n        \n        # Auto-adjust column widths\n        self._auto_adjust_columns(ws)\n    \n    def _auto_adjust_columns(self, ws: Worksheet) -> None:\n        \"\"\"Auto-adjust column widths based on content.\"\"\"\n        for column in ws.columns:\n            max_length = 0\n            column_letter = column[0].column_letter\n            \n            for cell in column:\n                try:\n                    if len(str(cell.value)) > max_length:\n                        max_length = len(str(cell.value))\n                except:\n                    pass\n            \n            adjusted_width = min(max_length + 2, 50)\n            ws.column_dimensions[column_letter].width = adjusted_width\n    \n    def add_history_event(self, event_data: Dict[str, Any]) -> None:\n        \"\"\"Add new event to Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ sheet.\"\"\"\n        wb = load_workbook(self.excel_file)\n        ws = wb[\"Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ\"]\n        \n        # Find next empty row\n        next_row = ws.max_row + 1\n        \n        # Format datetime according to TZ (Ð”Ð”.ÐœÐœ.Ð“Ð“Ð“Ð“ HH:MM)\n        event_time = event_data.get('event_time')\n        if isinstance(event_time, str):\n            event_time = datetime.fromisoformat(event_time.replace('Z', '+00:00'))\n        \n        formatted_time = event_time.strftime(\"%d.%m.%Y %H:%M\")\n        \n        # Map event type to Russian according to TZ\n        action_map = {\n            'subscribe': 'Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ°',\n            'unsubscribe': 'Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ°',\n            'subscription': 'Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ°',\n            'unsubscription': 'Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ°',\n            'join': 'Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ°',\n            'leave': 'Ð¾Ñ‚Ð¿Ð¸ÑÐºÐ°'\n        }\n        action = action_map.get(event_data.get('event_type', ''), event_data.get('event_type', ''))\n        \n        # Map status to Russian according to TZ\n        status_map = {\n            'subscribed': 'Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð½',\n            'unsubscribed': 'Ð²Ñ‹ÑˆÐµÐ»',\n            'left': 'Ð²Ñ‹ÑˆÐµÐ»',\n            'active': 'Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð½',\n            'inactive': 'Ð²Ñ‹ÑˆÐµÐ»'\n        }\n        status = status_map.get(event_data.get('status', ''), event_data.get('status', ''))\n        \n        # Format username (ensure @ prefix)\n        username = event_data.get('username', '')\n        if username and not username.startswith('@'):\n            username = f'@{username}'\n        \n        # Format inviter name (prefer username over name)\n        inviter_name = event_data.get('inviter_name', '')\n        \n        # Add data to row according to TZ format\n        row_data = [\n            formatted_time,\n            action,\n            event_data.get('tg_user_id', ''),\n            username,\n            event_data.get('user_name', event_data.get('name', '')),\n            inviter_name,\n            status\n        ]\n        \n        for col, value in enumerate(row_data, 1):\n            ws.cell(row=next_row, column=col, value=value)\n        \n        wb.save(self.excel_file)\n        logger.info(f\"Added history event: {action} for user {event_data.get('tg_user_id')}\")\n    \n    def update_statistics_sheet(self) -> None:\n        \"\"\"Update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet with current data from database.\"\"\"\n        wb = load_workbook(self.excel_file)\n        ws = wb[\"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\"]\n        \n        # Clear existing data (keep headers)\n        for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n            for cell in row:\n                cell.value = None\n        \n        # Get current statistics from database\n        stats_data = self._get_current_statistics()\n        \n        # Add data to sheet\n        for row_idx, inviter_stats in enumerate(stats_data, 2):\n            ws.cell(row=row_idx, column=1, value=inviter_stats['inviter_name'])\n            ws.cell(row=row_idx, column=2, value=inviter_stats['total_invited'])\n            ws.cell(row=row_idx, column=3, value=inviter_stats['currently_subscribed'])\n            ws.cell(row=row_idx, column=4, value=inviter_stats['unsubscribed'])\n            \n            # Calculate retention percentage\n            retention_pct = 0\n            if inviter_stats['total_invited'] > 0:\n                retention_pct = round(\n                    (inviter_stats['currently_subscribed'] / inviter_stats['total_invited']) * 100\n                )\n            ws.cell(row=row_idx, column=5, value=f\"{retention_pct}%\")\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n        \n        wb.save(self.excel_file)\n        logger.info(\"Updated Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet\")\n    \n    def _get_current_statistics(self) -> List[Dict[str, Any]]:\n        \"\"\"Get current statistics by inviter from database.\"\"\"\n        try:\n            # Get all unique inviters\n            inviters = self.db.get_all_inviters()\n            stats_data = []\n            \n            for inviter in inviters:\n                inviter_name = inviter.get('name', 'Unknown')\n                \n                # Get stats for this inviter\n                total_invited = self.db.count_users_by_inviter(inviter_name)\n                currently_subscribed = self.db.count_active_users_by_inviter(inviter_name)\n                unsubscribed = total_invited - currently_subscribed\n                \n                stats_data.append({\n                    'inviter_name': inviter_name,\n                    'total_invited': total_invited,\n                    'currently_subscribed': currently_subscribed,\n                    'unsubscribed': unsubscribed\n                })\n            \n            return stats_data\n            \n        except Exception as e:\n            logger.error(f\"Error getting current statistics: {e}\")\n            return []\n    \n    def create_daily_report_sheet(self, target_date: date) -> Dict[str, Any]:\n        \"\"\"Create daily report sheet with format Ð”Ð”-ÐœÐœ-Ð“Ð“Ð“Ð“.\"\"\"\n        sheet_name = target_date.strftime(\"%d-%m-%Y\")\n        \n        wb = load_workbook(self.excel_file)\n        \n        # Check if sheet already exists\n        if sheet_name in wb.sheetnames:\n            logger.info(f\"Daily sheet {sheet_name} already exists\")\n            return {'sheet_exists': True, 'sheet_name': sheet_name}\n        \n        # Create new sheet\n        ws = wb.create_sheet(sheet_name)\n        \n        # Get daily statistics\n        daily_stats = self._get_daily_statistics(target_date)\n        \n        # Create the report format according to TZ\n        current_row = 1\n        \n        # Title\n        title_cell = ws.cell(row=current_row, column=1, value=\"Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚\")\n        title_cell.font = Font(size=14, bold=True)\n        current_row += 2\n        \n        # Data rows according to TZ format\n        report_data = [\n            (\"Ð”Ð°Ñ‚Ð°\", target_date.strftime(\"%d.%m.%Y\")),\n            (\"ÐÐ¾Ð²Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸\", daily_stats['new_users']),\n            (\"ÐžÑÑ‚Ð°Ð»Ð¸ÑÑŒ Ð½Ð° \" + (target_date + timedelta(days=3)).strftime(\"%d.%m\"), \n             f\"{daily_stats['retained_3_days']} ({daily_stats['retention_3_days_pct']}%)\"),\n            (\"Ð’Ñ‹ÑˆÐ»Ð¸ Ð² Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð´ÐµÐ½ÑŒ\", daily_stats['left_same_day']),\n            (\"Ð¢Ð¾Ð¿-3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹\", daily_stats['top_inviters_text']),\n            (\"Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° (vs Ð²Ñ‡ÐµÑ€Ð°)\", daily_stats['dynamics_text'])\n        ]\n        \n        for param, value in report_data:\n            ws.cell(row=current_row, column=1, value=param).font = Font(bold=True)\n            ws.cell(row=current_row, column=2, value=value)\n            current_row += 1\n        \n        # Auto-adjust columns\n        self._auto_adjust_columns(ws)\n        \n        wb.save(self.excel_file)\n        logger.info(f\"Created daily report sheet: {sheet_name}\")\n        \n        return {\n            'sheet_exists': False, \n            'sheet_name': sheet_name,\n            'stats': daily_stats,\n            'excel_file': str(self.excel_file)\n        }\n    \n    def _get_daily_statistics(self, target_date: date) -> Dict[str, Any]:\n        \"\"\"Get daily statistics for the specified date.\"\"\"\n        try:\n            # Get basic stats for the day\n            date_str = target_date.strftime(\"%Y-%m-%d\")\n            daily_stats = self.db.get_daily_stats(date_str)\n            \n            new_users = daily_stats.get('total_subscriptions', 0)\n            left_same_day = daily_stats.get('same_day_unsubscriptions', 0)\n            \n            # Calculate 3-day retention\n            retention_3_days = self.db.get_retention_for_date(date_str, 3)\n            retained_3_days = retention_3_days.get('retained', 0)\n            retention_3_days_pct = round(retention_3_days.get('retention_rate', 0))\n            \n            # Get top 3 inviters for the day\n            top_inviters = self._get_top_inviters_for_date(target_date)\n            top_inviters_text = self._format_top_inviters(top_inviters)\n            \n            # Get dynamics (compare with yesterday)\n            yesterday = target_date - timedelta(days=1)\n            yesterday_stats = self.db.get_daily_stats(yesterday.strftime(\"%Y-%m-%d\"))\n            dynamics_text = self._format_dynamics(daily_stats, yesterday_stats)\n            \n            return {\n                'new_users': new_users,\n                'retained_3_days': retained_3_days,\n                'retention_3_days_pct': retention_3_days_pct,\n                'left_same_day': left_same_day,\n                'top_inviters_text': top_inviters_text,\n                'dynamics_text': dynamics_text,\n                'top_inviters': top_inviters\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting daily statistics: {e}\")\n            return {\n                'new_users': 0,\n                'retained_3_days': 0,\n                'retention_3_days_pct': 0,\n                'left_same_day': 0,\n                'top_inviters_text': 'ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…',\n                'dynamics_text': 'ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…',\n                'top_inviters': []\n            }\n    \n    def _get_top_inviters_for_date(self, target_date: date) -> List[Dict[str, Any]]:\n        \"\"\"Get top 3 inviters for specific date.\"\"\"\n        try:\n            date_str = target_date.strftime(\"%Y-%m-%d\")\n            return self.db.get_top_inviters_for_date(date_str, limit=3)\n        except Exception as e:\n            logger.error(f\"Error getting top inviters: {e}\")\n            return []\n    \n    def _format_top_inviters(self, top_inviters: List[Dict[str, Any]]) -> str:\n        \"\"\"Format top inviters according to TZ specification.\"\"\"\n        if not top_inviters:\n            return \"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\"\n        \n        formatted_lines = []\n        for i, inviter in enumerate(top_inviters, 1):\n            name = inviter.get('inviter_name', 'Unknown')\n            invited = inviter.get('invited_count', 0)\n            retained = inviter.get('retained_count', 0)\n            retention_pct = 0\n            if invited > 0:\n                retention_pct = round((retained / invited) * 100)\n            \n            formatted_lines.append(f\"{name} â€” {invited} ({retained} ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¾, {retention_pct}%)\")\n        \n        return \", \".join(formatted_lines)\n    \n    def _format_dynamics(self, today_stats: Dict[str, Any], yesterday_stats: Dict[str, Any]) -> str:\n        \"\"\"Format dynamics comparison according to TZ specification.\"\"\"\n        today_new = today_stats.get('total_subscriptions', 0)\n        today_retention = round(today_stats.get('retention_rate', 0))\n        \n        yesterday_new = yesterday_stats.get('total_subscriptions', 0)\n        yesterday_retention = round(yesterday_stats.get('retention_rate', 0))\n        \n        return f\"Ð’Ñ‡ÐµÑ€Ð°: +{yesterday_new} Ð½Ð¾Ð²Ñ‹Ñ…, {yesterday_retention}% ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ, Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ: +{today_new} Ð½Ð¾Ð²Ñ‹Ñ…, {today_retention}% ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ\"\n    \n    def get_daily_report_message(self, target_date: date) -> str:\n        \"\"\"Generate daily report message according to TZ specification.\"\"\"\n        daily_stats = self._get_daily_statistics(target_date)\n        \n        # Format date according to TZ\n        formatted_date = target_date.strftime(\"%d.%m.%Y\")\n        \n        # Top 3 inviters formatted for message\n        top_inviters_lines = []\n        for i, inviter in enumerate(daily_stats['top_inviters'][:3], 1):\n            name = inviter.get('inviter_name', 'Unknown')\n            invited = inviter.get('invited_count', 0)\n            retained = inviter.get('retained_count', 0)\n            retention_pct = 0\n            if invited > 0:\n                retention_pct = round((retained / invited) * 100)\n            \n            top_inviters_lines.append(f\"{i}. {name} â€” {invited} ({retained} ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¾, {retention_pct}%)\")\n        \n        top_inviters_text = \"\\n\".join(top_inviters_lines) if top_inviters_lines else \"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\"\n        \n        message = f\"\"\"ðŸ“Š Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ â€” {formatted_date}\n\nðŸ‘¥ ÐÐ¾Ð²Ñ‹Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸: {daily_stats['new_users']}\nâœ… ÐžÑÑ‚Ð°Ð»Ð¸ÑÑŒ Ð½Ð° {(target_date + timedelta(days=3)).strftime('%d.%m')}: {daily_stats['retained_3_days']} ({daily_stats['retention_3_days_pct']}%)\nâŒ Ð’Ñ‹ÑˆÐ»Ð¸ Ð² Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð´ÐµÐ½ÑŒ: {daily_stats['left_same_day']}\n\nðŸ† Ð¢Ð¾Ð¿-3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹:\n{top_inviters_text}\n\nðŸ“ˆ Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ°:\n{daily_stats['dynamics_text']}\n\nðŸ“¤ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel-Ñ„Ð°Ð¹Ð»\"\"\"\n\n        return message\n    \n    def get_excel_file_path(self) -> str:\n        \"\"\"Get path to the unified Excel file.\"\"\"\n        return str(self.excel_file)","size_bytes":17373},"bot_project/reports/unified_report_manager.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nUnified Report Manager that integrates the new Excel template with existing system.\nHandles both the unified Excel file and maintains compatibility with current workflows.\n\"\"\"\n\nimport logging\nfrom datetime import datetime, date, timedelta\nfrom typing import Dict, List, Optional, Any\nfrom pathlib import Path\n\nfrom aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton\n\nfrom db.db import DatabaseManager\nfrom reports.unified_excel_template import UnifiedExcelTemplate\nfrom utils.time_utils import get_almaty_now, format_datetime_for_report\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass UnifiedReportManager:\n    \"\"\"\n    Unified Report Manager that manages the subscribers_report.xlsx file\n    according to TZ specification and provides compatibility with existing system.\n    \"\"\"\n    \n    def __init__(self, db_manager: DatabaseManager, reports_dir: str = \"reports_output\"):\n        \"\"\"Initialize unified report manager.\"\"\"\n        self.db = db_manager\n        self.reports_dir = Path(reports_dir)\n        self.reports_dir.mkdir(exist_ok=True)\n        \n        # Initialize unified Excel template\n        self.excel_template = UnifiedExcelTemplate(db_manager, reports_dir)\n        \n        logger.info(f\"UnifiedReportManager initialized with reports directory: {self.reports_dir}\")\n    \n    def add_event_to_history(self, event_data: Dict[str, Any]) -> None:\n        \"\"\"Add event to Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ sheet and update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°.\"\"\"\n        try:\n            # Add to Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ sheet\n            self.excel_template.add_history_event(event_data)\n            \n            # Update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet\n            self.excel_template.update_statistics_sheet()\n            \n            logger.info(f\"Added event to unified Excel: {event_data.get('event_type')} for user {event_data.get('tg_user_id')}\")\n            \n        except Exception as e:\n            logger.error(f\"Error adding event to unified Excel: {e}\")\n    \n    def generate_daily_report(self, target_date: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"\n        Generate daily report according to TZ specification.\n        \n        Args:\n            target_date: Target date in YYYY-MM-DD format (default: yesterday)\n            \n        Returns:\n            Dict with report data and file path\n        \"\"\"\n        if target_date is None:\n            yesterday = get_almaty_now() - timedelta(days=1)\n            target_date = yesterday.strftime(\"%Y-%m-%d\")\n        \n        try:\n            target_date_obj = datetime.strptime(target_date, \"%Y-%m-%d\").date()\n            \n            # Update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet first\n            self.excel_template.update_statistics_sheet()\n            \n            # Create daily report sheet\n            report_result = self.excel_template.create_daily_report_sheet(target_date_obj)\n            \n            # Generate daily message\n            daily_message = self.excel_template.get_daily_report_message(target_date_obj)\n            \n            return {\n                'success': True,\n                'target_date': target_date,\n                'message': daily_message,\n                'excel_file': self.excel_template.get_excel_file_path(),\n                'sheet_created': not report_result.get('sheet_exists', False),\n                'stats': report_result.get('stats', {})\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error generating daily report: {e}\")\n            return {\n                'success': False,\n                'error': str(e),\n                'target_date': target_date\n            }\n    \n    def get_daily_message_with_button(self, target_date: Optional[str] = None) -> tuple[str, InlineKeyboardMarkup]:\n        \"\"\"\n        Get daily report message with download button according to TZ specification.\n        \n        Returns:\n            Tuple of (message_text, keyboard_markup)\n        \"\"\"\n        report_data = self.generate_daily_report(target_date)\n        \n        if not report_data['success']:\n            error_message = f\"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°: {report_data.get('error', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°')}\"\n            return error_message, InlineKeyboardMarkup(inline_keyboard=[])\n        \n        message = report_data['message']\n        \n        # Create download button according to TZ\n        download_button = InlineKeyboardMarkup(inline_keyboard=[\n            [InlineKeyboardButton(text=\"ðŸ“¤ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Excel-Ñ„Ð°Ð¹Ð»\", callback_data=\"download:unified_excel\")]\n        ])\n        \n        return message, download_button\n    \n    def get_excel_file_path(self) -> str:\n        \"\"\"Get path to the unified subscribers_report.xlsx file.\"\"\"\n        return self.excel_template.get_excel_file_path()\n    \n    def get_stats_summary(self) -> Dict[str, Any]:\n        \"\"\"Get current statistics summary from Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet.\"\"\"\n        try:\n            stats_data = self.excel_template._get_current_statistics()\n            \n            total_inviters = len(stats_data)\n            total_invited = sum(stat['total_invited'] for stat in stats_data)\n            total_active = sum(stat['currently_subscribed'] for stat in stats_data)\n            \n            return {\n                'total_inviters': total_inviters,\n                'total_invited': total_invited,\n                'total_active': total_active,\n                'overall_retention': round((total_active / total_invited * 100) if total_invited > 0 else 0),\n                'inviters_data': stats_data\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting stats summary: {e}\")\n            return {\n                'total_inviters': 0,\n                'total_invited': 0,\n                'total_active': 0,\n                'overall_retention': 0,\n                'inviters_data': []\n            }\n    \n    def export_excel_file(self) -> str:\n        \"\"\"\n        Export current unified Excel file.\n        Updates statistics and returns file path.\n        \"\"\"\n        try:\n            # Update statistics before export\n            self.excel_template.update_statistics_sheet()\n            \n            file_path = self.excel_template.get_excel_file_path()\n            logger.info(f\"Excel file ready for export: {file_path}\")\n            \n            return file_path\n            \n        except Exception as e:\n            logger.error(f\"Error exporting Excel file: {e}\")\n            raise\n    \n    def handle_subscription_event(self, user_data: Dict[str, Any]) -> None:\n        \"\"\"Handle subscription event - add to Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ and update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°.\"\"\"\n        event_data = {\n            'event_time': get_almaty_now().isoformat(),\n            'event_type': 'subscription',\n            'tg_user_id': user_data.get('tg_user_id'),\n            'username': user_data.get('username', ''),\n            'user_name': user_data.get('name', ''),\n            'inviter_name': user_data.get('inviter_name', ''),\n            'status': 'subscribed'\n        }\n        \n        self.add_event_to_history(event_data)\n    \n    def handle_unsubscription_event(self, user_data: Dict[str, Any]) -> None:\n        \"\"\"Handle unsubscription event - add to Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ and update Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°.\"\"\"\n        event_data = {\n            'event_time': get_almaty_now().isoformat(),\n            'event_type': 'unsubscription', \n            'tg_user_id': user_data.get('tg_user_id'),\n            'username': user_data.get('username', ''),\n            'user_name': user_data.get('name', ''),\n            'inviter_name': user_data.get('inviter_name', ''),\n            'status': 'unsubscribed'\n        }\n        \n        self.add_event_to_history(event_data)\n    \n    def get_daily_sheet_exists(self, target_date: Optional[date] = None) -> bool:\n        \"\"\"Check if daily sheet already exists for given date.\"\"\"\n        if target_date is None:\n            target_date = (get_almaty_now() - timedelta(days=1)).date()\n        \n        try:\n            from openpyxl import load_workbook\n            \n            excel_file = self.excel_template.get_excel_file_path()\n            if not Path(excel_file).exists():\n                return False\n            \n            wb = load_workbook(excel_file)\n            sheet_name = target_date.strftime(\"%d-%m-%Y\")\n            \n            return sheet_name in wb.sheetnames\n            \n        except Exception as e:\n            logger.error(f\"Error checking daily sheet existence: {e}\")\n            return False","size_bytes":8593},"bot_project/reports/subscribers_database_manager.py":{"content":"#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nSubscribers Database Manager - Ð•Ð´Ð¸Ð½Ñ‹Ð¹ Excel Ñ„Ð°Ð¹Ð» subscribers_database.xlsx Ð¿Ð¾ Ð¢Ð—.\nÐ ÐµÐ°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ Ñ Ð¾Ð´Ð½Ð¸Ð¼ Ñ„Ð°Ð¹Ð»Ð¾Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½Ð°ÐºÐ°Ð¿Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ.\n\"\"\"\n\nimport os\nimport logging\nfrom datetime import datetime, date, timedelta\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom pathlib import Path\n\nimport pandas as pd\nfrom openpyxl import Workbook, load_workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment, Border, Side\nfrom openpyxl.utils.dataframe import dataframe_to_rows\nfrom openpyxl.worksheet.worksheet import Worksheet\n\nfrom db.db import DatabaseManager\nfrom utils.time_utils import get_almaty_now, format_datetime_for_report\nfrom utils.logging_conf import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass SubscribersDatabaseManager:\n    \"\"\"\n    ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ ÐµÐ´Ð¸Ð½Ð¾Ð³Ð¾ Excel Ñ„Ð°Ð¹Ð»Ð° subscribers_database.xlsx ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\n    ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚:\n    1. Ð›Ð¸ÑÑ‚ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ - Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n    2. Ð›Ð¸ÑÑ‚ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° - Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ\n    3. Ð›Ð¸ÑÑ‚Ñ‹ YYYY-MM-DD - ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ Ð½Ð¾Ð²Ñ‹Ðµ Ð»Ð¸ÑÑ‚Ñ‹ Ð´Ð»Ñ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð²\n    \"\"\"\n    \n    def __init__(self, db_manager: DatabaseManager, reports_dir: str = \"reports_output\"):\n        \"\"\"Initialize subscribers database manager.\"\"\"\n        self.db = db_manager\n        self.reports_dir = Path(reports_dir)\n        self.reports_dir.mkdir(exist_ok=True)\n        self.excel_file = self.reports_dir / \"subscribers_database.xlsx\"\n        \n        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð» ÐµÑÐ»Ð¸ ÐµÐ³Ð¾ Ð½ÐµÑ‚\n        self._ensure_file_exists()\n        \n        logger.info(f\"SubscribersDatabaseManager initialized: {self.excel_file}\")\n    \n    def _ensure_file_exists(self) -> None:\n        \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Excel Ñ„Ð°Ð¹Ð» Ñ Ð»Ð¸ÑÑ‚Ð°Ð¼Ð¸ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¸ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐµÑÐ»Ð¸ ÐµÐ³Ð¾ Ð½ÐµÑ‚.\"\"\"\n        if not self.excel_file.exists():\n            logger.info(\"Creating new subscribers_database.xlsx with base sheets\")\n            \n            wb = Workbook()\n            \n            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð´ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ Ð»Ð¸ÑÑ‚\n            if 'Sheet' in wb.sheetnames:\n                wb.remove(wb['Sheet'])\n            \n            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð»Ð¸ÑÑ‚Ñ‹ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n            self._create_history_sheet(wb)\n            self._create_statistics_sheet(wb)\n            \n            wb.save(self.excel_file)\n            logger.info(\"âœ… Created subscribers_database.xlsx with Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ and Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheets\")\n    \n    def _create_history_sheet(self, wb: Workbook) -> None:\n        \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð»Ð¸ÑÑ‚ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼Ð¸ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\"\"\"\n        ws = wb.create_sheet(\"Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ\")\n        \n        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n        headers = [\n            \"Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸\", \"Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°\", \"ÐÐ¸ÐºÐ½ÐµÐ¹Ð¼\", \n            \"Username\", \"ÐšÑ‚Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð»\", \"Ð¡Ñ‚Ð°Ñ‚ÑƒÑ\"\n        ]\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸\n        for col, header in enumerate(headers, 1):\n            cell = ws.cell(row=1, column=col, value=header)\n            cell.font = Font(bold=True, color=\"FFFFFF\")\n            cell.fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n            cell.border = Border(\n                left=Side(style=\"thin\"), right=Side(style=\"thin\"),\n                top=Side(style=\"thin\"), bottom=Side(style=\"thin\")\n            )\n        \n        # ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ð±Ð¾Ñ€ ÑˆÐ¸Ñ€Ð¸Ð½Ñ‹ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº\n        self._auto_adjust_columns(ws)\n    \n    def _create_statistics_sheet(self, wb: Workbook) -> None:\n        \"\"\"Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð»Ð¸ÑÑ‚ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼Ð¸ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\"\"\"\n        ws = wb.create_sheet(\"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\")\n        \n        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n        headers = [\n            \"ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð²ÑˆÐ¸Ð¹\", \"Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾\", \"ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ°Ð½Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ\", \"ÐžÑ‚Ð¿Ð¸ÑÐ°Ð»Ð¸ÑÑŒ\"\n        ]\n        \n        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸\n        for col, header in enumerate(headers, 1):\n            cell = ws.cell(row=1, column=col, value=header)\n            cell.font = Font(bold=True, color=\"FFFFFF\")\n            cell.fill = PatternFill(start_color=\"366092\", end_color=\"366092\", fill_type=\"solid\")\n            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n            cell.border = Border(\n                left=Side(style=\"thin\"), right=Side(style=\"thin\"),\n                top=Side(style=\"thin\"), bottom=Side(style=\"thin\")\n            )\n        \n        # ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ð±Ð¾Ñ€ ÑˆÐ¸Ñ€Ð¸Ð½Ñ‹ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº\n        self._auto_adjust_columns(ws)\n    \n    def _auto_adjust_columns(self, ws: Worksheet) -> None:\n        \"\"\"ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ð±Ð¾Ñ€ ÑˆÐ¸Ñ€Ð¸Ð½Ñ‹ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð¿Ð¾ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ð¼Ñƒ.\"\"\"\n        for column in ws.columns:\n            max_length = 0\n            column_letter = column[0].column_letter\n            \n            for cell in column:\n                try:\n                    if len(str(cell.value)) > max_length:\n                        max_length = len(str(cell.value))\n                except:\n                    pass\n            \n            adjusted_width = min(max_length + 2, 50)\n            ws.column_dimensions[column_letter].width = adjusted_width\n    \n    def add_history_event(self, event_data: Dict[str, Any]) -> None:\n        \"\"\"\n        Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð² Ð»Ð¸ÑÑ‚ Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ (Ð´Ð¾Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð² ÐºÐ¾Ð½ÐµÑ†, Ð½Ðµ Ñ‚Ñ€Ð¾Ð³Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ).\n        \n        Args:\n            event_data: Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ñ Ð¿Ð¾Ð»ÑÐ¼Ð¸:\n                - event_time: Ð²Ñ€ÐµÐ¼Ñ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n                - event_type: Ñ‚Ð¸Ð¿ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ (subscribe/unsubscribe)\n                - tg_user_id: ID Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n                - username: @username Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n                - user_name: Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ (Ð½Ð¸ÐºÐ½ÐµÐ¹Ð¼)\n                - inviter_name: ÐºÑ‚Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð»\n                - status: Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ\n        \"\"\"\n        try:\n            wb = load_workbook(self.excel_file)\n            ws = wb[\"Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ\"]\n            \n            # ÐÐ°Ð¹Ñ‚Ð¸ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ Ð¿ÑƒÑÑ‚ÑƒÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ\n            next_row = ws.max_row + 1\n            \n            # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ\n            event_time = event_data.get('event_time')\n            if isinstance(event_time, str):\n                try:\n                    event_time = datetime.fromisoformat(event_time.replace('Z', '+00:00'))\n                except:\n                    event_time = get_almaty_now()\n            \n            # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n            if event_data.get('event_type') in ['subscribe', 'subscription', 'join']:\n                # ÐŸÐ¾Ð´Ð¿Ð¸ÑÐºÐ° - Ð·Ð°Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð´Ð°Ñ‚Ñƒ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸, Ð´Ð°Ñ‚Ñƒ Ð²Ñ‹Ñ…Ð¾Ð´Ð° Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹\n                subscription_time = event_time.strftime(\"%d.%m.%Y %H:%M\")\n                exit_time = \"\"\n                status = \"Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð½\"\n            else:\n                # ÐžÑ‚Ð¿Ð¸ÑÐºÐ° - Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ\n                user_id = str(event_data.get('tg_user_id', ''))\n                subscription_time = \"\"\n                exit_time = event_time.strftime(\"%d.%m.%Y %H:%M\")\n                status = \"Ð²Ñ‹ÑˆÐµÐ»\"\n                \n                # ÐŸÐ¾Ð¿Ñ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÑÑ‚Ñ€Ð¾ÐºÑƒ Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð°Ñ‚Ñ‹ Ð²Ñ‹Ñ…Ð¾Ð´Ð°\n                for row_num in range(2, ws.max_row + 1):\n                    existing_user_id = str(ws.cell(row=row_num, column=3).value or '')  # Username ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°\n                    existing_username = str(ws.cell(row=row_num, column=4).value or '')  # User ID ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°\n                    \n                    if (user_id and existing_user_id == user_id) or \\\n                       (event_data.get('username') and existing_username == f\"@{event_data.get('username').lstrip('@')}\"):\n                        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ\n                        ws.cell(row=row_num, column=2, value=exit_time)  # Ð”Ð°Ñ‚Ð° Ð²Ñ‹Ñ…Ð¾Ð´Ð°\n                        ws.cell(row=row_num, column=6, value=status)  # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ\n                        wb.save(self.excel_file)\n                        logger.info(f\"Updated exit time for user {user_id}\")\n                        return\n            \n            # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° username (Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÐ¼ @ Ð¿Ñ€ÐµÑ„Ð¸ÐºÑ)\n            username = event_data.get('username', '')\n            if username and not username.startswith('@'):\n                username = f'@{username}'\n            \n            # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ (Ñ€ÑƒÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Unknown)\n            inviter_name = event_data.get('inviter_name', '')\n            if inviter_name == 'Unknown' or not inviter_name:\n                inviter_name = 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'\n            \n            # Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ\n            row_data = [\n                subscription_time,  # Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸\n                exit_time,          # Ð”Ð°Ñ‚Ð°/Ð²Ñ€ÐµÐ¼Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°\n                event_data.get('user_name', event_data.get('name', '')),  # ÐÐ¸ÐºÐ½ÐµÐ¹Ð¼\n                username,           # Username\n                inviter_name,       # ÐšÑ‚Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð»\n                status              # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ\n            ]\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² ÑÑ‚Ñ€Ð¾ÐºÑƒ\n            for col, value in enumerate(row_data, 1):\n                ws.cell(row=next_row, column=col, value=value)\n            \n            wb.save(self.excel_file)\n            logger.info(f\"Added history event: {event_data.get('event_type')} for user {user_id}\")\n            \n        except Exception as e:\n            logger.error(f\"Error adding history event: {e}\")\n            raise\n    \n    def update_statistics_sheet(self) -> None:\n        \"\"\"\n        ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð»Ð¸ÑÑ‚ Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° - Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ.\n        ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚Ñ‹ Ð´ÐµÐ»Ð°ÑŽÑ‚ÑÑ Ð½Ð° Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\n        \"\"\"\n        try:\n            wb = load_workbook(self.excel_file)\n            ws = wb[\"Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°\"]\n            \n            # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ (Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸)\n            for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n                for cell in row:\n                    cell.value = None\n            \n            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¸Ð· Ð±Ð°Ð·Ñ‹\n            stats_data = self._get_current_statistics()\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð— Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ\n            for row_idx, inviter_stats in enumerate(stats_data, 2):\n                # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»Ñ\n                inviter_name = inviter_stats.get('inviter_name', 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½')\n                if inviter_name == 'Unknown' or not inviter_name:\n                    inviter_name = 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'\n                \n                ws.cell(row=row_idx, column=1, value=inviter_name)  # ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ð²ÑˆÐ¸Ð¹\n                ws.cell(row=row_idx, column=2, value=inviter_stats.get('total_invited', 0))  # Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾\n                ws.cell(row=row_idx, column=3, value=inviter_stats.get('currently_subscribed', 0))  # ÐŸÐ¾Ð´Ð¿Ð¸ÑÐ°Ð½Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ\n                \n                # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¾Ñ‚Ð¿Ð¸ÑÐ°Ð²ÑˆÐ¸Ñ…ÑÑ\n                total_invited = inviter_stats.get('total_invited', 0)\n                currently_subscribed = inviter_stats.get('currently_subscribed', 0)\n                unsubscribed = max(0, total_invited - currently_subscribed)\n                ws.cell(row=row_idx, column=4, value=unsubscribed)  # ÐžÑ‚Ð¿Ð¸ÑÐ°Ð»Ð¸ÑÑŒ\n            \n            # ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ð±Ð¾Ñ€ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº\n            self._auto_adjust_columns(ws)\n            \n            wb.save(self.excel_file)\n            logger.info(\"Updated Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° sheet with current data\")\n            \n        except Exception as e:\n            logger.error(f\"Error updating statistics sheet: {e}\")\n            raise\n    \n    def _get_current_statistics(self) -> List[Dict[str, Any]]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½ÑƒÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÑÐ¼ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ….\"\"\"\n        try:\n            return self.db.get_statistics_data()\n        except Exception as e:\n            logger.error(f\"Error getting statistics: {e}\")\n            return []\n    \n    def create_daily_report_sheet(self, target_date: date) -> Dict[str, Any]:\n        \"\"\"\n        Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ Ð»Ð¸ÑÑ‚ Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð¼ Ð·Ð° Ð´ÐµÐ½ÑŒ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ YYYY-MM-DD.\n        Ð•ÑÐ»Ð¸ Ð»Ð¸ÑÑ‚ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ - Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\n        \n        Args:\n            target_date: Ð”Ð°Ñ‚Ð° Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°\n            \n        Returns:\n            Dict Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸\n        \"\"\"\n        try:\n            sheet_name = target_date.strftime(\"%Y-%m-%d\")\n            \n            wb = load_workbook(self.excel_file)\n            \n            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ Ñ‚Ð°ÐºÐ¾Ð¹ Ð»Ð¸ÑÑ‚\n            if sheet_name in wb.sheetnames:\n                logger.info(f\"Daily sheet {sheet_name} already exists - skipping\")\n                return {'sheet_exists': True, 'sheet_name': sheet_name}\n            \n            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹ Ð»Ð¸ÑÑ‚\n            ws = wb.create_sheet(sheet_name)\n            \n            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð° Ð´ÐµÐ½ÑŒ\n            daily_stats = self._get_daily_statistics(target_date)\n            \n            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n            current_row = 1\n            \n            # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº\n            title_cell = ws.cell(row=current_row, column=1, value=f\"Ð•Ð¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ð·Ð° {target_date.strftime('%d.%m.%Y')}\")\n            title_cell.font = Font(size=14, bold=True)\n            current_row += 2\n            \n            # Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—\n            report_content = f\"\"\"Ð¡Ð²Ð¾Ð´ÐºÐ° Ð¿Ð¾ ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ:\n- ÐÐ¾Ð²Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: {daily_stats['new_users']}\n- ÐžÑÑ‚Ð°Ð»Ð¸ÑÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼Ð¸: {daily_stats['retained_users']} ({daily_stats['retention_rate']}%)\n- Ð’Ñ‹ÑˆÐ»Ð¸ Ð² Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ð´ÐµÐ½ÑŒ: {daily_stats['left_same_day']}\n\nÐ¢Ð¾Ð¿-3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹:\n{daily_stats['top_inviters_text']}\n\nÐ”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° (vs Ð²Ñ‡ÐµÑ€Ð°):\n{daily_stats['dynamics_text']}\"\"\"\n            \n            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°\n            ws.cell(row=current_row, column=1, value=report_content)\n            \n            # ÐÐ²Ñ‚Ð¾Ð¿Ð¾Ð´Ð±Ð¾Ñ€ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº\n            self._auto_adjust_columns(ws)\n            \n            wb.save(self.excel_file)\n            logger.info(f\"Created daily report sheet: {sheet_name}\")\n            \n            return {\n                'sheet_exists': False,\n                'sheet_name': sheet_name,\n                'stats': daily_stats\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error creating daily report sheet: {e}\")\n            return {'error': str(e)}\n    \n    def _get_daily_statistics(self, target_date: date) -> Dict[str, Any]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð·Ð° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ.\"\"\"\n        try:\n            date_str = target_date.strftime(\"%Y-%m-%d\")\n            daily_stats = self.db.get_daily_stats(date_str)\n            \n            # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»Ð¸\n            new_users = daily_stats.get('total_subscriptions', 0)\n            left_same_day = daily_stats.get('same_day_unsubscriptions', 0)\n            \n            # Ð£Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ Ñ‡ÐµÑ€ÐµÐ· 3 Ð´Ð½Ñ\n            retention_data = self.db.get_retention_for_date(date_str, 3)\n            retained_users = retention_data.get('retained', 0)\n            retention_rate = round(retention_data.get('retention_rate', 0))\n            \n            # Ð¢Ð¾Ð¿-3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹\n            top_inviters = self._get_top_inviters_for_date(target_date)\n            top_inviters_text = self._format_top_inviters(top_inviters)\n            \n            # Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° (ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ñ Ð²Ñ‡ÐµÑ€Ð°)\n            yesterday = target_date - timedelta(days=1)\n            yesterday_stats = self.db.get_daily_stats(yesterday.strftime(\"%Y-%m-%d\"))\n            dynamics_text = self._format_dynamics(daily_stats, yesterday_stats)\n            \n            return {\n                'new_users': new_users,\n                'retained_users': retained_users,\n                'retention_rate': retention_rate,\n                'left_same_day': left_same_day,\n                'top_inviters_text': top_inviters_text,\n                'dynamics_text': dynamics_text\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting daily statistics: {e}\")\n            return {\n                'new_users': 0, 'retained_users': 0, 'retention_rate': 0,\n                'left_same_day': 0, 'top_inviters_text': 'ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…',\n                'dynamics_text': 'ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…'\n            }\n    \n    def _get_top_inviters_for_date(self, target_date: date) -> List[Dict[str, Any]]:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ð¿-3 Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹ Ð·Ð° Ð´ÐµÐ½ÑŒ.\"\"\"\n        try:\n            date_str = target_date.strftime(\"%Y-%m-%d\")\n            return self.db.get_top_inviters_for_date(date_str, limit=3)\n        except:\n            return []\n    \n    def _format_top_inviters(self, top_inviters: List[Dict[str, Any]]) -> str:\n        \"\"\"Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð¿ Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÐµÐ»ÐµÐ¹.\"\"\"\n        if not top_inviters:\n            return \"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…\"\n        \n        lines = []\n        for i, inviter in enumerate(top_inviters, 1):\n            name = inviter.get('inviter_name', 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½')\n            if name == 'Unknown':\n                name = 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'\n            invited = inviter.get('invited_count', 0)\n            retained = inviter.get('retained_count', 0)\n            retention_pct = round((retained / invited * 100) if invited > 0 else 0)\n            \n            lines.append(f\"{i}. {name} â€” {invited} Ð¿Ñ€Ð¸Ð³Ð»Ð°ÑˆÐµÐ½Ð¾, {retained} ÑƒÐ´ÐµÑ€Ð¶Ð°Ð½Ð¾ ({retention_pct}%)\")\n        \n        return \"\\n\".join(lines)\n    \n    def _format_dynamics(self, today_stats: Dict[str, Any], yesterday_stats: Dict[str, Any]) -> str:\n        \"\"\"Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÑƒ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ñ Ð²Ñ‡ÐµÑ€Ð°.\"\"\"\n        today_new = today_stats.get('total_subscriptions', 0)\n        yesterday_new = yesterday_stats.get('total_subscriptions', 0)\n        \n        change = today_new - yesterday_new\n        change_text = f\"+{change}\" if change > 0 else str(change)\n        \n        return f\"Ð’Ñ‡ÐµÑ€Ð°: {yesterday_new} Ð½Ð¾Ð²Ñ‹Ñ…, Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ: {today_new} Ð½Ð¾Ð²Ñ‹Ñ… ({change_text})\"\n    \n    def export_database(self) -> str:\n        \"\"\"\n        Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐµÐ´Ð¸Ð½ÑƒÑŽ Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÐ¾Ð³Ð»Ð°ÑÐ½Ð¾ Ð¢Ð—.\n        ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ.\n        \n        Returns:\n            str: ÐŸÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ subscribers_database.xlsx\n        \"\"\"\n        try:\n            # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ\n            self.update_statistics_sheet()\n            \n            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð»Ð¸ÑÑ‚ Ð·Ð° ÑÐµÐ³Ð¾Ð´Ð½Ñ ÐµÑÐ»Ð¸ ÐµÐ³Ð¾ ÐµÑ‰Ðµ Ð½ÐµÑ‚\n            today = get_almaty_now().date()\n            self.create_daily_report_sheet(today)\n            \n            logger.info(f\"Database export completed: {self.excel_file}\")\n            return str(self.excel_file)\n            \n        except Exception as e:\n            logger.error(f\"Error exporting database: {e}\")\n            raise\n    \n    def get_file_path(self) -> str:\n        \"\"\"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ subscribers_database.xlsx.\"\"\"\n        return str(self.excel_file)","size_bytes":20868}},"version":1}